# Logfile created on 2025-12-08 13:50:33 +0800 by logger.rb/v1.7.0
I, [2025-12-08T13:50:33.163710 #23430]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:50:33.163738 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.163786 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.163808 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.163821 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.163826 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.163836 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.163842 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.163858 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.163863 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.163873 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.163877 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.163887 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.242321 #23430]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:50:33.242386 #23430]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:50:33.242848 #23430]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:50:33.242882 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.242917 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.242922 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.242930 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.242935 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.242941 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.242944 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.242955 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.242960 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.242969 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.242973 #23430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:50:33.242985 #23430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:50:33.243203 #23430]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:50:33.243226 #23430]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:51:29.912684 #23659]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:51:29.912754 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.912804 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.912811 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.912821 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.912825 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.912832 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.912836 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.912847 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.912852 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.912866 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.912870 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.912881 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972000 #23659]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:51:29.972071 #23659]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:51:29.972376 #23659]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:51:29.972415 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.972455 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972476 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.972488 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972494 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.972501 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972505 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.972519 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972523 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.972533 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972538 #23659]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:51:29.972551 #23659]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:51:29.972980 #23659]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:51:29.973006 #23659]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:52:14.842457 #23896]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:52:14.842557 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.842621 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.842629 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.842639 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.842644 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.842654 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.842659 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.842672 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.842676 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.842688 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.842692 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.842703 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.916903 #23896]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:52:14.916968 #23896]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:52:14.917301 #23896]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:52:14.917337 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.917373 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.917391 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.917403 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.917409 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.917416 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.917421 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.917435 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.917439 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.917449 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.917454 #23896]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:14.917463 #23896]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:14.917659 #23896]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:52:14.917681 #23896]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:52:45.842052 #24100]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:52:45.842389 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.842463 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.842483 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.842495 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.842501 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.842508 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.842512 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.842527 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.842532 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.842542 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.842546 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.842556 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.971653 #24100]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:52:45.971772 #24100]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:52:45.972522 #24100]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:52:45.972616 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.972686 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.972695 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.972704 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.972708 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.972715 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.972719 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.972732 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.972736 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.972746 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.972751 #24100]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:45.972761 #24100]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:45.972995 #24100]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:52:45.973021 #24100]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:52:53.186468 #24187]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:52:53.186542 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.186595 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.186603 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.186612 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.186617 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.186624 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.186628 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.186641 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.186646 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.186657 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.186661 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.186672 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.259411 #24187]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:52:53.259481 #24187]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:52:53.259796 #24187]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:52:53.259841 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.259891 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.259898 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.259906 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.259910 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.259916 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.259920 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.259932 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.259936 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.259945 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.259953 #24187]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:52:53.259963 #24187]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:52:53.260173 #24187]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:52:53.260196 #24187]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:53:49.178557 #24461]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:53:49.178637 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.178687 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.178694 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.178703 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.178707 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.178713 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.178717 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.178729 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.178733 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.178743 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.178747 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.178757 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.231397 #24461]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:53:49.231459 #24461]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:53:49.231756 #24461]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:53:49.231793 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.231828 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.231846 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.231858 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.231864 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.231871 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.231875 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.231888 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.231893 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.231903 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.231907 #24461]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:53:49.231917 #24461]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:53:49.232113 #24461]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:53:49.232137 #24461]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:55:58.749791 #25141]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:55:58.749940 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.750005 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.750013 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.750022 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.750028 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.750034 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.750038 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.750051 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.750056 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.750066 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.750071 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.750080 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830054 #25141]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:55:58.830118 #25141]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:55:58.830497 #25141]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:55:58.830541 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.830576 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830583 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.830590 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830595 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.830601 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830605 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.830618 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830623 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.830632 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830636 #25141]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:55:58.830646 #25141]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:55:58.830903 #25141]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:55:58.830949 #25141]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:57:07.778606 #25561]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:57:07.778687 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.778737 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.778744 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.778753 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.778758 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.778799 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.778806 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.778946 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.779012 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.779051 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.779062 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.779081 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.850567 #25561]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:57:07.850690 #25561]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:57:07.851064 #25561]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:57:07.851112 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.851147 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.851153 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.851161 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.851165 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.851171 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.851176 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.851187 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.851191 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.851201 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.851205 #25561]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:57:07.851214 #25561]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:57:07.851423 #25561]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:57:07.851446 #25561]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:58:52.239341 #26302]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:58:52.240181 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.240249 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.240270 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.240287 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.240293 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.240301 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.240306 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.240352 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.240369 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.240387 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.240394 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.240405 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.362526 #26302]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:58:52.362590 #26302]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:58:52.362879 #26302]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:58:52.362951 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.362987 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.363016 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.363029 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.363034 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.363042 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.363046 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.363059 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.363064 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.363074 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.363078 #26302]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:58:52.363088 #26302]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:58:52.363302 #26302]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:58:52.363323 #26302]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:59:10.631404 #26448]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:59:10.631486 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.631543 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.631550 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.631563 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.631567 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.631573 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.631577 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.631589 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.631594 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.631603 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.631607 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.631617 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.685334 #26448]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:59:10.685397 #26448]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T13:59:10.685679 #26448]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T13:59:10.685715 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.685748 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.685764 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.685775 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.685780 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.685787 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.685790 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.685802 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.685806 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.685816 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.685820 #26448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T13:59:10.685829 #26448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T13:59:10.686034 #26448]  INFO -- : Configuration loaded successfully
I, [2025-12-08T13:59:10.686054 #26448]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:43:11.483797 #35911]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:43:11.484143 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.484210 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.484218 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.484227 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.484232 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.484239 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.484243 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.484256 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.484260 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.484270 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.484274 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.484284 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.595251 #35911]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:43:11.595310 #35911]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:43:11.596009 #35911]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:43:11.596043 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.596087 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.596113 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.596125 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.596130 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.596136 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.596141 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.596153 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.596158 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.596168 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.596172 #35911]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:43:11.596182 #35911]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:43:11.596466 #35911]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:43:11.596493 #35911]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:44:33.951469 #36306]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:44:33.951548 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:33.951595 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:33.951602 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:33.951610 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:33.951615 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:33.951621 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:33.951625 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:33.951638 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:33.951642 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:33.951652 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:33.951656 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:33.951667 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.005927 #36306]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:44:34.005993 #36306]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:44:34.006334 #36306]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:44:34.006377 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:34.006411 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.006418 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:34.006426 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.006431 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:34.006444 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.006452 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:34.006465 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.006470 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:34.006481 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.006485 #36306]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:44:34.006495 #36306]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:44:34.006751 #36306]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:44:34.006777 #36306]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:45:57.906216 #37122]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:45:57.906572 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:57.906654 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:57.906687 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:57.906702 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:57.906707 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:57.906715 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:57.906719 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:57.906734 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:57.906738 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:57.906749 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:57.906753 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:57.906763 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.042825 #37122]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:45:58.042890 #37122]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:45:58.043509 #37122]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:45:58.043560 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:58.043605 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.043611 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:58.043620 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.043624 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:58.043631 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.043635 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:58.043650 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.043654 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:58.043664 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.043668 #37122]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:45:58.043679 #37122]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:45:58.043920 #37122]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:45:58.043944 #37122]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:46:43.309836 #37356]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:46:43.309942 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.309998 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.310005 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.310014 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.310019 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.310026 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.310031 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.310043 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.310047 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.310058 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.310062 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.310131 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.366818 #37356]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:46:43.366880 #37356]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:46:43.367179 #37356]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:46:43.367213 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.367249 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.367274 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.367286 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.367291 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.367298 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.367303 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.367315 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.367320 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.367329 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.367333 #37356]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:46:43.367343 #37356]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:46:43.367633 #37356]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:46:43.367675 #37356]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:48:23.557504 #37862]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:48:23.557579 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.557630 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.557637 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.557646 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.557650 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.557657 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.557661 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.557673 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.557678 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.557688 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.557692 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.557702 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.613660 #37862]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:48:23.613723 #37862]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:48:23.614016 #37862]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:48:23.614049 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.614081 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.614097 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.614120 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.614125 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.614133 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.614137 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.614150 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.614154 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.614164 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.614168 #37862]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:48:23.614178 #37862]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:48:23.614444 #37862]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:48:23.614471 #37862]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:51:14.867096 #38567]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:51:14.867174 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.867231 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.867255 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.867266 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.867271 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.867277 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.867281 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.867295 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.867299 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.867309 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.867313 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.867324 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.980495 #38567]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:51:14.980573 #38567]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T14:51:14.980899 #38567]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T14:51:14.980937 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.980981 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.980998 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.981012 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.981017 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.981027 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.981031 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.981043 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.981047 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.981075 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.981081 #38567]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T14:51:14.981093 #38567]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T14:51:14.981318 #38567]  INFO -- : Configuration loaded successfully
I, [2025-12-08T14:51:14.981340 #38567]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:00:38.544075 #40517]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:00:38.544161 #40517]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:00:38.544194 #40517]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:00:38.544201 #40517]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:00:38.544209 #40517]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:00:38.544213 #40517]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:00:38.544219 #40517]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:00:38.613939 #40517]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:00:38.614003 #40517]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:00:38.614368 #40517]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:00:38.614411 #40517]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:00:38.614434 #40517]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:00:38.614439 #40517]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:00:38.614446 #40517]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:00:38.614450 #40517]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:00:38.614457 #40517]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:00:38.614702 #40517]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:00:38.614729 #40517]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:01:04.005325 #40712]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:01:04.005409 #40712]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:01:04.005449 #40712]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:01:04.005455 #40712]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:01:04.005462 #40712]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:01:04.005466 #40712]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:01:04.005472 #40712]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:01:04.064528 #40712]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:01:04.064698 #40712]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:01:04.065063 #40712]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:01:04.065105 #40712]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:01:04.065133 #40712]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:01:04.065138 #40712]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:01:04.065146 #40712]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:01:04.065150 #40712]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:01:04.065156 #40712]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:01:04.065389 #40712]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:01:04.065417 #40712]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:20:15.654540 #44717]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:20:15.654920 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655039 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655107 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655123 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655128 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655136 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655140 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655197 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655209 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655224 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655230 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655242 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655247 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655311 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655320 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655327 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.655332 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.655339 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.769962 #44717]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:20:15.770026 #44717]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:20:15.770404 #44717]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:20:15.770447 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770488 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770505 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770517 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770531 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770538 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770566 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770585 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770591 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770602 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770606 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770617 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770621 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770628 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770632 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770638 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770642 #44717]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:15.770647 #44717]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:15.770883 #44717]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:20:15.770905 #44717]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:20:50.575928 #44937]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:20:50.576018 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576069 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576076 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576084 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576089 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576096 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576100 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576112 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576117 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576126 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576130 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576140 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576144 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576151 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576155 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576161 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.576165 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.576171 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636057 #44937]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:20:50.636133 #44937]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:20:50.636482 #44937]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:20:50.636520 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636568 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636576 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636585 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636590 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636597 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636602 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636617 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636621 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636695 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636706 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636720 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636726 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636734 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636844 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636871 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.636880 #44937]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:20:50.636887 #44937]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:20:50.637169 #44937]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:20:50.637192 #44937]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:22:07.613978 #45489]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:22:07.614082 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614138 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614146 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614156 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614161 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614168 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614172 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614184 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614189 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614199 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614204 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614213 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614217 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614224 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614228 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614234 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.614238 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.614244 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.671488 #45489]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:22:07.671574 #45489]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:22:07.672044 #45489]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:22:07.672093 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672135 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672142 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672150 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672155 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672162 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672167 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672185 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672190 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672200 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672205 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672215 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672219 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672263 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672272 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672280 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672285 #45489]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:07.672292 #45489]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:07.672793 #45489]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:22:07.672903 #45489]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:22:19.395518 #45594]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:22:19.395606 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395661 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395667 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395679 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395683 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395690 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395694 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395707 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395711 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395722 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395726 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395737 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395741 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395747 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395751 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395757 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.395761 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.395767 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457007 #45594]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:22:19.457074 #45594]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:22:19.457487 #45594]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:22:19.457527 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457562 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457568 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457575 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457579 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457585 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457589 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457602 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457606 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457616 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457620 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457629 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457633 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457639 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457642 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457648 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457652 #45594]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:22:19.457667 #45594]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:22:19.457898 #45594]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:22:19.457921 #45594]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:23:29.559898 #45943]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:23:29.560042 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560103 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560112 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560122 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560127 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560134 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560138 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560152 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560157 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560182 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560192 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560209 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560215 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560223 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560228 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560235 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.560240 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.560246 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.673851 #45943]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:23:29.673917 #45943]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:23:29.674632 #45943]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:23:29.674673 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674726 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674747 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674759 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674765 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674772 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674777 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674789 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674794 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674804 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674808 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674817 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674822 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674828 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674832 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674838 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.674842 #45943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:23:29.674849 #45943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:23:29.675080 #45943]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:23:29.675105 #45943]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:26:28.253172 #46748]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:26:28.253495 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.253586 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.253609 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.253624 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.253629 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.253638 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.253643 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.253657 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.253663 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.253679 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.253684 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.253694 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.386176 #46748]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:26:28.386242 #46748]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:26:28.386860 #46748]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:26:28.386906 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.386944 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.386950 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.386958 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.386963 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.386969 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.386973 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.386985 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.386989 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.386998 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.387003 #46748]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:26:28.387012 #46748]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:26:28.387240 #46748]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:26:28.387264 #46748]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:32:01.167635 #48033]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:32:01.167716 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.167771 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.167780 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.167790 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.167995 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.168014 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.168020 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.168079 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.168097 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.168150 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.168171 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.168190 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.238207 #48033]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:32:01.238287 #48033]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:32:01.238747 #48033]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:32:01.238796 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.238845 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.238864 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.238877 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.238883 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.238890 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.238894 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.238908 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.238912 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.238923 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.238927 #48033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:32:01.238937 #48033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:32:01.239193 #48033]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:32:01.239214 #48033]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:33:55.916436 #48569]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:33:55.916547 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.916685 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.916735 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.916778 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.916786 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.916794 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.916799 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.916831 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.916854 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.916878 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.916885 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.916897 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.988603 #48569]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:33:55.988671 #48569]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:33:55.989000 #48569]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:33:55.989041 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.989080 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.989100 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.989112 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.989118 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.989125 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.989130 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.989144 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.989149 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.989163 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.989167 #48569]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:33:55.989177 #48569]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:33:55.989452 #48569]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:33:55.989483 #48569]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:33:58.688670 #48569]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-08T15:33:58.688684 #48569]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:33:58.688692 #48569]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:33:58.688704 #48569]  INFO -- : Create Conversation
I, [2025-12-08T15:33:58.688939 #48569]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:33:58.689353 #48569]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:33:58.689383 #48569]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:33:58.854290 #48569] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:33:58.854368 #48569]  INFO -- : Successful send a message
I, [2025-12-08T15:33:58.854390 #48569]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-08T15:34:39.801689 #48769]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:34:39.801785 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.801844 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.801852 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.801861 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.801866 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.801873 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.801877 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.801892 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.801896 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.801910 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.801915 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.801925 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.870786 #48769]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:34:39.870859 #48769]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:34:39.871224 #48769]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:34:39.871267 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.871307 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.871326 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.871338 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.871344 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.871353 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.871358 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.871375 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.871380 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.871391 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.871395 #48769]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:34:39.871405 #48769]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:34:39.871644 #48769]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:34:39.871666 #48769]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:34:42.308256 #48769]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-08T15:34:42.308264 #48769]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:34:42.308272 #48769]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:34:42.308283 #48769]  INFO -- : Create Conversation
I, [2025-12-08T15:34:42.308322 #48769]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:34:42.308673 #48769]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:34:42.308705 #48769]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:34:42.461355 #48769] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:34:42.461466 #48769]  INFO -- : Successful send a message
I, [2025-12-08T15:34:42.461494 #48769]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-08T15:35:34.711136 #49080]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:35:34.711227 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.711321 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.711342 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.711355 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.711360 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.711367 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.711372 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.711397 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.711403 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.711420 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.711425 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.711434 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.780008 #49080]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:35:34.780077 #49080]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:35:34.780394 #49080]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:35:34.780432 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.780496 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.780505 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.780515 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.780519 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.780526 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.780530 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.780548 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.780803 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.780850 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.780869 #49080]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:35:34.780887 #49080]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:35:34.781160 #49080]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:35:34.781182 #49080]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:35:45.334193 #49080]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-08T15:35:45.334206 #49080]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:35:45.334215 #49080]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:35:45.334228 #49080]  INFO -- : Create Conversation
I, [2025-12-08T15:35:45.334260 #49080]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:35:45.334614 #49080]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:35:45.334647 #49080]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:35:45.492051 #49080] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:35:45.492179 #49080]  INFO -- : Successful send a message
I, [2025-12-08T15:35:45.492213 #49080]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:37:11.748240 #49656]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:37:11.748319 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.748396 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.748404 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.748413 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.748418 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.748424 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.748429 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.748441 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.748445 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.748457 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.748462 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.748479 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.814314 #49656]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:37:11.814518 #49656]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:37:11.814946 #49656]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:37:11.814989 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.815059 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.815066 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.815075 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.815080 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.815087 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.815092 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.815104 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.815108 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.815120 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.815124 #49656]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:37:11.815134 #49656]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:37:11.815407 #49656]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:37:11.815444 #49656]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:37:19.936991 #49656]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-08T15:37:19.937000 #49656]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:37:19.937009 #49656]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:37:19.937031 #49656]  INFO -- : Create Conversation
I, [2025-12-08T15:37:19.937066 #49656]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:37:19.937492 #49656]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:37:19.937532 #49656]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:37:20.083515 #49656] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:37:20.083621 #49656]  INFO -- : Successful send a message
I, [2025-12-08T15:37:20.083654 #49656]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:37:20.685829 #49656]  INFO -- : Calling worker: pre_search with params: {:text=>"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:37:20.685967 #49656]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-08T15:37:20.685988 #49656]  INFO -- : Create worker's name is pre_search
I, [2025-12-08T15:37:20.686008 #49656]  INFO -- : Create Conversation
I, [2025-12-08T15:37:20.686051 #49656]  INFO -- : Use template pre_search
I, [2025-12-08T15:37:20.686505 #49656]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:37:20.686551 #49656]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:37:20.856743 #49656] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:37:20.856853 #49656]  INFO -- : Successful send a message
I, [2025-12-08T15:37:20.856882 #49656]  INFO -- : Worker pre_search executed successfully
I, [2025-12-08T15:37:21.460004 #49656]  INFO -- : Calling worker: smart_search with params: {:text=>"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:37:21.460118 #49656]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-08T15:37:21.460134 #49656]  INFO -- : Create worker's name is smart_search
I, [2025-12-08T15:37:21.460146 #49656]  INFO -- : Create Conversation
I, [2025-12-08T15:37:21.460175 #49656]  INFO -- : Use template smart_search
I, [2025-12-08T15:37:21.460446 #49656]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:37:21.460476 #49656]  INFO -- : OpenAIAdapter: Using model deepseek-chat
E, [2025-12-08T15:37:21.613182 #49656] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:37:21.613319 #49656]  INFO -- : Successful send a message
I, [2025-12-08T15:37:21.613352 #49656]  INFO -- : Worker smart_search executed successfully
I, [2025-12-08T15:37:21.614268 #49656]  INFO -- : Calling worker: summary with params: {:text=>"hello", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:37:21.614333 #49656]  INFO -- : Creating worker instance for: summary
I, [2025-12-08T15:37:21.614352 #49656]  INFO -- : Create worker's name is summary
I, [2025-12-08T15:37:21.614369 #49656]  INFO -- : Create Conversation
I, [2025-12-08T15:37:21.614408 #49656]  INFO -- : Use template summarize
I, [2025-12-08T15:37:21.614917 #49656]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:37:21.614970 #49656]  INFO -- : OpenAIAdapter: Using model moonshotai/Kimi-K2-Instruct
E, [2025-12-08T15:37:21.812824 #49656] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.siliconflow.cn/v1/chat/completions
I, [2025-12-08T15:37:21.812937 #49656]  INFO -- : Successful send a message
I, [2025-12-08T15:37:21.812966 #49656]  INFO -- : Worker summary executed successfully
I, [2025-12-08T15:39:42.387225 #50401]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:39:42.387300 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387374 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387385 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387571 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387608 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387622 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387628 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387695 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387722 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387734 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387740 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387746 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387751 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387764 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387768 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387778 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.387782 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.387791 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.459968 #50401]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:39:42.460038 #50401]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:39:42.460397 #50401]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:39:42.460437 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460459 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460464 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460471 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460479 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460500 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460507 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460530 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460547 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460573 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460579 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460587 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460591 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460604 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460609 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460618 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460622 #50401]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:39:42.460632 #50401]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:39:42.460878 #50401]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:39:42.460903 #50401]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:40:06.422408 #50608]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:40:06.422477 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422514 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422521 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422529 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422534 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422540 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422544 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422567 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422572 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422579 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422582 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422597 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422601 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422612 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422617 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422627 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.422631 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.422640 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.492599 #50608]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:40:06.492703 #50608]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:40:06.493171 #50608]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:40:06.493216 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493240 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493245 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493253 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493257 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493264 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493268 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493296 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493301 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493308 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493312 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493319 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493322 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493334 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493338 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493348 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493353 #50608]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:40:06.493363 #50608]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:40:06.493731 #50608]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:40:06.493910 #50608]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:41:33.427922 #51011]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:41:33.428002 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428036 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428043 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428052 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428056 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428063 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428067 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428126 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428146 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428158 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428164 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428176 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428181 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428199 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428205 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428223 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.428227 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.428238 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495016 #51011]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:41:33.495091 #51011]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:41:33.495473 #51011]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:41:33.495509 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495534 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495539 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495546 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495550 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495556 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495559 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495581 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495586 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495593 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495596 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495602 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495606 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495615 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495619 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495628 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495631 #51011]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:41:33.495641 #51011]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:41:33.495874 #51011]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:41:33.495896 #51011]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:41:36.378724 #51011]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-08T15:41:36.378733 #51011]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:41:36.378741 #51011]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:41:36.378753 #51011]  INFO -- : Create Conversation
I, [2025-12-08T15:41:36.378786 #51011]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:41:36.379104 #51011]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:41:36.379132 #51011]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:41:36.526336 #51011] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:41:36.526425 #51011]  INFO -- : Successful send a message
I, [2025-12-08T15:41:36.526447 #51011]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:41:37.128324 #51011]  INFO -- : Calling worker: pre_search with params: {:text=>"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:41:37.128421 #51011]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-08T15:41:37.128435 #51011]  INFO -- : Create worker's name is pre_search
I, [2025-12-08T15:41:37.128446 #51011]  INFO -- : Create Conversation
I, [2025-12-08T15:41:37.128472 #51011]  INFO -- : Use template pre_search
I, [2025-12-08T15:41:37.128930 #51011]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:41:37.128970 #51011]  INFO -- : OpenAIAdapter: Using model deepseek-reasoner
E, [2025-12-08T15:41:37.295702 #51011] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:41:37.295836 #51011]  INFO -- : Successful send a message
I, [2025-12-08T15:41:37.295868 #51011]  INFO -- : Worker pre_search executed successfully
I, [2025-12-08T15:41:37.898335 #51011]  INFO -- : Calling worker: smart_search with params: {:text=>"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:41:37.898485 #51011]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-08T15:41:37.898509 #51011]  INFO -- : Create worker's name is smart_search
I, [2025-12-08T15:41:37.898527 #51011]  INFO -- : Create Conversation
I, [2025-12-08T15:41:37.898565 #51011]  INFO -- : Use template smart_search
I, [2025-12-08T15:41:37.898916 #51011]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:41:37.898964 #51011]  INFO -- : OpenAIAdapter: Using model deepseek-chat
E, [2025-12-08T15:41:38.050625 #51011] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.deepseek.com/v1/chat/completions
I, [2025-12-08T15:41:38.050721 #51011]  INFO -- : Successful send a message
I, [2025-12-08T15:41:38.050741 #51011]  INFO -- : Worker smart_search executed successfully
I, [2025-12-08T15:41:38.051203 #51011]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:41:38.051268 #51011]  INFO -- : Creating worker instance for: summary
I, [2025-12-08T15:41:38.051278 #51011]  INFO -- : Create worker's name is summary
I, [2025-12-08T15:41:38.051290 #51011]  INFO -- : Create Conversation
I, [2025-12-08T15:41:38.051313 #51011]  INFO -- : Use template summarize
I, [2025-12-08T15:41:38.051563 #51011]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:41:38.051589 #51011]  INFO -- : OpenAIAdapter: Using model moonshotai/Kimi-K2-Instruct
E, [2025-12-08T15:41:38.221615 #51011] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://api.siliconflow.cn/v1/chat/completions
I, [2025-12-08T15:41:38.221730 #51011]  INFO -- : Successful send a message
I, [2025-12-08T15:41:38.221757 #51011]  INFO -- : Worker summary executed successfully
I, [2025-12-08T15:43:35.313867 #51610]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:43:35.314203 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314243 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314250 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314262 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314267 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314274 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314279 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314309 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314326 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314339 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314345 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314353 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314358 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314374 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314388 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314413 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.314420 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.314431 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.432759 #51610]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:43:35.432819 #51610]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:43:35.433466 #51610]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:43:35.433508 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433535 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433540 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433547 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433551 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433557 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433561 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433583 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433588 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433594 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433598 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433604 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433607 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433618 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433622 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433635 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433640 #51610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:43:35.433649 #51610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:43:35.433972 #51610]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:43:35.434006 #51610]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:43:37.833164 #51610]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-08T15:43:37.833187 #51610]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:43:37.833198 #51610]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:43:37.833211 #51610]  INFO -- : Create Conversation
I, [2025-12-08T15:43:37.833244 #51610]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:43:37.833565 #51610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:43:37.833602 #51610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:43:45.729564 #51610]  INFO -- : Successful send a message
I, [2025-12-08T15:43:45.729649 #51610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:43:45.729671 #51610]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:43:46.331927 #51610]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n** / **  \n\n- ****  \n    \n- ****  \n  -   \n  -   \n- ****  \n  ********Social Initiation Utterance\n\n---\n\n### **2. **  \n****  \n\n- ****    \n- ****    \n- ****    \n- ****    \n\n>  ********\n\n---\n\n### **3. **  \n****  \n\n- ****  \n  -     \n- ****  \n  - ****  \n- ****  \n  -  `site:`, `filetype:`   \n- ****  \n  -   \n\n>    \n> -   \n> -   \n> -   \n>  ****\n\n---\n\n### **4. **  \n\n|  |  |\n|------|------|\n| **** | ****   |\n| **** | <br> - <br> -  <br> - <br> |\n| **** | ****<br> -  <br> - ****<br> - ******** |\n\n---\n\n###  ****\n\n> ****  \n> ****  \n>   \n>   \n> ****  \n> -   \n> - ****  \n> -   \n\n---\n\n****  \n********  \n\n\nPython", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:43:46.332149 #51610]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-08T15:43:46.332169 #51610]  INFO -- : Create worker's name is pre_search
I, [2025-12-08T15:43:46.332185 #51610]  INFO -- : Create Conversation
I, [2025-12-08T15:43:46.332223 #51610]  INFO -- : Use template pre_search
I, [2025-12-08T15:43:46.332742 #51610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:43:46.332777 #51610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:43:50.498167 #51610]  INFO -- : Successful send a message
I, [2025-12-08T15:43:50.498244 #51610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:43:50.498263 #51610]  INFO -- : Worker pre_search executed successfully
I, [2025-12-08T15:43:51.100753 #51610]  INFO -- : Calling worker: smart_search with params: {:text=>"****\n\n###  ****\n\n****\n\n- ****  \n- ****  \n- ****  \n- ****  \n\n---\n\n###  ****\n\n> ****  \n> ****  \n>  \n\n---\n\n###  ****\n\n\n- API\n- \n- \n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| **** |  |\n| **** | 3PythonGitHubGitee |\n| **** |  `smart_search``get_open_digger_metric`  |\n\n---\n\n****  \n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:43:51.100870 #51610]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-08T15:43:51.100885 #51610]  INFO -- : Create worker's name is smart_search
I, [2025-12-08T15:43:51.100899 #51610]  INFO -- : Create Conversation
I, [2025-12-08T15:43:51.100930 #51610]  INFO -- : Use template smart_search
I, [2025-12-08T15:43:51.101206 #51610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:43:51.101237 #51610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:43:51.380122 #51610]  INFO -- : Successful send a message
I, [2025-12-08T15:43:51.380187 #51610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:43:51.380203 #51610]  INFO -- : Worker smart_search executed successfully
I, [2025-12-08T15:43:51.380617 #51610]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:43:51.380653 #51610]  INFO -- : Creating worker instance for: summary
I, [2025-12-08T15:43:51.380662 #51610]  INFO -- : Create worker's name is summary
I, [2025-12-08T15:43:51.380671 #51610]  INFO -- : Create Conversation
I, [2025-12-08T15:43:51.380691 #51610]  INFO -- : Use template summarize
I, [2025-12-08T15:43:51.380916 #51610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:43:51.380940 #51610]  INFO -- : OpenAIAdapter: Using model moonshotai/Kimi-K2-Instruct
E, [2025-12-08T15:43:51.467760 #51610] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/chat/completions
I, [2025-12-08T15:43:51.467880 #51610]  INFO -- : Successful send a message
I, [2025-12-08T15:43:51.467909 #51610]  INFO -- : Worker summary executed successfully
I, [2025-12-08T15:44:43.168363 #52044]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:44:43.168439 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168475 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168482 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168490 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168501 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168508 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168512 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168621 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168644 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168656 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168662 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168669 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168673 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168687 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168691 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168701 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.168705 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.168715 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.233911 #52044]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:44:43.233983 #52044]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:44:43.234360 #52044]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:44:43.234463 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234504 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234511 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234518 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234522 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234529 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234533 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234572 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234580 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234588 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234592 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234599 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234603 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234615 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234619 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234630 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234634 #52044]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:44:43.234645 #52044]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:44:43.234961 #52044]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:44:43.234999 #52044]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:44:45.412672 #52044]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-08T15:44:45.412680 #52044]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:44:45.412687 #52044]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:44:45.412712 #52044]  INFO -- : Create Conversation
I, [2025-12-08T15:44:45.412740 #52044]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:44:45.413085 #52044]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:44:45.413113 #52044]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:44:52.323573 #52044]  INFO -- : Successful send a message
I, [2025-12-08T15:44:52.323658 #52044]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:44:52.323678 #52044]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:44:52.926013 #52044]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n** / **  \n\n-   \n- ****  \n- AI  \n\n>  ************\n\n---\n\n### **2. **  \n- ****   \n- ****   \n- ****   \n- ****   \n\n>  ************\n\n---\n\n### **3. **  \n- ****  \n- ****  \n- ****  `site:`, `intitle:`   \n- ****\n\n>  ********\n\n---\n\n### **4. **  \n- ********  \n- ****  \n  -     \n  - AI     \n- ****  \n  - ****  \n  - ****  \n  - ****\n\n>  ********\n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| **** |  **** |\n| **** |  |\n| **** |  |\n| **** |  |\n\n>  ********\n\n--- \n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:44:52.926121 #52044]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-08T15:44:52.926134 #52044]  INFO -- : Create worker's name is pre_search
I, [2025-12-08T15:44:52.926144 #52044]  INFO -- : Create Conversation
I, [2025-12-08T15:44:52.926170 #52044]  INFO -- : Use template pre_search
I, [2025-12-08T15:44:52.926504 #52044]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:44:52.926530 #52044]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:44:54.426241 #52044]  INFO -- : Successful send a message
I, [2025-12-08T15:44:54.426311 #52044]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:44:54.426328 #52044]  INFO -- : Worker pre_search executed successfully
I, [2025-12-08T15:44:55.028366 #52044]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1  \n  - []   \n\n- 2  \n  - []   \n\n- 3  \n  - []   \n\n- 4  \n  - []   \n\n---\n\n ********  \n****  \n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:44:55.028473 #52044]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-08T15:44:55.028488 #52044]  INFO -- : Create worker's name is smart_search
I, [2025-12-08T15:44:55.028499 #52044]  INFO -- : Create Conversation
I, [2025-12-08T15:44:55.028549 #52044]  INFO -- : Use template smart_search
I, [2025-12-08T15:44:55.028782 #52044]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:44:55.028811 #52044]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:44:55.316175 #52044]  INFO -- : Successful send a message
I, [2025-12-08T15:44:55.316252 #52044]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:44:55.316272 #52044]  INFO -- : Worker smart_search executed successfully
I, [2025-12-08T15:44:55.316719 #52044]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:44:55.316748 #52044]  INFO -- : Creating worker instance for: summary
I, [2025-12-08T15:44:55.316757 #52044]  INFO -- : Create worker's name is summary
I, [2025-12-08T15:44:55.316767 #52044]  INFO -- : Create Conversation
I, [2025-12-08T15:44:55.316788 #52044]  INFO -- : Use template summarize
I, [2025-12-08T15:44:55.317010 #52044]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:44:55.317035 #52044]  INFO -- : OpenAIAdapter: Using model moonshotai/Kimi-K2-Instruct
E, [2025-12-08T15:44:55.398321 #52044] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/chat/completions
I, [2025-12-08T15:44:55.398402 #52044]  INFO -- : Successful send a message
I, [2025-12-08T15:44:55.398422 #52044]  INFO -- : Worker summary executed successfully
I, [2025-12-08T15:46:33.216122 #52666]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:46:33.216205 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216241 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216248 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216257 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216262 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216269 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216274 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216333 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216354 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216367 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216373 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216389 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216393 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216407 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216411 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216421 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.216426 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.216436 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.285900 #52666]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:46:33.285975 #52666]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:46:33.286403 #52666]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:46:33.286447 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286469 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286474 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286481 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286485 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286492 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286496 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286520 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286525 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286531 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286535 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286541 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286545 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286556 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286560 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286570 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286574 #52666]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:46:33.286583 #52666]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:46:33.286831 #52666]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:46:33.286854 #52666]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:46:35.442417 #52666]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-08T15:46:35.442426 #52666]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:46:35.442434 #52666]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:46:35.442445 #52666]  INFO -- : Create Conversation
I, [2025-12-08T15:46:35.442474 #52666]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:46:35.442812 #52666]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:46:35.442838 #52666]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:46:44.065406 #52666]  INFO -- : Successful send a message
I, [2025-12-08T15:46:44.065493 #52666]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:46:44.065518 #52666]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:46:44.668122 #52666]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n** / **  \n\n- ****  \n    \n- ****  \n  -    \n  -    \n  -  /  \n  -    \n  -    \n\n>  ********\n\n---\n\n### **2. **  \n****  \n\n- ****    \n- ****    \n- ****    \n- ****    \n\n>  ********\n\n---\n\n### **3. **  \n****  \n\n- ****  \n  -     \n- ****  \n  -   \n- ****  \n  -  `site:`, `filetype:`, `intitle:`     \n- ****  \n  -     \n\n>  ********\n\n---\n\n### **4. **  \n\n- ****  \n   ********  \n\n- ****  \n  -     \n  - AI    \n  >  ****\n\n- ****  \n  -  ****   \n  -  ****  \n  -  ********hihello****\n\n---\n\n###  ****  \n\n|  |  |\n|------|----------|\n| **** | **** |\n| **** | NLP |\n| **** |  |\n| **** | **** |\n\n---\n\n>  ****  \n> ********  \n> AI\n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:46:44.668244 #52666]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-08T15:46:44.668258 #52666]  INFO -- : Create worker's name is pre_search
I, [2025-12-08T15:46:44.668269 #52666]  INFO -- : Create Conversation
I, [2025-12-08T15:46:44.668301 #52666]  INFO -- : Use template pre_search
I, [2025-12-08T15:46:44.668786 #52666]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:46:44.668820 #52666]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:46:46.623571 #52666]  INFO -- : Successful send a message
I, [2025-12-08T15:46:46.623642 #52666]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:46:46.623668 #52666]  INFO -- : Worker pre_search executed successfully
I, [2025-12-08T15:46:47.225607 #52666]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1  \n  - []   \n\n- 2  \n  - []   \n\n- 3  \n  - []   \n\n- 4  \n  - []   \n\n---\n\n###  ****  \n********  \n\n****  \n>   \n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:46:47.225732 #52666]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-08T15:46:47.225751 #52666]  INFO -- : Create worker's name is smart_search
I, [2025-12-08T15:46:47.225764 #52666]  INFO -- : Create Conversation
I, [2025-12-08T15:46:47.225795 #52666]  INFO -- : Use template smart_search
I, [2025-12-08T15:46:47.226176 #52666]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:46:47.226217 #52666]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:46:47.637346 #52666]  INFO -- : Successful send a message
I, [2025-12-08T15:46:47.637418 #52666]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:46:47.637435 #52666]  INFO -- : Worker smart_search executed successfully
I, [2025-12-08T15:46:47.637826 #52666]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:46:47.637850 #52666]  INFO -- : Creating worker instance for: summary
I, [2025-12-08T15:46:47.637859 #52666]  INFO -- : Create worker's name is summary
I, [2025-12-08T15:46:47.637872 #52666]  INFO -- : Create Conversation
I, [2025-12-08T15:46:47.637891 #52666]  INFO -- : Use template summarize
I, [2025-12-08T15:46:47.638120 #52666]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:46:47.638144 #52666]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:46:52.001203 #52666]  INFO -- : Successful send a message
I, [2025-12-08T15:46:52.001315 #52666]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:46:52.001336 #52666]  INFO -- : Worker summary executed successfully
I, [2025-12-08T15:47:57.841305 #53173]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:47:57.841388 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841425 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841431 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841440 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841447 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841456 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841460 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841483 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841495 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841502 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841506 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841512 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841516 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841529 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841534 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841543 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.841547 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.841557 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.900950 #53173]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:47:57.901014 #53173]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:47:57.901385 #53173]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:47:57.901421 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901454 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901462 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901481 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901487 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901494 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901498 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901520 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901525 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901531 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901535 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901541 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901544 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901555 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901559 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901568 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901572 #53173]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:47:57.901581 #53173]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:47:57.901805 #53173]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:47:57.901829 #53173]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:55:27.801487 #54942]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:55:27.801567 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801602 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801608 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801616 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801620 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801627 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801631 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801653 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801658 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801664 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801669 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801675 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801686 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801696 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801702 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801713 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.801717 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.801726 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859318 #54942]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:55:27.859380 #54942]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:55:27.859716 #54942]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:55:27.859754 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859776 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859782 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859789 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859793 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859799 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859803 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859825 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859841 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859852 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859858 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859866 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859870 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859883 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859888 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.859898 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.859902 #54942]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:27.860096 #54942]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:27.860341 #54942]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:55:27.860366 #54942]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:55:44.340727 #55097]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:55:44.340802 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340837 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340842 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340850 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340854 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340861 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340864 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340903 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340920 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340931 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340936 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340944 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340948 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340960 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340964 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340982 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.340986 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.340996 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.408521 #55097]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:55:44.408592 #55097]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:55:44.408912 #55097]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T15:55:44.408948 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.408968 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.408973 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.408980 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.408984 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.408990 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.408994 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.409014 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.409018 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.409025 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.409029 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.409035 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.409038 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.409048 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.409053 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.409062 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.409066 #55097]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T15:55:44.409075 #55097]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T15:55:44.409335 #55097]  INFO -- : Configuration loaded successfully
I, [2025-12-08T15:55:44.409361 #55097]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T15:55:51.463777 #55097]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-08T15:55:51.463787 #55097]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-08T15:55:51.463796 #55097]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-08T15:55:51.463810 #55097]  INFO -- : Create Conversation
I, [2025-12-08T15:55:51.463883 #55097]  INFO -- : Use template analyze_search_scope
I, [2025-12-08T15:55:51.464266 #55097]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:55:51.464301 #55097]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:55:59.874568 #55097]  INFO -- : Successful send a message
I, [2025-12-08T15:55:59.874674 #55097]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:55:59.874704 #55097]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-08T15:56:00.477167 #55097]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n** / **  \n\n- ****  \n    \n- ****  \n  \n\n>  ********  \n\n---\n\n### **2. **  \n****  \n\n- ****    \n- ****    \n- ****    \n- ****    \n\n>  ********\n\n---\n\n### **3. **  \n****  \n\n- ****  \n      \n- ****  \n  AI  \n- ****  \n   site:filetype:   \n- ****  \n    \n\n>  ********\n\n---\n\n### **4. **  \n\n- ****  \n  ****    \n\n- ****  \n    \n  - ```  ```  \n  - `site:zhihu.com \"\" `  `intitle:\"\" `  \n  -   \n\n- ****  \n  - ****  \n  - ****  \n  - ****  \n\n>  ********  \n> **\n\n---\n\n###  ****  \n|  |  |\n|------|------|\n| **** |  |\n| **** |  |\n| **** | AI |\n\n>  ****  \n>  ****\n\n--- \n\nPython********", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:56:00.477360 #55097]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-08T15:56:00.477382 #55097]  INFO -- : Create worker's name is pre_search
I, [2025-12-08T15:56:00.477397 #55097]  INFO -- : Create Conversation
I, [2025-12-08T15:56:00.477434 #55097]  INFO -- : Use template pre_search
I, [2025-12-08T15:56:00.477982 #55097]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:56:00.478028 #55097]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:56:02.806645 #55097]  INFO -- : Successful send a message
I, [2025-12-08T15:56:02.806753 #55097]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:56:02.806791 #55097]  INFO -- : Worker pre_search executed successfully
I, [2025-12-08T15:56:03.409664 #55097]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1  \n  - []   \n\n- 2  \n  - []   \n\n- 3  \n  - []   \n\n- 4  \n  - []   \n\n---\n\n###  ****  \n********  \n\n****  \n>   \n\n****  \nAI****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:56:03.409759 #55097]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-08T15:56:03.409773 #55097]  INFO -- : Create worker's name is smart_search
I, [2025-12-08T15:56:03.409784 #55097]  INFO -- : Create Conversation
I, [2025-12-08T15:56:03.409807 #55097]  INFO -- : Use template smart_search
I, [2025-12-08T15:56:03.410024 #55097]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:56:03.410053 #55097]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:56:03.875620 #55097]  INFO -- : Successful send a message
I, [2025-12-08T15:56:03.875715 #55097]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:56:03.875741 #55097]  INFO -- : Worker smart_search executed successfully
I, [2025-12-08T15:56:03.876357 #55097]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-08T15:56:03.876405 #55097]  INFO -- : Creating worker instance for: summary
I, [2025-12-08T15:56:03.876420 #55097]  INFO -- : Create worker's name is summary
I, [2025-12-08T15:56:03.876636 #55097]  INFO -- : Create Conversation
I, [2025-12-08T15:56:03.876694 #55097]  INFO -- : Use template summarize
I, [2025-12-08T15:56:03.877152 #55097]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-08T15:56:03.877202 #55097]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-08T15:56:06.703008 #55097]  INFO -- : Successful send a message
I, [2025-12-08T15:56:06.703070 #55097]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-08T15:56:06.703087 #55097]  INFO -- : Worker summary executed successfully
I, [2025-12-08T16:39:06.769812 #65369]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T16:39:06.770439 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770487 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770495 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770505 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770510 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770517 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770522 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770591 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770612 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770625 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770631 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770639 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770651 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770666 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770671 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770681 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.770685 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.770694 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.882989 #65369]  INFO -- : Configuration loaded successfully
I, [2025-12-08T16:39:06.883049 #65369]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T16:39:06.883396 #65369]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T16:39:06.883429 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883456 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883465 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883472 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883476 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883483 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883487 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883508 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883512 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883519 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883523 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883529 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883533 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883545 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883549 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883559 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883563 #65369]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T16:39:06.883572 #65369]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T16:39:06.883797 #65369]  INFO -- : Configuration loaded successfully
I, [2025-12-08T16:39:06.883823 #65369]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T17:33:35.872799 #78208]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T17:33:35.872893 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.872939 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.872945 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.872954 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.872958 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.872965 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.872970 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.872997 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.873002 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.873009 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.873013 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.873020 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.873024 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.873037 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.873042 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.873052 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.873065 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.873075 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.942539 #78208]  INFO -- : Configuration loaded successfully
I, [2025-12-08T17:33:35.942604 #78208]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-08T17:33:35.942990 #78208]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-08T17:33:35.943030 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943052 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943058 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943065 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943069 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943075 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943079 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943100 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943104 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943111 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943115 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943121 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943124 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943135 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943150 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943166 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943172 #78208]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-08T17:33:35.943182 #78208]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-08T17:33:35.943418 #78208]  INFO -- : Configuration loaded successfully
I, [2025-12-08T17:33:35.943440 #78208]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:23:18.062717 #8978]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:23:18.063272 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063332 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063351 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063364 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063371 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063379 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063384 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063411 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063426 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063441 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063449 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063458 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063474 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063494 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063501 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063513 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.063518 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.063528 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.191905 #8978]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:23:18.191964 #8978]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:23:18.192621 #8978]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:23:18.192671 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192694 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192700 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192707 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192711 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192717 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192721 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192743 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192748 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192755 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192759 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192765 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192769 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192780 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192784 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192793 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.192797 #8978]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:23:18.192807 #8978]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:23:18.193218 #8978]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:23:18.193256 #8978]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:23:44.725796 #8978]  INFO -- : Calling worker: pre_search with params: {:text=>"esp-idf i2sapi", :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}], :with_history=>true}
I, [2025-12-09T16:23:44.725933 #8978]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:23:44.725959 #8978]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:23:44.725987 #8978]  INFO -- : Create Conversation
I, [2025-12-09T16:23:44.726037 #8978]  INFO -- : Use template pre_search
I, [2025-12-09T16:23:44.726719 #8978]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:23:44.726774 #8978]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:23:45.363034 #8978]  INFO -- : Successful send a message
I, [2025-12-09T16:23:45.363119 #8978]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:23:45.363146 #8978]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T16:23:45.363176 #8978] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T16:23:45.363196 #8978] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smart_search.rb:3:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:133:in `search_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:57:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T16:31:12.657682 #11601]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:31:12.657779 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657847 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657857 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657867 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657871 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657878 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657882 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657906 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657911 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657917 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657921 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657927 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657931 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657942 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657946 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657955 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.657959 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.657968 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722080 #11601]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:31:12.722147 #11601]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:31:12.722517 #11601]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:31:12.722564 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722594 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722599 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722606 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722610 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722616 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722620 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722646 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722650 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722660 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722664 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722670 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722674 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722684 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722688 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722697 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722701 #11601]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:31:12.722711 #11601]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:31:12.722980 #11601]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:31:12.723003 #11601]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:31:50.339724 #11601]  INFO -- : Calling worker: pre_search with params: {:text=>"esp idf i2s  api", :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}], :with_history=>true}
I, [2025-12-09T16:31:50.339821 #11601]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:31:50.339836 #11601]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:31:50.339856 #11601]  INFO -- : Create Conversation
I, [2025-12-09T16:31:50.339893 #11601]  INFO -- : Use template pre_search
I, [2025-12-09T16:31:50.340284 #11601]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:31:50.340313 #11601]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:31:50.869998 #11601]  INFO -- : Successful send a message
I, [2025-12-09T16:31:50.870159 #11601]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:31:50.870298 #11601]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T16:31:50.870588 #11601] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T16:31:50.870635 #11601] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smart_search.rb:3:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:133:in `search_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:57:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T16:32:24.950817 #11601]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf i2sapi", :with_history=>true}
I, [2025-12-09T16:32:24.950826 #11601]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T16:32:24.950832 #11601]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T16:32:24.950841 #11601]  INFO -- : Create Conversation
I, [2025-12-09T16:32:24.950868 #11601]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T16:32:24.951147 #11601]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:32:24.951176 #11601]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:32:32.701621 #11601]  INFO -- : Successful send a message
I, [2025-12-09T16:32:32.701747 #11601]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:32:32.701777 #11601]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T16:32:33.304224 #11601]  INFO -- : Calling worker: pre_search with params: {:text=>"- ****  \n  - ****ESP-IDF I2SAPI  \n  - ****APII2SAPI  \n\n- ****  \n  - ****ESP-IDFI2S API  \n  - ****ESP-IDFv5.xAPIv5.3+  \n  - ****Espressif  \n\n- ****  \n  - ****  \n    `ESP-IDF I2S API``esp_i2s``I2S driver API`  \n  - ****  \n    `i2s_config_t``i2s_driver_install``i2s_write``i2s_read``i2s_pin_config_t``I2S_MODE_MASTER`  \n  - ****  \n    - `site:docs.espressif.com \"I2S API\"`  \n    - `site:docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/audio/i2s.html`  \n    - `intitle:\"I2S\" \"ESP-IDF\" filetype:rst`RSTESP-IDF  \n    - `site:github.com/espressif/esp-idf \"i2s\" \"api\"`  \n  - ****  \n    `-forum -stackoverflow -blog -tutorial`  \n\n- ****  \n  - ****  \n    Espressif `ESP-IDF  Audio  I2S Driver` URL `/projects/esp-idf/en/latest/esp32/api-reference/audio/i2s.html`API  \n  - ****  \n    - GitHub `esp-idf/components/driver/i2s.c`  `i2s.h` API  \n    - Espressif `examples/peripherals/i2s` `main.c`API  \n  - ****  \n    - ****APIESP-IDF v3.x `i2s_init()`  \n    - ****I2S APIAPIPCMDACdriverapplication  \n    - ****ESP32ESP32-S3I2SAPIESP32  \n\n>  ******EspressifI2S** + ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T16:32:33.304380 #11601]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:32:33.304435 #11601]  INFO -- : Use template pre_search
I, [2025-12-09T16:32:33.305169 #11601]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:32:33.305236 #11601]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:32:36.022802 #11601]  INFO -- : Successful send a message
I, [2025-12-09T16:32:36.022878 #11601]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:32:36.022898 #11601]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T16:32:36.022919 #11601] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T16:32:36.022933 #11601] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T16:36:25.672269 #13091]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:36:25.672354 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672397 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672404 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672413 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672417 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672424 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672428 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672482 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672501 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672513 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672519 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672528 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672533 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672546 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672550 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672559 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.672564 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.672572 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737313 #13091]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:36:25.737381 #13091]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:36:25.737754 #13091]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:36:25.737788 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737810 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737815 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737822 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737826 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737836 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737840 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737861 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737865 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737872 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737876 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737882 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737885 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737896 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737900 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737909 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.737913 #13091]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:36:25.737922 #13091]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:36:25.738148 #13091]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:36:25.738171 #13091]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:36:36.929324 #13091]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-09T16:36:36.929347 #13091]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T16:36:36.929355 #13091]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T16:36:36.929370 #13091]  INFO -- : Create Conversation
I, [2025-12-09T16:36:36.929402 #13091]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T16:36:36.929803 #13091]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:36:36.929839 #13091]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:36:46.289693 #13091]  INFO -- : Successful send a message
I, [2025-12-09T16:36:46.289798 #13091]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:36:46.289828 #13091]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T16:36:48.470256 #13091]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **\n\n- ****** / **  \n  ****\n\n- ****\n  - AI\n  - \n  - \n\n>  ********  \n> ****\n\n---\n\n### **2. **\n\n- ****   \n  \n\n- ****   \n  \n\n- ****  \n  \n\n- ****  \n  \n\n>  ************\n\n---\n\n### **3. **\n\n- ****  \n    ``, ``, ``\n\n- ****  \n  -   \n  -   \n  - NLU  \n  - AI\n\n- ****  \n  ```  \n  \"user says hello\" site:researchgate.net  \n  \"how to handle 'hello' in chatbots\" filetype:pdf  \n  intitle:\"conversational AI\" intitle:\"initial greeting\"  \n  ```\n\n- ****  \n  ``, ``, ``, ``  \n\n>  ********AI\n\n---\n\n### **4. **\n\n- ****  \n  ****  \n   /  \n   `chatbot greeting response strategies`, `NLU for ambiguous user inputs`\n\n- ****  \n  -  vs Hello  \n  -   \n  - Siri\n\n- ****  \n  -  ****  \n  -    \n  -  \n\n>  ****  \n> ********  \n>   \n> *  *\n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| **** |     |\n| **** |   |\n| **** | //// |\n| **** | AI |\n| **** | `greeting`, `ambiguous input`, `user intent clarification` |\n\n---\n\n>  ****  \n>   \n> ********\n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}, {:type=>"function", :function=>{"name"=>"company-search", "description"=>"Research companies - performs targeted searches of company websites to gather comprehensive information about businesses. Returns detailed information from company websites including about pages, pricing, FAQs, blogs, and other relevant content. Specify the company URL and optionally target specific sections of their website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"query"=>{:type=>"string", :description=>"Company website URL (e.g., 'dephy.io' or 'https://dephy.io'"}, "subpageTarget"=>{:type=>"array", :description=>"Specific sections to target (e.g., ['about', 'pricing', 'faq', 'blog']). If not provided, will crawl the most relevant pages."}, "subpages"=>{:type=>"integer", :description=>"Number of subpages to crawl (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"competitor-finder", "description"=>"Find competitors of a company - performs targeted searches to identify businesses that offer similar products or services. Describe what the company does (without mentioning its name) and optionally provide the company's website to exclude it from results.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"excludeDomain"=>{:type=>"string", :description=>"Optional: The company's website to exclude from results (e.g., 'dephy.io')"}, "numResults"=>{:type=>"integer", :description=>"Number of competitors to return (default: 10)"}, "query"=>{:type=>"string", :description=>"Describe what the company/product in a few words (e.g., 'web search API', 'AI image generation', 'cloud storage service'). Keep it simple. Do not include the company name.'"}}}}}, {:type=>"function", :function=>{"name"=>"convert_time", "description"=>"Convert time between timezones", "parameters"=>{"type"=>"object", "required"=>["source_timezone", "time", "target_timezone"], "properties"=>{"source_timezone"=>{:type=>"string", :description=>"Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no source timezone provided by the user."}, "target_timezone"=>{:type=>"string", :description=>"Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Local' as local timezone if no target timezone provided by the user."}, "time"=>{:type=>"string", :description=>"Time to convert in 24-hour format (HH:MM)"}}}}}, {:type=>"function", :function=>{"name"=>"get_current_time", "description"=>"Get current time in a specific timezones", "parameters"=>{"type"=>"object", "required"=>["timezone"], "properties"=>{"timezone"=>{:type=>"string", :description=>"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no timezone provided by the user."}}}}}, {:type=>"function", :function=>{"name"=>"get_dev_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_activities", "description"=>"\n    \n\n    Args:\n        token: \n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"address"=>{:type=>nil, :description=>nil}, "token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_basic_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_events", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_extra_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_launchpad", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_pool_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_price", "description"=>"\n    \n\n    Args:\n        tokens: \n    ", "parameters"=>{"type"=>"object", "required"=>["tokens"], "properties"=>{"tokens"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_stats", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_holders", "description"=>"\n    100\n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_traders", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_activities", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_association", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_flow", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_holding_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_labels", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_sol_balance", "description"=>"\n    SOL\n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_token_balance", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"linkedin-search", "description"=>"Search LinkedIn for companies - Simply include company URL, or company name, with 'company page' appended in your query", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"numResults"=>{:type=>"integer", :description=>"Number of search results to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Search query for LinkedIn (e.g., <url> company page OR <company name> company page)."}}}}}, {:type=>"function", :function=>{"name"=>"maps_directions", "description"=>"Get directions between two points", "parameters"=>{"type"=>"object", "required"=>["origin", "destination"], "properties"=>{"destination"=>{:type=>"string", :description=>"Ending point address or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origin"=>{:type=>"string", :description=>"Starting point address or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_distance_matrix", "description"=>"Calculate travel distance and time for multiple origins and destinations", "parameters"=>{"type"=>"object", "required"=>["origins", "destinations"], "properties"=>{"destinations"=>{:type=>"array", :description=>"Array of destination addresses or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origins"=>{:type=>"array", :description=>"Array of origin addresses or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_elevation", "description"=>"Get elevation data for locations on the earth", "parameters"=>{"type"=>"object", "required"=>["locations"], "properties"=>{"locations"=>{:type=>"array", :description=>"Array of locations to get elevation for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_geocode", "description"=>"Convert an address into geographic coordinates", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>"The address to geocode"}}}}}, {:type=>"function", :function=>{"name"=>"maps_place_details", "description"=>"Get detailed information about a specific place", "parameters"=>{"type"=>"object", "required"=>["place_id"], "properties"=>{"place_id"=>{:type=>"string", :description=>"The place ID to get details for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_reverse_geocode", "description"=>"Convert coordinates into an address", "parameters"=>{"type"=>"object", "required"=>["latitude", "longitude"], "properties"=>{"latitude"=>{:type=>"number", :description=>"Latitude coordinate"}, "longitude"=>{:type=>"number", :description=>"Longitude coordinate"}}}}}, {:type=>"function", :function=>{"name"=>"maps_search_places", "description"=>"Search for places using Google Places API", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"location"=>{:type=>"object", :description=>"Optional center point for the search"}, "query"=>{:type=>"string", :description=>"Search query"}, "radius"=>{:type=>"number", :description=>"Search radius in meters (max 50000)"}}}}}, {:type=>"function", :function=>{"name"=>"research-paper-search", "description"=>"Search across 100M+ research papers with full text access - performs targeted academic paper searches with deep research content coverage. Returns detailed information about relevant academic papers including titles, authors, publication dates, and full text excerpts. Control the number of results and character counts returned to balance comprehensiveness with conciseness based on your task requirements.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"maxCharacters"=>{:type=>"integer", :description=>"Maximum number of characters to return for each result's text content (Default: 3000)"}, "numResults"=>{:type=>"integer", :description=>"Number of research papers to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Research topic or keyword to search for"}}}}}, {:type=>"function", :function=>{"name"=>"scrape", "description"=>"Scrape a single webpage with advanced options for content extraction. Supports various formats including markdown and HTML. ", "parameters"=>{"type"=>"object", "required"=>["url"], "properties"=>{"url"=>{:type=>"string", :description=>"The URL of the webpage to scrape."}}}}}, {:type=>"function", :function=>{"name"=>"search", "description"=>"Performs a web search using the Google Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. To narrow your results in specific ways, you can use special operators in your search. Do not put spaces between the operator and your search term. A search for \"site:nytimes.com\" will work, but \"site: nytimes.com\" won't. The \"site:\" operator only accept one website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"num"=>{:type=>"integer", :description=>"The number of results to return"}, "query"=>{:type=>"string", :description=>"The search query string"}}}}}, {:type=>"function", :function=>{"name"=>"search_token", "description"=>"\n    \n\n    Args:\n        text: \n    ", "parameters"=>{"type"=>"object", "required"=>["text"], "properties"=>{"text"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"sequentialthinking", "description"=>"A detailed tool for dynamic and reflective problem-solving through thoughts.\nThis tool helps analyze problems through a flexible thinking process that can adapt and evolve.\nEach thought can build on, question, or revise previous insights as understanding deepens.\n\nWhen to use this tool:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Problems that require a multi-step solution\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\nKey features:\n- You can adjust total_thoughts up or down as you progress\n- You can question or revise previous thoughts\n- You can add more thoughts even after reaching what seemed like the end\n- You can express uncertainty and explore alternative approaches\n- Not every thought needs to build linearly - you can branch or backtrack\n- Generates a solution hypothesis\n- Verifies the hypothesis based on the Chain of Thought steps\n- Repeats the process until satisfied\n- Provides a correct answer\n\nParameters explained:\n- thought: Your current thinking step, which can include:\n* Regular analytical steps\n* Revisions of previous thoughts\n* Questions about previous decisions\n* Realizations about needing more analysis\n* Changes in approach\n* Hypothesis generation\n* Hypothesis verification\n- next_thought_needed: True if you need more thinking, even if at what seemed like the end\n- thought_number: Current number in sequence (can go beyond initial total if needed)\n- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)\n- is_revision: A boolean indicating if this thought revises previous thinking\n- revises_thought: If is_revision is true, which thought number is being reconsidered\n- branch_from_thought: If branching, which thought number is the branching point\n- branch_id: Identifier for the current branch (if any)\n- needs_more_thoughts: If reaching end but realizing more thoughts needed\n\nYou should:\n1. Start with an initial estimate of needed thoughts, but be ready to adjust\n2. Feel free to question or revise previous thoughts\n3. Don't hesitate to add more thoughts if needed, even at the \"end\"\n4. Express uncertainty when present\n5. Mark thoughts that revise previous thinking or branch into new paths\n6. Ignore information that is irrelevant to the current step\n7. Generate a solution hypothesis when appropriate\n8. Verify the hypothesis based on the Chain of Thought steps\n9. Repeat the process until satisfied with the solution\n10. Provide a single, ideally correct answer as the final output\n11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached", "parameters"=>{"type"=>"object", "required"=>["thought", "nextThoughtNeeded", "thoughtNumber", "totalThoughts"], "properties"=>{"branchFromThought"=>{:type=>"integer", :description=>"Branching point thought number"}, "branchId"=>{:type=>"string", :description=>"Branch identifier"}, "isRevision"=>{:type=>"boolean", :description=>"Whether this revises previous thinking"}, "needsMoreThoughts"=>{:type=>"boolean", :description=>"If more thoughts are needed"}, "nextThoughtNeeded"=>{:type=>"boolean", :description=>"Whether another thought step is needed"}, "revisesThought"=>{:type=>"integer", :description=>"Which thought is being reconsidered"}, "thought"=>{:type=>"string", :description=>"Your current thinking step"}, "thoughtNumber"=>{:type=>"integer", :description=>"Current thought number"}, "totalThoughts"=>{:type=>"integer", :description=>"Estimated total thoughts needed"}}}}}]}
I, [2025-12-09T16:36:48.470500 #13091]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:36:48.470525 #13091]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:36:48.470541 #13091]  INFO -- : Create Conversation
I, [2025-12-09T16:36:48.470580 #13091]  INFO -- : Use template pre_search
I, [2025-12-09T16:36:48.471153 #13091]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:36:48.471205 #13091]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:36:50.941377 #13091]  INFO -- : Successful send a message
I, [2025-12-09T16:36:50.941491 #13091]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:36:50.941520 #13091]  INFO -- : Worker pre_search executed successfully
I, [2025-12-09T16:36:53.206769 #13091]  INFO -- : Calling worker: smart_search with params: {:text=>"****\n\n---\n\n###  \n\n- ****  \n  - []   \n\n- ****  \n  - []   \n\n- ****  \n  - []   \n\n- ****  \n  - []   \n\n---\n\n###  \n\n\n- \n- Python\n- 2025AI\n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}, {:type=>"function", :function=>{"name"=>"company-search", "description"=>"Research companies - performs targeted searches of company websites to gather comprehensive information about businesses. Returns detailed information from company websites including about pages, pricing, FAQs, blogs, and other relevant content. Specify the company URL and optionally target specific sections of their website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"query"=>{:type=>"string", :description=>"Company website URL (e.g., 'dephy.io' or 'https://dephy.io'"}, "subpageTarget"=>{:type=>"array", :description=>"Specific sections to target (e.g., ['about', 'pricing', 'faq', 'blog']). If not provided, will crawl the most relevant pages."}, "subpages"=>{:type=>"integer", :description=>"Number of subpages to crawl (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"competitor-finder", "description"=>"Find competitors of a company - performs targeted searches to identify businesses that offer similar products or services. Describe what the company does (without mentioning its name) and optionally provide the company's website to exclude it from results.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"excludeDomain"=>{:type=>"string", :description=>"Optional: The company's website to exclude from results (e.g., 'dephy.io')"}, "numResults"=>{:type=>"integer", :description=>"Number of competitors to return (default: 10)"}, "query"=>{:type=>"string", :description=>"Describe what the company/product in a few words (e.g., 'web search API', 'AI image generation', 'cloud storage service'). Keep it simple. Do not include the company name.'"}}}}}, {:type=>"function", :function=>{"name"=>"convert_time", "description"=>"Convert time between timezones", "parameters"=>{"type"=>"object", "required"=>["source_timezone", "time", "target_timezone"], "properties"=>{"source_timezone"=>{:type=>"string", :description=>"Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no source timezone provided by the user."}, "target_timezone"=>{:type=>"string", :description=>"Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Local' as local timezone if no target timezone provided by the user."}, "time"=>{:type=>"string", :description=>"Time to convert in 24-hour format (HH:MM)"}}}}}, {:type=>"function", :function=>{"name"=>"get_current_time", "description"=>"Get current time in a specific timezones", "parameters"=>{"type"=>"object", "required"=>["timezone"], "properties"=>{"timezone"=>{:type=>"string", :description=>"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no timezone provided by the user."}}}}}, {:type=>"function", :function=>{"name"=>"get_dev_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_activities", "description"=>"\n    \n\n    Args:\n        token: \n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"address"=>{:type=>nil, :description=>nil}, "token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_basic_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_events", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_extra_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_launchpad", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_pool_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_price", "description"=>"\n    \n\n    Args:\n        tokens: \n    ", "parameters"=>{"type"=>"object", "required"=>["tokens"], "properties"=>{"tokens"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_stats", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_holders", "description"=>"\n    100\n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_traders", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_activities", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_association", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_flow", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_holding_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_labels", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_sol_balance", "description"=>"\n    SOL\n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_token_balance", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"linkedin-search", "description"=>"Search LinkedIn for companies - Simply include company URL, or company name, with 'company page' appended in your query", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"numResults"=>{:type=>"integer", :description=>"Number of search results to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Search query for LinkedIn (e.g., <url> company page OR <company name> company page)."}}}}}, {:type=>"function", :function=>{"name"=>"maps_directions", "description"=>"Get directions between two points", "parameters"=>{"type"=>"object", "required"=>["origin", "destination"], "properties"=>{"destination"=>{:type=>"string", :description=>"Ending point address or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origin"=>{:type=>"string", :description=>"Starting point address or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_distance_matrix", "description"=>"Calculate travel distance and time for multiple origins and destinations", "parameters"=>{"type"=>"object", "required"=>["origins", "destinations"], "properties"=>{"destinations"=>{:type=>"array", :description=>"Array of destination addresses or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origins"=>{:type=>"array", :description=>"Array of origin addresses or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_elevation", "description"=>"Get elevation data for locations on the earth", "parameters"=>{"type"=>"object", "required"=>["locations"], "properties"=>{"locations"=>{:type=>"array", :description=>"Array of locations to get elevation for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_geocode", "description"=>"Convert an address into geographic coordinates", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>"The address to geocode"}}}}}, {:type=>"function", :function=>{"name"=>"maps_place_details", "description"=>"Get detailed information about a specific place", "parameters"=>{"type"=>"object", "required"=>["place_id"], "properties"=>{"place_id"=>{:type=>"string", :description=>"The place ID to get details for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_reverse_geocode", "description"=>"Convert coordinates into an address", "parameters"=>{"type"=>"object", "required"=>["latitude", "longitude"], "properties"=>{"latitude"=>{:type=>"number", :description=>"Latitude coordinate"}, "longitude"=>{:type=>"number", :description=>"Longitude coordinate"}}}}}, {:type=>"function", :function=>{"name"=>"maps_search_places", "description"=>"Search for places using Google Places API", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"location"=>{:type=>"object", :description=>"Optional center point for the search"}, "query"=>{:type=>"string", :description=>"Search query"}, "radius"=>{:type=>"number", :description=>"Search radius in meters (max 50000)"}}}}}, {:type=>"function", :function=>{"name"=>"research-paper-search", "description"=>"Search across 100M+ research papers with full text access - performs targeted academic paper searches with deep research content coverage. Returns detailed information about relevant academic papers including titles, authors, publication dates, and full text excerpts. Control the number of results and character counts returned to balance comprehensiveness with conciseness based on your task requirements.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"maxCharacters"=>{:type=>"integer", :description=>"Maximum number of characters to return for each result's text content (Default: 3000)"}, "numResults"=>{:type=>"integer", :description=>"Number of research papers to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Research topic or keyword to search for"}}}}}, {:type=>"function", :function=>{"name"=>"scrape", "description"=>"Scrape a single webpage with advanced options for content extraction. Supports various formats including markdown and HTML. ", "parameters"=>{"type"=>"object", "required"=>["url"], "properties"=>{"url"=>{:type=>"string", :description=>"The URL of the webpage to scrape."}}}}}, {:type=>"function", :function=>{"name"=>"search", "description"=>"Performs a web search using the Google Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. To narrow your results in specific ways, you can use special operators in your search. Do not put spaces between the operator and your search term. A search for \"site:nytimes.com\" will work, but \"site: nytimes.com\" won't. The \"site:\" operator only accept one website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"num"=>{:type=>"integer", :description=>"The number of results to return"}, "query"=>{:type=>"string", :description=>"The search query string"}}}}}, {:type=>"function", :function=>{"name"=>"search_token", "description"=>"\n    \n\n    Args:\n        text: \n    ", "parameters"=>{"type"=>"object", "required"=>["text"], "properties"=>{"text"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"sequentialthinking", "description"=>"A detailed tool for dynamic and reflective problem-solving through thoughts.\nThis tool helps analyze problems through a flexible thinking process that can adapt and evolve.\nEach thought can build on, question, or revise previous insights as understanding deepens.\n\nWhen to use this tool:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Problems that require a multi-step solution\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\nKey features:\n- You can adjust total_thoughts up or down as you progress\n- You can question or revise previous thoughts\n- You can add more thoughts even after reaching what seemed like the end\n- You can express uncertainty and explore alternative approaches\n- Not every thought needs to build linearly - you can branch or backtrack\n- Generates a solution hypothesis\n- Verifies the hypothesis based on the Chain of Thought steps\n- Repeats the process until satisfied\n- Provides a correct answer\n\nParameters explained:\n- thought: Your current thinking step, which can include:\n* Regular analytical steps\n* Revisions of previous thoughts\n* Questions about previous decisions\n* Realizations about needing more analysis\n* Changes in approach\n* Hypothesis generation\n* Hypothesis verification\n- next_thought_needed: True if you need more thinking, even if at what seemed like the end\n- thought_number: Current number in sequence (can go beyond initial total if needed)\n- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)\n- is_revision: A boolean indicating if this thought revises previous thinking\n- revises_thought: If is_revision is true, which thought number is being reconsidered\n- branch_from_thought: If branching, which thought number is the branching point\n- branch_id: Identifier for the current branch (if any)\n- needs_more_thoughts: If reaching end but realizing more thoughts needed\n\nYou should:\n1. Start with an initial estimate of needed thoughts, but be ready to adjust\n2. Feel free to question or revise previous thoughts\n3. Don't hesitate to add more thoughts if needed, even at the \"end\"\n4. Express uncertainty when present\n5. Mark thoughts that revise previous thinking or branch into new paths\n6. Ignore information that is irrelevant to the current step\n7. Generate a solution hypothesis when appropriate\n8. Verify the hypothesis based on the Chain of Thought steps\n9. Repeat the process until satisfied with the solution\n10. Provide a single, ideally correct answer as the final output\n11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached", "parameters"=>{"type"=>"object", "required"=>["thought", "nextThoughtNeeded", "thoughtNumber", "totalThoughts"], "properties"=>{"branchFromThought"=>{:type=>"integer", :description=>"Branching point thought number"}, "branchId"=>{:type=>"string", :description=>"Branch identifier"}, "isRevision"=>{:type=>"boolean", :description=>"Whether this revises previous thinking"}, "needsMoreThoughts"=>{:type=>"boolean", :description=>"If more thoughts are needed"}, "nextThoughtNeeded"=>{:type=>"boolean", :description=>"Whether another thought step is needed"}, "revisesThought"=>{:type=>"integer", :description=>"Which thought is being reconsidered"}, "thought"=>{:type=>"string", :description=>"Your current thinking step"}, "thoughtNumber"=>{:type=>"integer", :description=>"Current thought number"}, "totalThoughts"=>{:type=>"integer", :description=>"Estimated total thoughts needed"}}}}}]}
I, [2025-12-09T16:36:53.206937 #13091]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-09T16:36:53.206976 #13091]  INFO -- : Create worker's name is smart_search
I, [2025-12-09T16:36:53.206994 #13091]  INFO -- : Create Conversation
I, [2025-12-09T16:36:53.207026 #13091]  INFO -- : Use template smart_search
I, [2025-12-09T16:36:53.207327 #13091]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:36:53.207372 #13091]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:36:53.685788 #13091]  INFO -- : Successful send a message
I, [2025-12-09T16:36:53.685866 #13091]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:36:53.685881 #13091]  INFO -- : Worker smart_search executed successfully
I, [2025-12-09T16:36:53.687354 #13091]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}, {:type=>"function", :function=>{"name"=>"company-search", "description"=>"Research companies - performs targeted searches of company websites to gather comprehensive information about businesses. Returns detailed information from company websites including about pages, pricing, FAQs, blogs, and other relevant content. Specify the company URL and optionally target specific sections of their website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"query"=>{:type=>"string", :description=>"Company website URL (e.g., 'dephy.io' or 'https://dephy.io'"}, "subpageTarget"=>{:type=>"array", :description=>"Specific sections to target (e.g., ['about', 'pricing', 'faq', 'blog']). If not provided, will crawl the most relevant pages."}, "subpages"=>{:type=>"integer", :description=>"Number of subpages to crawl (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"competitor-finder", "description"=>"Find competitors of a company - performs targeted searches to identify businesses that offer similar products or services. Describe what the company does (without mentioning its name) and optionally provide the company's website to exclude it from results.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"excludeDomain"=>{:type=>"string", :description=>"Optional: The company's website to exclude from results (e.g., 'dephy.io')"}, "numResults"=>{:type=>"integer", :description=>"Number of competitors to return (default: 10)"}, "query"=>{:type=>"string", :description=>"Describe what the company/product in a few words (e.g., 'web search API', 'AI image generation', 'cloud storage service'). Keep it simple. Do not include the company name.'"}}}}}, {:type=>"function", :function=>{"name"=>"convert_time", "description"=>"Convert time between timezones", "parameters"=>{"type"=>"object", "required"=>["source_timezone", "time", "target_timezone"], "properties"=>{"source_timezone"=>{:type=>"string", :description=>"Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no source timezone provided by the user."}, "target_timezone"=>{:type=>"string", :description=>"Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Local' as local timezone if no target timezone provided by the user."}, "time"=>{:type=>"string", :description=>"Time to convert in 24-hour format (HH:MM)"}}}}}, {:type=>"function", :function=>{"name"=>"get_current_time", "description"=>"Get current time in a specific timezones", "parameters"=>{"type"=>"object", "required"=>["timezone"], "properties"=>{"timezone"=>{:type=>"string", :description=>"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no timezone provided by the user."}}}}}, {:type=>"function", :function=>{"name"=>"get_dev_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_activities", "description"=>"\n    \n\n    Args:\n        token: \n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"address"=>{:type=>nil, :description=>nil}, "token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_basic_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_events", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_extra_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_launchpad", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_pool_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_price", "description"=>"\n    \n\n    Args:\n        tokens: \n    ", "parameters"=>{"type"=>"object", "required"=>["tokens"], "properties"=>{"tokens"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_stats", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_holders", "description"=>"\n    100\n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_traders", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_activities", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_association", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_flow", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_holding_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_labels", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_sol_balance", "description"=>"\n    SOL\n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_token_balance", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"linkedin-search", "description"=>"Search LinkedIn for companies - Simply include company URL, or company name, with 'company page' appended in your query", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"numResults"=>{:type=>"integer", :description=>"Number of search results to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Search query for LinkedIn (e.g., <url> company page OR <company name> company page)."}}}}}, {:type=>"function", :function=>{"name"=>"maps_directions", "description"=>"Get directions between two points", "parameters"=>{"type"=>"object", "required"=>["origin", "destination"], "properties"=>{"destination"=>{:type=>"string", :description=>"Ending point address or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origin"=>{:type=>"string", :description=>"Starting point address or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_distance_matrix", "description"=>"Calculate travel distance and time for multiple origins and destinations", "parameters"=>{"type"=>"object", "required"=>["origins", "destinations"], "properties"=>{"destinations"=>{:type=>"array", :description=>"Array of destination addresses or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origins"=>{:type=>"array", :description=>"Array of origin addresses or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_elevation", "description"=>"Get elevation data for locations on the earth", "parameters"=>{"type"=>"object", "required"=>["locations"], "properties"=>{"locations"=>{:type=>"array", :description=>"Array of locations to get elevation for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_geocode", "description"=>"Convert an address into geographic coordinates", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>"The address to geocode"}}}}}, {:type=>"function", :function=>{"name"=>"maps_place_details", "description"=>"Get detailed information about a specific place", "parameters"=>{"type"=>"object", "required"=>["place_id"], "properties"=>{"place_id"=>{:type=>"string", :description=>"The place ID to get details for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_reverse_geocode", "description"=>"Convert coordinates into an address", "parameters"=>{"type"=>"object", "required"=>["latitude", "longitude"], "properties"=>{"latitude"=>{:type=>"number", :description=>"Latitude coordinate"}, "longitude"=>{:type=>"number", :description=>"Longitude coordinate"}}}}}, {:type=>"function", :function=>{"name"=>"maps_search_places", "description"=>"Search for places using Google Places API", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"location"=>{:type=>"object", :description=>"Optional center point for the search"}, "query"=>{:type=>"string", :description=>"Search query"}, "radius"=>{:type=>"number", :description=>"Search radius in meters (max 50000)"}}}}}, {:type=>"function", :function=>{"name"=>"research-paper-search", "description"=>"Search across 100M+ research papers with full text access - performs targeted academic paper searches with deep research content coverage. Returns detailed information about relevant academic papers including titles, authors, publication dates, and full text excerpts. Control the number of results and character counts returned to balance comprehensiveness with conciseness based on your task requirements.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"maxCharacters"=>{:type=>"integer", :description=>"Maximum number of characters to return for each result's text content (Default: 3000)"}, "numResults"=>{:type=>"integer", :description=>"Number of research papers to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Research topic or keyword to search for"}}}}}, {:type=>"function", :function=>{"name"=>"scrape", "description"=>"Scrape a single webpage with advanced options for content extraction. Supports various formats including markdown and HTML. ", "parameters"=>{"type"=>"object", "required"=>["url"], "properties"=>{"url"=>{:type=>"string", :description=>"The URL of the webpage to scrape."}}}}}, {:type=>"function", :function=>{"name"=>"search", "description"=>"Performs a web search using the Google Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. To narrow your results in specific ways, you can use special operators in your search. Do not put spaces between the operator and your search term. A search for \"site:nytimes.com\" will work, but \"site: nytimes.com\" won't. The \"site:\" operator only accept one website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"num"=>{:type=>"integer", :description=>"The number of results to return"}, "query"=>{:type=>"string", :description=>"The search query string"}}}}}, {:type=>"function", :function=>{"name"=>"search_token", "description"=>"\n    \n\n    Args:\n        text: \n    ", "parameters"=>{"type"=>"object", "required"=>["text"], "properties"=>{"text"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"sequentialthinking", "description"=>"A detailed tool for dynamic and reflective problem-solving through thoughts.\nThis tool helps analyze problems through a flexible thinking process that can adapt and evolve.\nEach thought can build on, question, or revise previous insights as understanding deepens.\n\nWhen to use this tool:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Problems that require a multi-step solution\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\nKey features:\n- You can adjust total_thoughts up or down as you progress\n- You can question or revise previous thoughts\n- You can add more thoughts even after reaching what seemed like the end\n- You can express uncertainty and explore alternative approaches\n- Not every thought needs to build linearly - you can branch or backtrack\n- Generates a solution hypothesis\n- Verifies the hypothesis based on the Chain of Thought steps\n- Repeats the process until satisfied\n- Provides a correct answer\n\nParameters explained:\n- thought: Your current thinking step, which can include:\n* Regular analytical steps\n* Revisions of previous thoughts\n* Questions about previous decisions\n* Realizations about needing more analysis\n* Changes in approach\n* Hypothesis generation\n* Hypothesis verification\n- next_thought_needed: True if you need more thinking, even if at what seemed like the end\n- thought_number: Current number in sequence (can go beyond initial total if needed)\n- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)\n- is_revision: A boolean indicating if this thought revises previous thinking\n- revises_thought: If is_revision is true, which thought number is being reconsidered\n- branch_from_thought: If branching, which thought number is the branching point\n- branch_id: Identifier for the current branch (if any)\n- needs_more_thoughts: If reaching end but realizing more thoughts needed\n\nYou should:\n1. Start with an initial estimate of needed thoughts, but be ready to adjust\n2. Feel free to question or revise previous thoughts\n3. Don't hesitate to add more thoughts if needed, even at the \"end\"\n4. Express uncertainty when present\n5. Mark thoughts that revise previous thinking or branch into new paths\n6. Ignore information that is irrelevant to the current step\n7. Generate a solution hypothesis when appropriate\n8. Verify the hypothesis based on the Chain of Thought steps\n9. Repeat the process until satisfied with the solution\n10. Provide a single, ideally correct answer as the final output\n11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached", "parameters"=>{"type"=>"object", "required"=>["thought", "nextThoughtNeeded", "thoughtNumber", "totalThoughts"], "properties"=>{"branchFromThought"=>{:type=>"integer", :description=>"Branching point thought number"}, "branchId"=>{:type=>"string", :description=>"Branch identifier"}, "isRevision"=>{:type=>"boolean", :description=>"Whether this revises previous thinking"}, "needsMoreThoughts"=>{:type=>"boolean", :description=>"If more thoughts are needed"}, "nextThoughtNeeded"=>{:type=>"boolean", :description=>"Whether another thought step is needed"}, "revisesThought"=>{:type=>"integer", :description=>"Which thought is being reconsidered"}, "thought"=>{:type=>"string", :description=>"Your current thinking step"}, "thoughtNumber"=>{:type=>"integer", :description=>"Current thought number"}, "totalThoughts"=>{:type=>"integer", :description=>"Estimated total thoughts needed"}}}}}]}
I, [2025-12-09T16:36:53.687404 #13091]  INFO -- : Creating worker instance for: summary
I, [2025-12-09T16:36:53.687413 #13091]  INFO -- : Create worker's name is summary
I, [2025-12-09T16:36:53.687421 #13091]  INFO -- : Create Conversation
I, [2025-12-09T16:36:53.687437 #13091]  INFO -- : Use template summarize
I, [2025-12-09T16:36:53.687643 #13091]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:36:53.687666 #13091]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:36:59.803847 #13091]  INFO -- : Successful send a message
I, [2025-12-09T16:36:59.803989 #13091]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:36:59.804021 #13091]  INFO -- : Worker summary executed successfully
I, [2025-12-09T16:37:29.353817 #13566]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:37:29.353888 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.353917 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.353922 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.353931 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.353935 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.353941 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.353946 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.353969 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.353974 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.353981 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.353992 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.353997 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.354001 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.354014 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.354019 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.354028 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.354032 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.354042 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416280 #13566]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:37:29.416346 #13566]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:37:29.416699 #13566]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:37:29.416731 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416749 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416754 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416761 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416765 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416771 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416774 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416796 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416812 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416835 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416850 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416861 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416869 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416887 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416892 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416902 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.416906 #13566]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:37:29.416916 #13566]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:37:29.417181 #13566]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:37:29.417204 #13566]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:37:54.221611 #13566]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp-idfi2sapi", :with_history=>true}
I, [2025-12-09T16:37:54.221622 #13566]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T16:37:54.221632 #13566]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T16:37:54.221646 #13566]  INFO -- : Create Conversation
I, [2025-12-09T16:37:54.221683 #13566]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T16:37:54.222049 #13566]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:37:54.222083 #13566]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:38:06.588297 #13566]  INFO -- : Successful send a message
I, [2025-12-09T16:38:06.588404 #13566]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:38:06.588436 #13566]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T16:38:08.899239 #13566]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp-idfi2sapi** \n\n---\n\n### **1. **  \n ****  \n- ****API**ESP-IDFI2S**  \n- ****  \n- API****\n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** | ****  I2SESP-IDF |\n| **** | ****  ESP-IDFv4.x  v5.xAPI**** |\n| **** | ****  **Espressif** |\n\n>  ****GitHub\n\n---\n\n### **3. **  \n\n#### ****  \n- `ESP-IDF`  \n- `I2S`  \n- `API`  \n- `function` / `function list` / `interface`  \n- `example` / `usage` \n\n#### ****  \n- `I2S driver`ESP-IDFI2S  \n- `i2s_config_t`  \n- `i2s_install` / `i2s_write` / `i2s_read`  \n- `audio` / `DAC` / `ADC`I2S  \n- `DMA`I2SDMA\n\n#### ****  \n```plaintext\nsite:docs.espressif.com \"I2S\" API  \nsite:docs.espressif.com \"i2s_\" filetype:md  \nintitle:\"I2S\" \"ESP-IDF\" \"example\"  \n\"ESP-IDF\" \"I2S\" (\"function\" OR \"API\") -forum -stackoverflow  \n```\n\n>  ****  \n> `site:docs.espressif.com \"I2S\" driver API`  \n> `site:docs.espressif.com \"i2s_\" intitle:reference`\n\n#### ****  \n- `-forum`  \n- `-stackoverflow`  \n- `-arduino`ESP-IDF  Arduino  \n- `-tutorial`  \n- `-youtube`\n\n---\n\n### **4. **  \n\n#### ****  \n **Espressifdocs.espressif.com**  \n- `ESP-IDF Programming Guide  Peripherals  I2S`  \n- `I2S Driver`  \n  - `i2s_config_t`   \n  - `i2s_driver_install()`  \n  - `i2s_write()` / `i2s_read()`  \n  - `i2s_event_t`   \n  - `examples/peripherals/i2s/`\n\n#### ****  \n1. **GitHub**  \n   - `espressif/esp-idf examples i2s`  \n   - `/examples/peripherals/i2s/`  `i2s_pcm``i2s_stream`   \n2. **ESP-IDF API ReferenceHTML/PDF**  \n   - Ctrl+F `i2s_`  \n3. **Espressifforum.espressif.com**  \n   - i2s_write timeout  \n\n#### ****  \n **1**APIESP-IDFv4.4 vs v5.1  \n **** `ESP-IDF v5.1 I2S API`  \n\n **2**I2SI2CI2SInter-IC Sound  \n ****ESP-IDF  \n\n **3**/API `i2s_init()`  `i2s_driver_install()`  \n ********  \n\n---\n\n###  ****  \n1. **** [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/peripherals/i2s.html](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/peripherals/i2s.html)  \n2. **** `i2s_`  \n3. **** `examples/peripherals/i2s/`   \n4. ****GitHub `repo:espressif/esp-idf path:examples/peripherals/i2s`   \n5. ****GoogleESP32 I2S API `site:docs.espressif.com`\n\n---\n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}, {:type=>"function", :function=>{"name"=>"company-search", "description"=>"Research companies - performs targeted searches of company websites to gather comprehensive information about businesses. Returns detailed information from company websites including about pages, pricing, FAQs, blogs, and other relevant content. Specify the company URL and optionally target specific sections of their website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"query"=>{:type=>"string", :description=>"Company website URL (e.g., 'dephy.io' or 'https://dephy.io'"}, "subpageTarget"=>{:type=>"array", :description=>"Specific sections to target (e.g., ['about', 'pricing', 'faq', 'blog']). If not provided, will crawl the most relevant pages."}, "subpages"=>{:type=>"integer", :description=>"Number of subpages to crawl (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"competitor-finder", "description"=>"Find competitors of a company - performs targeted searches to identify businesses that offer similar products or services. Describe what the company does (without mentioning its name) and optionally provide the company's website to exclude it from results.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"excludeDomain"=>{:type=>"string", :description=>"Optional: The company's website to exclude from results (e.g., 'dephy.io')"}, "numResults"=>{:type=>"integer", :description=>"Number of competitors to return (default: 10)"}, "query"=>{:type=>"string", :description=>"Describe what the company/product in a few words (e.g., 'web search API', 'AI image generation', 'cloud storage service'). Keep it simple. Do not include the company name.'"}}}}}, {:type=>"function", :function=>{"name"=>"convert_time", "description"=>"Convert time between timezones", "parameters"=>{"type"=>"object", "required"=>["source_timezone", "time", "target_timezone"], "properties"=>{"source_timezone"=>{:type=>"string", :description=>"Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no source timezone provided by the user."}, "target_timezone"=>{:type=>"string", :description=>"Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Local' as local timezone if no target timezone provided by the user."}, "time"=>{:type=>"string", :description=>"Time to convert in 24-hour format (HH:MM)"}}}}}, {:type=>"function", :function=>{"name"=>"get_current_time", "description"=>"Get current time in a specific timezones", "parameters"=>{"type"=>"object", "required"=>["timezone"], "properties"=>{"timezone"=>{:type=>"string", :description=>"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no timezone provided by the user."}}}}}, {:type=>"function", :function=>{"name"=>"get_dev_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_activities", "description"=>"\n    \n\n    Args:\n        token: \n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"address"=>{:type=>nil, :description=>nil}, "token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_basic_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_events", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_extra_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_launchpad", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_pool_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_price", "description"=>"\n    \n\n    Args:\n        tokens: \n    ", "parameters"=>{"type"=>"object", "required"=>["tokens"], "properties"=>{"tokens"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_stats", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_holders", "description"=>"\n    100\n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_traders", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_activities", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_association", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_flow", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_holding_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_labels", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_sol_balance", "description"=>"\n    SOL\n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_token_balance", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"linkedin-search", "description"=>"Search LinkedIn for companies - Simply include company URL, or company name, with 'company page' appended in your query", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"numResults"=>{:type=>"integer", :description=>"Number of search results to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Search query for LinkedIn (e.g., <url> company page OR <company name> company page)."}}}}}, {:type=>"function", :function=>{"name"=>"maps_directions", "description"=>"Get directions between two points", "parameters"=>{"type"=>"object", "required"=>["origin", "destination"], "properties"=>{"destination"=>{:type=>"string", :description=>"Ending point address or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origin"=>{:type=>"string", :description=>"Starting point address or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_distance_matrix", "description"=>"Calculate travel distance and time for multiple origins and destinations", "parameters"=>{"type"=>"object", "required"=>["origins", "destinations"], "properties"=>{"destinations"=>{:type=>"array", :description=>"Array of destination addresses or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origins"=>{:type=>"array", :description=>"Array of origin addresses or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_elevation", "description"=>"Get elevation data for locations on the earth", "parameters"=>{"type"=>"object", "required"=>["locations"], "properties"=>{"locations"=>{:type=>"array", :description=>"Array of locations to get elevation for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_geocode", "description"=>"Convert an address into geographic coordinates", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>"The address to geocode"}}}}}, {:type=>"function", :function=>{"name"=>"maps_place_details", "description"=>"Get detailed information about a specific place", "parameters"=>{"type"=>"object", "required"=>["place_id"], "properties"=>{"place_id"=>{:type=>"string", :description=>"The place ID to get details for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_reverse_geocode", "description"=>"Convert coordinates into an address", "parameters"=>{"type"=>"object", "required"=>["latitude", "longitude"], "properties"=>{"latitude"=>{:type=>"number", :description=>"Latitude coordinate"}, "longitude"=>{:type=>"number", :description=>"Longitude coordinate"}}}}}, {:type=>"function", :function=>{"name"=>"maps_search_places", "description"=>"Search for places using Google Places API", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"location"=>{:type=>"object", :description=>"Optional center point for the search"}, "query"=>{:type=>"string", :description=>"Search query"}, "radius"=>{:type=>"number", :description=>"Search radius in meters (max 50000)"}}}}}, {:type=>"function", :function=>{"name"=>"research-paper-search", "description"=>"Search across 100M+ research papers with full text access - performs targeted academic paper searches with deep research content coverage. Returns detailed information about relevant academic papers including titles, authors, publication dates, and full text excerpts. Control the number of results and character counts returned to balance comprehensiveness with conciseness based on your task requirements.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"maxCharacters"=>{:type=>"integer", :description=>"Maximum number of characters to return for each result's text content (Default: 3000)"}, "numResults"=>{:type=>"integer", :description=>"Number of research papers to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Research topic or keyword to search for"}}}}}, {:type=>"function", :function=>{"name"=>"scrape", "description"=>"Scrape a single webpage with advanced options for content extraction. Supports various formats including markdown and HTML. ", "parameters"=>{"type"=>"object", "required"=>["url"], "properties"=>{"url"=>{:type=>"string", :description=>"The URL of the webpage to scrape."}}}}}, {:type=>"function", :function=>{"name"=>"search", "description"=>"Performs a web search using the Google Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. To narrow your results in specific ways, you can use special operators in your search. Do not put spaces between the operator and your search term. A search for \"site:nytimes.com\" will work, but \"site: nytimes.com\" won't. The \"site:\" operator only accept one website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"num"=>{:type=>"integer", :description=>"The number of results to return"}, "query"=>{:type=>"string", :description=>"The search query string"}}}}}, {:type=>"function", :function=>{"name"=>"search_token", "description"=>"\n    \n\n    Args:\n        text: \n    ", "parameters"=>{"type"=>"object", "required"=>["text"], "properties"=>{"text"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"sequentialthinking", "description"=>"A detailed tool for dynamic and reflective problem-solving through thoughts.\nThis tool helps analyze problems through a flexible thinking process that can adapt and evolve.\nEach thought can build on, question, or revise previous insights as understanding deepens.\n\nWhen to use this tool:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Problems that require a multi-step solution\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\nKey features:\n- You can adjust total_thoughts up or down as you progress\n- You can question or revise previous thoughts\n- You can add more thoughts even after reaching what seemed like the end\n- You can express uncertainty and explore alternative approaches\n- Not every thought needs to build linearly - you can branch or backtrack\n- Generates a solution hypothesis\n- Verifies the hypothesis based on the Chain of Thought steps\n- Repeats the process until satisfied\n- Provides a correct answer\n\nParameters explained:\n- thought: Your current thinking step, which can include:\n* Regular analytical steps\n* Revisions of previous thoughts\n* Questions about previous decisions\n* Realizations about needing more analysis\n* Changes in approach\n* Hypothesis generation\n* Hypothesis verification\n- next_thought_needed: True if you need more thinking, even if at what seemed like the end\n- thought_number: Current number in sequence (can go beyond initial total if needed)\n- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)\n- is_revision: A boolean indicating if this thought revises previous thinking\n- revises_thought: If is_revision is true, which thought number is being reconsidered\n- branch_from_thought: If branching, which thought number is the branching point\n- branch_id: Identifier for the current branch (if any)\n- needs_more_thoughts: If reaching end but realizing more thoughts needed\n\nYou should:\n1. Start with an initial estimate of needed thoughts, but be ready to adjust\n2. Feel free to question or revise previous thoughts\n3. Don't hesitate to add more thoughts if needed, even at the \"end\"\n4. Express uncertainty when present\n5. Mark thoughts that revise previous thinking or branch into new paths\n6. Ignore information that is irrelevant to the current step\n7. Generate a solution hypothesis when appropriate\n8. Verify the hypothesis based on the Chain of Thought steps\n9. Repeat the process until satisfied with the solution\n10. Provide a single, ideally correct answer as the final output\n11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached", "parameters"=>{"type"=>"object", "required"=>["thought", "nextThoughtNeeded", "thoughtNumber", "totalThoughts"], "properties"=>{"branchFromThought"=>{:type=>"integer", :description=>"Branching point thought number"}, "branchId"=>{:type=>"string", :description=>"Branch identifier"}, "isRevision"=>{:type=>"boolean", :description=>"Whether this revises previous thinking"}, "needsMoreThoughts"=>{:type=>"boolean", :description=>"If more thoughts are needed"}, "nextThoughtNeeded"=>{:type=>"boolean", :description=>"Whether another thought step is needed"}, "revisesThought"=>{:type=>"integer", :description=>"Which thought is being reconsidered"}, "thought"=>{:type=>"string", :description=>"Your current thinking step"}, "thoughtNumber"=>{:type=>"integer", :description=>"Current thought number"}, "totalThoughts"=>{:type=>"integer", :description=>"Estimated total thoughts needed"}}}}}]}
I, [2025-12-09T16:38:08.899365 #13566]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:38:08.899379 #13566]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:38:08.899390 #13566]  INFO -- : Create Conversation
I, [2025-12-09T16:38:08.899417 #13566]  INFO -- : Use template pre_search
I, [2025-12-09T16:38:08.899835 #13566]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:38:08.899869 #13566]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:38:10.810921 #13566]  INFO -- : Successful send a message
I, [2025-12-09T16:38:10.811021 #13566]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:38:10.811048 #13566]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T16:38:10.811096 #13566] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T16:38:10.811121 #13566] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T16:40:42.143151 #14448]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:40:42.143231 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143266 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143272 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143281 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143285 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143292 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143297 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143353 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143371 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143383 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143389 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143396 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143401 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143417 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143432 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143449 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.143456 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.143467 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.217606 #14448]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:40:42.217678 #14448]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:40:42.218084 #14448]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:40:42.218137 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218159 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218165 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218173 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218177 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218184 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218188 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218216 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218235 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218247 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218254 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218263 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218271 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218307 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218314 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218332 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218364 #14448]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:42.218382 #14448]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:42.218681 #14448]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:40:42.218712 #14448]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:40:48.410120 #14500]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:40:48.410199 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410236 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410242 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410251 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410256 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410262 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410266 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410298 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410303 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410310 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410314 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410320 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410324 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410335 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410426 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410474 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.410494 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.410512 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.482538 #14500]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:40:48.482612 #14500]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:40:48.482999 #14500]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:40:48.483039 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483066 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483073 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483080 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483084 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483090 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483094 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483117 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483122 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483129 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483133 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483139 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483143 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483153 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483157 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483166 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483170 #14500]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:40:48.483186 #14500]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:40:48.483414 #14500]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:40:48.483437 #14500]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:41:03.911449 #14500]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp-idfi2sapi", :with_history=>true}
I, [2025-12-09T16:41:03.911460 #14500]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T16:41:03.911471 #14500]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T16:41:03.911487 #14500]  INFO -- : Create Conversation
I, [2025-12-09T16:41:03.911525 #14500]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T16:41:03.912023 #14500]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:41:03.912063 #14500]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:41:20.579916 #14500]  INFO -- : Successful send a message
I, [2025-12-09T16:41:20.579997 #14500]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:41:20.580017 #14500]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T16:41:24.055530 #14500]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp-idfi2sapi** \n\n---\n\n### **1. **  \n ****  \n- ****I2SAPI**API**ESP-IDFI2S********\n- ********API****\n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** |  ****  ESP-IDF |\n| **** |  ****  ESP-IDFv4.x  v5.xAPI`i2s_driver_install`****v5.3+ |\n| **** |  ****  **EspressifGitHub** |\n\n---\n\n### **3. **  \n\n#### ****  \n- `ESP-IDF`  \n- `I2S`  \n- `API`  \n- `function` / `function list`  \n- `example` / `sample code`  \n\n#### ****  \n- `i2s_driver_install`  \n- `i2s_write` / `i2s_read`  \n- `i2s_config_t`  \n- `i2s_pin_config_t`  \n- `i2s_event_t`  \n- `i2s_zero_dma_buffer`  \n- `I2S_MODE_MASTER` / `I2S_MODE_SLAVE`  \n\n#### ****  \n```plaintext\nsite:docs.espressif.com \"i2s\" api  \nsite:docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/audio/i2s.html  \nintitle:\"I2S\" \"ESP-IDF\" example  \nfiletype:pdf \"ESP-IDF I2S API reference\"  \n\"i2s_driver_install\" site:github.com/espressif/esp-idf  \n```\n\n#### ****  \n- `Arduino`ESP-IDF  \n- `Raspberry Pi` / `STM32`  \n- `audio player` / `music`API  \n- `tutorial`  \n\n---\n\n### **4. **  \n\n#### ****  \n ****  \n> [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/audio/i2s.html](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/audio/i2s.html)  \n- **API**  \n- \n\n#### ****  \n ****GitHub  \n> [https://github.com/espressif/esp-idf/tree/master/examples/audio/i2s](https://github.com/espressif/esp-idf/tree/master/examples/audio/i2s)  \n-  `i2s_stream``i2s_pdm``i2s_tdm`   \n-  `main.c` \n\n ****  \n- ESP32[https://esp32.com/](https://esp32.com/)I2S API usage  \n- Stack Overflow`[esp-idf] i2s` + `function`  \n- CSDN\n\n#### ****  \n ****  \n- ESP-IDF v4.x  v5.x  `i2s_config_t`  `communication_format`  `mode`  \n- **** `ESP-IDF v5.3 i2s api`\n\n **API**  \n- `i2s_driver_install``i2s_pin_config_t`DMA  \n- ****`driver/i2s.h`GitHub Issues\n\n ****  \n- API`I2S_MODE_DAC_BUILT_IN`DACC\n\n---\n\n###  ****  \n1. ****[ESP-IDF I2SAPI](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/audio/i2s.html)  \n2. ****[I2S](https://github.com/espressif/esp-idf/tree/master/examples/audio/i2s)  \n3. ****GitHub `\"i2s_driver_install\" site:github.com/espressif/esp-idf`  \n4. ****  \n   - ESP-IDF  \n   - Arduino I2SESP-IDF  \n5. ****I2S`#define I2S_DEBUG` \n\n---\n\n****I2S API", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}, {:type=>"function", :function=>{"name"=>"company-search", "description"=>"Research companies - performs targeted searches of company websites to gather comprehensive information about businesses. Returns detailed information from company websites including about pages, pricing, FAQs, blogs, and other relevant content. Specify the company URL and optionally target specific sections of their website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"query"=>{:type=>"string", :description=>"Company website URL (e.g., 'dephy.io' or 'https://dephy.io'"}, "subpageTarget"=>{:type=>"array", :description=>"Specific sections to target (e.g., ['about', 'pricing', 'faq', 'blog']). If not provided, will crawl the most relevant pages."}, "subpages"=>{:type=>"integer", :description=>"Number of subpages to crawl (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"competitor-finder", "description"=>"Find competitors of a company - performs targeted searches to identify businesses that offer similar products or services. Describe what the company does (without mentioning its name) and optionally provide the company's website to exclude it from results.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"excludeDomain"=>{:type=>"string", :description=>"Optional: The company's website to exclude from results (e.g., 'dephy.io')"}, "numResults"=>{:type=>"integer", :description=>"Number of competitors to return (default: 10)"}, "query"=>{:type=>"string", :description=>"Describe what the company/product in a few words (e.g., 'web search API', 'AI image generation', 'cloud storage service'). Keep it simple. Do not include the company name.'"}}}}}, {:type=>"function", :function=>{"name"=>"convert_time", "description"=>"Convert time between timezones", "parameters"=>{"type"=>"object", "required"=>["source_timezone", "time", "target_timezone"], "properties"=>{"source_timezone"=>{:type=>"string", :description=>"Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no source timezone provided by the user."}, "target_timezone"=>{:type=>"string", :description=>"Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Local' as local timezone if no target timezone provided by the user."}, "time"=>{:type=>"string", :description=>"Time to convert in 24-hour format (HH:MM)"}}}}}, {:type=>"function", :function=>{"name"=>"get_current_time", "description"=>"Get current time in a specific timezones", "parameters"=>{"type"=>"object", "required"=>["timezone"], "properties"=>{"timezone"=>{:type=>"string", :description=>"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Local' as local timezone if no timezone provided by the user."}}}}}, {:type=>"function", :function=>{"name"=>"get_dev_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_activities", "description"=>"\n    \n\n    Args:\n        token: \n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"address"=>{:type=>nil, :description=>nil}, "token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_basic_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_events", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_extra_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_launchpad", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_pool_info", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_price", "description"=>"\n    \n\n    Args:\n        tokens: \n    ", "parameters"=>{"type"=>"object", "required"=>["tokens"], "properties"=>{"tokens"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_stats", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_holders", "description"=>"\n    100\n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_token_top_traders", "description"=>"\n    \n\n    Args:\n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["token"], "properties"=>{"token"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_activities", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_association", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_flow", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_holding_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_labels", "description"=>"\n    \n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_profits", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_sol_balance", "description"=>"\n    SOL\n\n    Args:\n        address: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"get_wallet_token_balance", "description"=>"\n    \n\n    Args:\n        address: \n        token: \n    ", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>nil}, "token"=>{:type=>nil, :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"linkedin-search", "description"=>"Search LinkedIn for companies - Simply include company URL, or company name, with 'company page' appended in your query", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"numResults"=>{:type=>"integer", :description=>"Number of search results to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Search query for LinkedIn (e.g., <url> company page OR <company name> company page)."}}}}}, {:type=>"function", :function=>{"name"=>"maps_directions", "description"=>"Get directions between two points", "parameters"=>{"type"=>"object", "required"=>["origin", "destination"], "properties"=>{"destination"=>{:type=>"string", :description=>"Ending point address or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origin"=>{:type=>"string", :description=>"Starting point address or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_distance_matrix", "description"=>"Calculate travel distance and time for multiple origins and destinations", "parameters"=>{"type"=>"object", "required"=>["origins", "destinations"], "properties"=>{"destinations"=>{:type=>"array", :description=>"Array of destination addresses or coordinates"}, "mode"=>{:type=>"string", :description=>"Travel mode (driving, walking, bicycling, transit)", "enum"=>["driving", "walking", "bicycling", "transit"]}, "origins"=>{:type=>"array", :description=>"Array of origin addresses or coordinates"}}}}}, {:type=>"function", :function=>{"name"=>"maps_elevation", "description"=>"Get elevation data for locations on the earth", "parameters"=>{"type"=>"object", "required"=>["locations"], "properties"=>{"locations"=>{:type=>"array", :description=>"Array of locations to get elevation for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_geocode", "description"=>"Convert an address into geographic coordinates", "parameters"=>{"type"=>"object", "required"=>["address"], "properties"=>{"address"=>{:type=>"string", :description=>"The address to geocode"}}}}}, {:type=>"function", :function=>{"name"=>"maps_place_details", "description"=>"Get detailed information about a specific place", "parameters"=>{"type"=>"object", "required"=>["place_id"], "properties"=>{"place_id"=>{:type=>"string", :description=>"The place ID to get details for"}}}}}, {:type=>"function", :function=>{"name"=>"maps_reverse_geocode", "description"=>"Convert coordinates into an address", "parameters"=>{"type"=>"object", "required"=>["latitude", "longitude"], "properties"=>{"latitude"=>{:type=>"number", :description=>"Latitude coordinate"}, "longitude"=>{:type=>"number", :description=>"Longitude coordinate"}}}}}, {:type=>"function", :function=>{"name"=>"maps_search_places", "description"=>"Search for places using Google Places API", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"location"=>{:type=>"object", :description=>"Optional center point for the search"}, "query"=>{:type=>"string", :description=>"Search query"}, "radius"=>{:type=>"number", :description=>"Search radius in meters (max 50000)"}}}}}, {:type=>"function", :function=>{"name"=>"research-paper-search", "description"=>"Search across 100M+ research papers with full text access - performs targeted academic paper searches with deep research content coverage. Returns detailed information about relevant academic papers including titles, authors, publication dates, and full text excerpts. Control the number of results and character counts returned to balance comprehensiveness with conciseness based on your task requirements.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"maxCharacters"=>{:type=>"integer", :description=>"Maximum number of characters to return for each result's text content (Default: 3000)"}, "numResults"=>{:type=>"integer", :description=>"Number of research papers to return (default: 5)"}, "query"=>{:type=>"string", :description=>"Research topic or keyword to search for"}}}}}, {:type=>"function", :function=>{"name"=>"scrape", "description"=>"Scrape a single webpage with advanced options for content extraction. Supports various formats including markdown and HTML. ", "parameters"=>{"type"=>"object", "required"=>["url"], "properties"=>{"url"=>{:type=>"string", :description=>"The URL of the webpage to scrape."}}}}}, {:type=>"function", :function=>{"name"=>"search", "description"=>"Performs a web search using the Google Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. To narrow your results in specific ways, you can use special operators in your search. Do not put spaces between the operator and your search term. A search for \"site:nytimes.com\" will work, but \"site: nytimes.com\" won't. The \"site:\" operator only accept one website.", "parameters"=>{"type"=>"object", "required"=>["query"], "properties"=>{"num"=>{:type=>"integer", :description=>"The number of results to return"}, "query"=>{:type=>"string", :description=>"The search query string"}}}}}, {:type=>"function", :function=>{"name"=>"search_token", "description"=>"\n    \n\n    Args:\n        text: \n    ", "parameters"=>{"type"=>"object", "required"=>["text"], "properties"=>{"text"=>{:type=>"string", :description=>nil}}}}}, {:type=>"function", :function=>{"name"=>"sequentialthinking", "description"=>"A detailed tool for dynamic and reflective problem-solving through thoughts.\nThis tool helps analyze problems through a flexible thinking process that can adapt and evolve.\nEach thought can build on, question, or revise previous insights as understanding deepens.\n\nWhen to use this tool:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Problems that require a multi-step solution\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\nKey features:\n- You can adjust total_thoughts up or down as you progress\n- You can question or revise previous thoughts\n- You can add more thoughts even after reaching what seemed like the end\n- You can express uncertainty and explore alternative approaches\n- Not every thought needs to build linearly - you can branch or backtrack\n- Generates a solution hypothesis\n- Verifies the hypothesis based on the Chain of Thought steps\n- Repeats the process until satisfied\n- Provides a correct answer\n\nParameters explained:\n- thought: Your current thinking step, which can include:\n* Regular analytical steps\n* Revisions of previous thoughts\n* Questions about previous decisions\n* Realizations about needing more analysis\n* Changes in approach\n* Hypothesis generation\n* Hypothesis verification\n- next_thought_needed: True if you need more thinking, even if at what seemed like the end\n- thought_number: Current number in sequence (can go beyond initial total if needed)\n- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)\n- is_revision: A boolean indicating if this thought revises previous thinking\n- revises_thought: If is_revision is true, which thought number is being reconsidered\n- branch_from_thought: If branching, which thought number is the branching point\n- branch_id: Identifier for the current branch (if any)\n- needs_more_thoughts: If reaching end but realizing more thoughts needed\n\nYou should:\n1. Start with an initial estimate of needed thoughts, but be ready to adjust\n2. Feel free to question or revise previous thoughts\n3. Don't hesitate to add more thoughts if needed, even at the \"end\"\n4. Express uncertainty when present\n5. Mark thoughts that revise previous thinking or branch into new paths\n6. Ignore information that is irrelevant to the current step\n7. Generate a solution hypothesis when appropriate\n8. Verify the hypothesis based on the Chain of Thought steps\n9. Repeat the process until satisfied with the solution\n10. Provide a single, ideally correct answer as the final output\n11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached", "parameters"=>{"type"=>"object", "required"=>["thought", "nextThoughtNeeded", "thoughtNumber", "totalThoughts"], "properties"=>{"branchFromThought"=>{:type=>"integer", :description=>"Branching point thought number"}, "branchId"=>{:type=>"string", :description=>"Branch identifier"}, "isRevision"=>{:type=>"boolean", :description=>"Whether this revises previous thinking"}, "needsMoreThoughts"=>{:type=>"boolean", :description=>"If more thoughts are needed"}, "nextThoughtNeeded"=>{:type=>"boolean", :description=>"Whether another thought step is needed"}, "revisesThought"=>{:type=>"integer", :description=>"Which thought is being reconsidered"}, "thought"=>{:type=>"string", :description=>"Your current thinking step"}, "thoughtNumber"=>{:type=>"integer", :description=>"Current thought number"}, "totalThoughts"=>{:type=>"integer", :description=>"Estimated total thoughts needed"}}}}}]}
I, [2025-12-09T16:41:24.055699 #14500]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:41:24.055716 #14500]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:41:24.055727 #14500]  INFO -- : Create Conversation
I, [2025-12-09T16:41:24.055752 #14500]  INFO -- : Use template pre_search
I, [2025-12-09T16:41:24.056094 #14500]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:41:24.056122 #14500]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:41:26.579812 #14500]  INFO -- : Successful send a message
I, [2025-12-09T16:41:26.579923 #14500]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:41:26.579951 #14500]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T16:41:26.580000 #14500] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T16:41:26.580029 #14500] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T16:47:33.849365 #17662]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:47:33.849726 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849771 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849778 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849787 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849792 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849799 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849803 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849833 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849841 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849862 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849869 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849878 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849889 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849913 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849918 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849929 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.849934 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.849944 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.969568 #17662]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:47:33.969641 #17662]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:47:33.970216 #17662]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:47:33.970253 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970278 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970283 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970289 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970293 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970300 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970303 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970328 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970332 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970347 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970355 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970361 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970364 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970376 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970380 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970389 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970393 #17662]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:47:33.970401 #17662]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:47:33.970703 #17662]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:47:33.970727 #17662]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:47:48.392573 #17662]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-09T16:47:48.392590 #17662]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T16:47:48.392600 #17662]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T16:47:48.392616 #17662]  INFO -- : Create Conversation
I, [2025-12-09T16:47:48.392655 #17662]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T16:47:48.393038 #17662]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:47:48.393073 #17662]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:47:56.241288 #17662]  INFO -- : Successful send a message
I, [2025-12-09T16:47:56.241371 #17662]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:47:56.241394 #17662]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T16:47:56.843720 #17662]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n** / **  \n\n- ****  \n    \n- ****  \n  -   \n  -   \n\n>  ********\n\n---\n\n### **2. **  \n****  \n\n- ****    \n- ****    \n- ****    \n- ****    \n\n>  ********\n\n---\n\n### **3. **  \n****  \n\n- ****  \n    \n- ****  \n  ****  \n- ****  \n   `site:`, `filetype:`    \n- ****  \n    \n\n>  ********\n\n---\n\n### **4. **  \n\n- ****  \n  ****    \n\n- ****  \n    \n  -   \n  -   \n  -  vs   \n\n- ****  \n  - ****  \n  - ****  \n  - ****AI  \n\n>  ******** \n\n---\n\n###  ****  \n|  |  |\n|------|------|\n| **** | ******** |\n| **** |  |\n| **** |  |\n| **** | NLU |\n\n---\n\n************", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T16:47:56.843914 #17662]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:47:56.843937 #17662]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:47:56.843956 #17662]  INFO -- : Create Conversation
I, [2025-12-09T16:47:56.844000 #17662]  INFO -- : Use template pre_search
I, [2025-12-09T16:47:56.844694 #17662]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:47:56.844749 #17662]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:47:59.094524 #17662]  INFO -- : Successful send a message
I, [2025-12-09T16:47:59.094623 #17662]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:47:59.094649 #17662]  INFO -- : Worker pre_search executed successfully
I, [2025-12-09T16:47:59.697508 #17662]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1  \n  - []   \n\n- 2  \n  - []   \n\n- 3  \n  - []   \n\n- 4  \n  - []   \n\n---\n\n###  ****  \n****  \n\n****  \n>   \n\n****  \n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T16:47:59.697684 #17662]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-09T16:47:59.697709 #17662]  INFO -- : Create worker's name is smart_search
I, [2025-12-09T16:47:59.697724 #17662]  INFO -- : Create Conversation
I, [2025-12-09T16:47:59.697759 #17662]  INFO -- : Use template smart_search
I, [2025-12-09T16:47:59.698101 #17662]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:47:59.698148 #17662]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:48:00.221894 #17662]  INFO -- : Successful send a message
I, [2025-12-09T16:48:00.221996 #17662]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:48:00.222021 #17662]  INFO -- : Worker smart_search executed successfully
I, [2025-12-09T16:48:00.222766 #17662]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T16:48:00.222808 #17662]  INFO -- : Creating worker instance for: summary
I, [2025-12-09T16:48:00.222822 #17662]  INFO -- : Create worker's name is summary
I, [2025-12-09T16:48:00.222836 #17662]  INFO -- : Create Conversation
I, [2025-12-09T16:48:00.222867 #17662]  INFO -- : Use template summarize
I, [2025-12-09T16:48:00.223167 #17662]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:48:00.223200 #17662]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:48:04.116380 #17662]  INFO -- : Successful send a message
I, [2025-12-09T16:48:04.116465 #17662]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:48:04.116485 #17662]  INFO -- : Worker summary executed successfully
I, [2025-12-09T16:52:53.240931 #19116]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:52:53.241004 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241036 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241042 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241051 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241056 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241062 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241066 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241092 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241097 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241103 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241107 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241113 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241118 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241136 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241140 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241148 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.241152 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.241161 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.308963 #19116]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:52:53.309030 #19116]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:52:53.309435 #19116]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T16:52:53.309472 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309492 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309501 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309508 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309512 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309518 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309522 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309543 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309548 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309555 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309558 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309565 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309569 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309579 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309583 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309593 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309596 #19116]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T16:52:53.309606 #19116]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T16:52:53.309848 #19116]  INFO -- : Configuration loaded successfully
I, [2025-12-09T16:52:53.309873 #19116]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T16:53:26.292401 #19116]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf", :with_history=>true}
I, [2025-12-09T16:53:26.292412 #19116]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T16:53:26.292422 #19116]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T16:53:26.292436 #19116]  INFO -- : Create Conversation
I, [2025-12-09T16:53:26.292479 #19116]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T16:53:26.292928 #19116]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:53:26.292959 #19116]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:53:37.848953 #19116]  INFO -- : Successful send a message
I, [2025-12-09T16:53:37.849026 #19116]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:53:37.849048 #19116]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T16:53:38.451502 #19116]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp idf** \n\n---\n\n### **1. **  \n ****\n\n- ****  \n  ESP-IDF Espressif ESP32/ESP8266   \n  ESP-IDF ArduinoZephyr********\n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | **** |\n| **** | ****ESP-IDF  v4.x  v5.x CMake **v5.3+**  |\n| **** | **** **Espressif **GitHub  |\n\n---\n\n### **3. **  \n\n####  \n- `ESP-IDF structure`\n- `ESP-IDF architecture`\n- `ESP-IDF component system`\n- `ESP-IDF directory layout`\n- `ESP-IDF build system`\n\n####  \n- `FreeRTOS`\n- `CMake`v4.0+  Makefile\n- `SDK Config` / `menuconfig`\n- `main component`\n- `bootloader`\n- `partition table`\n- `driver framework`\n\n####  \n```plaintext\nsite:docs.espressif.com \"ESP-IDF structure\"\nsite:docs.espressif.com \"ESP-IDF architecture\"\nsite:github.com/espressif/esp-idf \"directory structure\"\nintitle:\"ESP-IDF\" \"component system\"\nfiletype:pdf \"ESP-IDF\" \"technical reference\"\n```\n\n####  \n- `Arduino`\n- `tutorial` / `beginner`\n- `comparison`\n- `install` / `setup`\n\n---\n\n### **4. **  \n\n####  \n1. ****  \n   - [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/)  \n   - **Overview  Architecture**  **Project Structure**   \n2. **GitHub **  \n   - [https://github.com/espressif/esp-idf](https://github.com/espressif/esp-idf)  \n   - `components/`, `examples/`, `tools/`, `main/`, `sdkconfig`  \n3. ****  \n   -  `examples/get-started/hello_world` `CMakeLists.txt`  `main/` \n\n####  \n- **YouTube ** Espressif \n- **** Hackster.ioMedium  Espressif \n- **Stack Overflow / ESP32 **\n\n####  \n|  |  |\n|------|------|\n| **** |  ESP-IDF v3.3Makefile v4.0+  CMake |\n| **** | --- |\n| **** |  v5.x  |\n| **** |  `idf.py``cmake``ninja``xtensa-esp32-elf-gcc` |\n\n---\n\n###  ****\n\n1. **** [ESP-IDF  - Project Structure](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/build-system.html)  \n2. **** GitHub  [esp-idf ](https://github.com/espressif/esp-idf/tree/master)  \n3. **** `site:docs.espressif.com \"ESP-IDF architecture\"`   \n4. **** `examples/hello_world`  `examples/system/esp_wifi` \n\n>  **** `esp-idf`  `idf.py build` `tree`  `build/` \n\n---\n\n**** ESP-IDF ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T16:53:38.451623 #19116]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T16:53:38.451640 #19116]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T16:53:38.451656 #19116]  INFO -- : Create Conversation
I, [2025-12-09T16:53:38.451683 #19116]  INFO -- : Use template pre_search
I, [2025-12-09T16:53:38.451990 #19116]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T16:53:38.452020 #19116]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T16:53:41.569401 #19116]  INFO -- : Successful send a message
I, [2025-12-09T16:53:41.569507 #19116]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T16:53:41.569531 #19116]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T16:53:41.569574 #19116] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T16:53:41.569597 #19116] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T17:00:50.246178 #20946]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:00:50.246841 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.246891 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.246910 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.246936 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.246941 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.246949 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.246953 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.247007 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.247024 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.247040 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.247046 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.247053 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.247058 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.247072 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.247076 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.247087 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.247091 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.247106 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.370863 #20946]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:00:50.370924 #20946]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:00:50.371527 #20946]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:00:50.371567 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371588 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371592 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371599 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371603 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371609 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371613 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371635 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371651 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371662 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371668 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371676 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371680 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371693 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371697 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371706 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371710 #20946]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:00:50.371722 #20946]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:00:50.371955 #20946]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:00:50.371975 #20946]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:01:07.255280 #21033]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:01:07.255425 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255466 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255472 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255481 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255485 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255492 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255496 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255553 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255558 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255565 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255568 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255574 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255578 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255589 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255593 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255602 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.255606 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.255615 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.322517 #21033]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:01:07.322579 #21033]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:01:07.322941 #21033]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:01:07.322987 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323015 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323020 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323027 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323031 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323037 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323041 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323066 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323070 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323077 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323081 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323087 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323091 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323102 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323106 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323116 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323120 #21033]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:01:07.323132 #21033]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:01:07.323391 #21033]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:01:07.323414 #21033]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:02:26.266886 #21033]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf", :with_history=>true}
I, [2025-12-09T17:02:26.266916 #21033]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T17:02:26.266932 #21033]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T17:02:26.266953 #21033]  INFO -- : Create Conversation
I, [2025-12-09T17:02:26.267002 #21033]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T17:02:26.267437 #21033]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T17:02:26.267480 #21033]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T17:02:42.787726 #21033]  INFO -- : Successful send a message
I, [2025-12-09T17:02:42.787851 #21033]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T17:02:42.787901 #21033]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T17:02:43.390882 #21033]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp idf** \n\n---\n\n### **1. **\n\n****\n\n- ****  \n  ESP-IDFESP-IDF********\n\n- ****\n  -  \n  -  ArduinoZephyr\n  -  \n  -  \n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| ** vs ** | ****ESP-IDF |\n| **** | ****ESP-IDFv4.x  v5.xCMake**2** |\n| **** | **** **Espressif **GitHub  |\n\n>  ************\n\n---\n\n### **3. **\n\n#### ****\n- `ESP-IDF`\n- `architecture`\n- `structure`\n- `directory layout`\n- `component system`\n- `CMake build system`\n- `sdkconfig`\n\n#### ****\n|  |  |\n|------|--------|\n|  | `driver`, `freertos`, `esp_wifi`, `esp_log`, `bootloader`, `partition table` |\n|  | `CMakeLists.txt`, `idf.py`, `build directory`, `target` |\n|  | `standalone`, `multi-project`, `component dependency` |\n|  | `ESP-IDF v5.0`, `ESP-IDF v4.4` |\n\n#### ****\n```plaintext\n# \nsite:docs.espressif.com \"ESP-IDF\" structure\nsite:docs.espressif.com \"ESP-IDF\" architecture\nsite:docs.espressif.com \"ESP-IDF\" directory layout\n\n# GitHub\nsite:github.com/espressif/esp-idf \"components\" \"directory\" structure\n\n# CMake\nintitle:\"ESP-IDF\" \"CMakeLists.txt\" structure\n\n# \n\"ESP-IDF\" structure site:docs.espressif.com after:2022\n\n# \n\"ESP-IDF\" structure filetype:pdf\n```\n\n#### ****\n- `tutorial`\n- `beginner` / `how to start`\n- `arduino`ESP-IDF  Arduino-ESP32\n- `comparison` / `vs`\n\n---\n\n### **4. **\n\n#### ****\n **Espressif **docs.espressif.com  \n- `ESP-IDF Programming Guide`  `Project Structure` / `Component System` / `Build System`  \n-   \n  - [Project Structure](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/build-system.html)  \n  - [Component System](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/build-system.html#component-system)  \n  - [CMake Integration](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/build-system.html#cmake-integration)\n\n#### ****\n- **GitHub **  \n  [https://github.com/espressif/esp-idf](https://github.com/espressif/esp-idf)  \n  -  `components/`, `examples/`, `tools/`, `main/`   \n  -  `CMakeLists.txt`  `idf_component.yml` \n- ** / **  \n   `\"ESP-IDF architecture diagram\"`  `\"ESP-IDF system overview\"`PDFPPT\n- **** ESP-IDF Summit  \n  YouTube  `\"ESP-IDF architecture talk\"`\n\n#### ****\n **1. **  \n   - v4.x  `make`v5.x  `CMake`  \n    **** `ESP-IDF v5.1 structure`\n\n **2. /**  \n   - /2020 `make`   \n    **** `docs.espressif.com`  GitHub \n\n **3. **  \n   -   \n    **** +  +  Mermaid  Draw.io \n\n **4. **  \n   -  `esp_wifi`  `esp_netif``lwip`  \n    **** `idf.py component-graph` \n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| **1. ** |  [https://docs.espressif.com/projects/esp-idf/en/latest/](https://docs.espressif.com/projects/esp-idf/en/latest/)   Project Structure  Build System  |\n| **2. ** |  GitHub  [esp-idf](https://github.com/espressif/esp-idf)  `components/`  `examples/`  |\n| **3. ** |  `ESP-IDF v5.2` |\n| **4. ** |  `site:docs.espressif.com \"ESP-IDF\" structure`  Google  |\n| **5. ** | ESP-IDF |\n\n>  **** ESP-IDF  `idf.py component-graph` \n\n---\n\n ESP-IDF ****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T17:02:43.391069 #21033]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T17:02:43.391214 #21033]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T17:02:43.391275 #21033]  INFO -- : Create Conversation
I, [2025-12-09T17:02:43.391351 #21033]  INFO -- : Use template pre_search
I, [2025-12-09T17:02:43.392201 #21033]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T17:02:43.392285 #21033]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T17:02:46.770809 #21033]  INFO -- : Successful send a message
I, [2025-12-09T17:02:46.770935 #21033]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T17:02:46.770966 #21033]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T17:02:46.771017 #21033] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T17:02:46.771064 #21033] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T17:20:41.333702 #25350]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:20:41.334107 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334178 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334198 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334243 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334261 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334275 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334281 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334369 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334400 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334422 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334429 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334440 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334454 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334499 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334517 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334534 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.334550 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.334567 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.460407 #25350]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:20:41.460505 #25350]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:20:41.461532 #25350]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:20:41.461577 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461598 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461613 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461624 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461629 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461635 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461639 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461664 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461668 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461675 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461679 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461685 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461689 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461699 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461704 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461713 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.461730 #25350]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:20:41.461747 #25350]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:20:41.462097 #25350]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:20:41.462136 #25350]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:20:50.215764 #25350]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf", :with_history=>true}
I, [2025-12-09T17:20:50.215799 #25350]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T17:20:50.215812 #25350]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T17:20:50.215828 #25350]  INFO -- : Create Conversation
I, [2025-12-09T17:20:50.215863 #25350]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T17:20:50.216383 #25350]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T17:20:50.216447 #25350]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T17:21:03.562007 #25350]  INFO -- : Successful send a message
I, [2025-12-09T17:21:03.562147 #25350]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T17:21:03.562208 #25350]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T17:21:04.165136 #25350]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp idf** \n\n---\n\n### **1. **  \n ****  \n\n- ****  \n  ESP-IDF ESP-IDF ****  \n    \n- ****  \n  -   \n  - ArduinoZephyr  \n  -   \n  - \n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** |  ****   |\n| **** |  ****  ESP-IDF v4.x  v5.x |\n| **** |  ****   Espressif  |\n\n>  **** >  GitHub  >  > /Stack Overflow > /\n\n---\n\n### **3. **  \n\n#### ****  \n- `ESP-IDF`  \n- `architecture` / `structure` / `directory structure` / `module organization`  \n- `components` / `framework layout` / `bootloader` / `app` / `sdkconfig`\n\n#### ****  \n- `FreeRTOS`ESP-IDF   \n- `CMake`  \n- `partition table`  \n- `main()` vs `app_main()`  \n- `driver layer` / `middleware` / `application layer`\n\n#### ****  \n```plaintext\n#  site:  intitle: \nsite:docs.espressif.com \"ESP-IDF\" structure\nsite:docs.espressif.com \"ESP-IDF\" architecture\nsite:docs.espressif.com \"ESP-IDF\" directory layout\nintitle:\"ESP-IDF\" \"project structure\" site:docs.espressif.com\nsite:github.com/espressif/esp-idf \"components\" \"directory\"\n\n#  v5.2\nsite:docs.espressif.com \"ESP-IDF\" structure v5.2\n```\n\n#### ****  \n- `tutorial`  \n- `how to` / `beginner` / `setup`  \n- `Arduino` Arduino ESP32   \n- `comparison` / `vs`\n\n---\n\n### **4. **  \n\n#### ****  \n **Espressif Project Structure**  \n- `https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-guides/build-system.html`  \n-   \n  - `components/`   \n  - `main/`   \n  - `sdkconfig`   \n  - `CMakeLists.txt`   \n  - bootloaderpartition tableflash layout  \n\n#### ****  \n- **GitHub **  \n  `https://github.com/espressif/esp-idf`   `components/`   \n  -  `driver`, `wifi`, `bt`, `freertos`  \n- ****  \n   `\"ESP-IDF architecture diagram\"` + `site:espressif.com`  \n- **/** ESP-IDF Summit  \n  - \n\n#### ****  \n **1. **  \n   - ESP-IDF v4.x  v5.x CMake   \n   - **** `v5.2`\n\n **2. **  \n   -  ESP-IDF  Arduino  `main.c`   \n   - **** `espressif.com`  `github.com/espressif` \n\n **3. **  \n   -   \n   - **** `\"ESP-IDF architecture diagram\"` \n\n---\n\n###  **Summary**\n\n|  |  |\n|------|------|\n| 1 | ****[https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html)   Project Structure  Build System  |\n| 2 | ****`site:docs.espressif.com \"ESP-IDF\" structure directory layout` |\n| 3 | **** [https://github.com/espressif/esp-idf/tree/master](https://github.com/espressif/esp-idf/tree/master)  |\n| 4 | **** ESP-IDF **v5.2+** |\n| 5 | **** Arduinotutorialbeginner  |\n| 6 | **** `\"ESP-IDF architecture diagram\"`  |\n\n---\n\n ****  \n**********+**Project Structure GitHub ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T17:21:04.165313 #25350]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T17:21:04.165333 #25350]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T17:21:04.165349 #25350]  INFO -- : Create Conversation
I, [2025-12-09T17:21:04.165385 #25350]  INFO -- : Use template pre_search
I, [2025-12-09T17:21:04.165933 #25350]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T17:21:04.165994 #25350]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T17:21:06.940844 #25350]  INFO -- : Successful send a message
I, [2025-12-09T17:21:06.940966 #25350]  INFO -- : OpenAIAdapter: Received response from OpenAI
E, [2025-12-09T17:21:06.941001 #25350] ERROR -- : pre_search worker: send_msg returned nil
E, [2025-12-09T17:21:06.941037 #25350] ERROR -- : Error executing worker pre_search: unexpected return
D, [2025-12-09T17:21:06.941087 #25350] DEBUG -- : /home/nix/SmartResearch/agents/workers/pre_search.rb:11:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T17:37:33.572368 #28943]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:37:33.572711 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.572753 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.572760 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.572769 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.572773 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.572780 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.572784 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.572851 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.572886 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.572900 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.572906 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.572913 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.572951 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.573006 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.573025 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.573042 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.573048 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.573072 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.685445 #28943]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:37:33.685540 #28943]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:37:33.686238 #28943]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:37:33.686290 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686314 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686354 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686369 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686385 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686396 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686402 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686431 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686441 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686448 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686453 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686542 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686567 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686602 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686629 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686655 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.686662 #28943]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:37:33.686674 #28943]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:37:33.687202 #28943]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:37:33.687246 #28943]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:38:00.727504 #28943]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf", :with_history=>true}
I, [2025-12-09T17:38:00.727542 #28943]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T17:38:00.727555 #28943]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T17:38:00.727571 #28943]  INFO -- : Create Conversation
I, [2025-12-09T17:38:00.727610 #28943]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T17:38:00.728001 #28943]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T17:38:00.728042 #28943]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T17:38:13.811854 #28943]  INFO -- : Successful send a message
I, [2025-12-09T17:38:13.811929 #28943]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T17:38:13.811948 #28943]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T17:38:14.414318 #28943]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp idf** \n\n---\n\n### **1. **  \n ****\n\n- ****  \n  ESP-IDF ESP-IDF ****\n- ****  \n  -   \n  - ArduinoRT-OS  \n  -   \n  - \n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** |  **** |\n| **** |  ****ESP-IDF  36 v5.x CMake  **v5.3+**  |\n| **** |  **** **Espressif **  GitHub IEEE/ACM / |\n\n---\n\n### **3. **  \n\n####  ****\n- `ESP-IDF architecture`\n- `ESP-IDF structure`\n- `ESP-IDF component system`\n- `ESP-IDF directory layout`\n- `ESP-IDF build system`\n\n####  ****\n- `FreeRTOS`RTOS\n- `CMake`v4.0+ Make\n- `driver` / `hal` / `libc` / `lwip`\n- `main.c` / `CMakeLists.txt` / `idf_component_register`/\n- `sdkconfig` / `partition table`\n\n####  ****\n```bash\n# \nsite:docs.espressif.com \"ESP-IDF architecture\"\nsite:docs.espressif.com \"ESP-IDF directory structure\"\n\n# GitHub\nsite:github.com/espressif/esp-idf \"components\" \"directory\"\n\n# \nsite:docs.espressif.com \"ESP-IDF\" \"v5.3\" structure\n\n# PDF\nfiletype:pdf \"ESP-IDF\" \"system architecture\"\n\n# /\nsite:www.espressif.com \"blog\" \"ESP-IDF\" \"structure\"\n```\n\n####  ****\n- `Arduino`ESP-IDF  Arduino-ESP32\n- `how to install` / `setup`\n- `beginner` / `tutorial`\n- `comparison` / `vs`\n\n---\n\n### **4. **  \n\n####  ****\n- **Espressif **  [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/)  \n  -   \n    - **Application Development Framework**  \n    - **Component System**  \n    - **Build System**  \n    - **Directory Structure**  \n- **GitHub **  [https://github.com/espressif/esp-idf](https://github.com/espressif/esp-idf)  \n  -  `components/`  `driver`, `freertos`, `lwip`, `esp_wifi`  \n  -  `examples/`  `hello_world`\n\n####  ****\n- **Espressif ** Inside ESP-IDF: The Component System  \n- **YouTube **Espressif Systems  \n- **** IEEE Xplore  ESP-IDF architecture\n\n####  ****\n|  |  |\n|------|------|\n| **** | ESP-IDF v3.x  Makev4.x+  CMake |\n| **** | CMakeLists.txt |\n| **SDK** | ESP-IDF   xtensa-esp32-elf |\n| **** | /main.c |\n\n---\n\n###  ****  \n1. ****[https://docs.espressif.com/projects/esp-idf/en/latest/esp32/](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/)   Application Development Framework  Component System   \n2. ****GitHub  `components/`  `examples/hello_world/`   \n3. **** **ESP-IDF v5.3+**  \n4. **** YouTube  ESP-IDF architecture overview Espressif   \n5. **** StackOverflow  CSDN \n\n---\n\n**** ESP-IDF ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T17:38:14.414542 #28943]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T17:38:14.414564 #28943]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T17:38:14.414581 #28943]  INFO -- : Create Conversation
I, [2025-12-09T17:38:14.414618 #28943]  INFO -- : Use template pre_search
I, [2025-12-09T17:38:14.415408 #28943]  INFO -- : pre_search: About to call send_msg with params: {:text=>" **esp idf** \n\n---\n\n### **1. **  \n ****\n\n- ****  \n  ESP-IDF ESP-IDF ****\n- ****  \n  -   \n  - ArduinoRT-OS  \n  -   \n  - \n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** |  **** |\n| **** |  ****ESP-IDF  36 v5.x CMake  **v5.3+**  |\n| **** |  **** **Espressif **  GitHub IEEE/ACM / |\n\n---\n\n### **3. **  \n\n####  ****\n- `ESP-IDF architecture`\n- `ESP-IDF structure`\n- `ESP-IDF component system`\n- `ESP-IDF directory layout`\n- `ESP-IDF build system`\n\n####  ****\n- `FreeRTOS`RTOS\n- `CMake`v4.0+ Make\n- `driver` / `hal` / `libc` / `lwip`\n- `main.c` / `CMakeLists.txt` / `idf_component_register`/\n- `sdkconfig` / `partition table`\n\n####  ****\n```bash\n# \nsite:docs.espressif.com \"ESP-IDF architecture\"\nsite:docs.espressif.com \"ESP-IDF directory structure\"\n\n# GitHub\nsite:github.com/espressif/esp-idf \"components\" \"directory\"\n\n# \nsite:docs.espressif.com \"ESP-IDF\" \"v5.3\" structure\n\n# PDF\nfiletype:pdf \"ESP-IDF\" \"system architecture\"\n\n# /\nsite:www.espressif.com \"blog\" \"ESP-IDF\" \"structure\"\n```\n\n####  ****\n- `Arduino`ESP-IDF  Arduino-ESP32\n- `how to install` / `setup`\n- `beginner` / `tutorial`\n- `comparison` / `vs`\n\n---\n\n### **4. **  \n\n####  ****\n- **Espressif **  [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/)  \n  -   \n    - **Application Development Framework**  \n    - **Component System**  \n    - **Build System**  \n    - **Directory Structure**  \n- **GitHub **  [https://github.com/espressif/esp-idf](https://github.com/espressif/esp-idf)  \n  -  `components/`  `driver`, `freertos`, `lwip`, `esp_wifi`  \n  -  `examples/`  `hello_world`\n\n####  ****\n- **Espressif ** Inside ESP-IDF: The Component System  \n- **YouTube **Espressif Systems  \n- **** IEEE Xplore  ESP-IDF architecture\n\n####  ****\n|  |  |\n|------|------|\n| **** | ESP-IDF v3.x  Makev4.x+  CMake |\n| **** | CMakeLists.txt |\n| **SDK** | ESP-IDF   xtensa-esp32-elf |\n| **** | /main.c |\n\n---\n\n###  ****  \n1. ****[https://docs.espressif.com/projects/esp-idf/en/latest/esp32/](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/)   Application Development Framework  Component System   \n2. ****GitHub  `components/`  `examples/hello_world/`   \n3. **** **ESP-IDF v5.3+**  \n4. **** YouTube  ESP-IDF architecture overview Espressif   \n5. **** StackOverflow  CSDN \n\n---\n\n**** ESP-IDF ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T17:38:14.415657 #28943]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T17:38:14.415711 #28943]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T17:38:17.033098 #28943]  INFO -- : Successful send a message
I, [2025-12-09T17:38:17.033228 #28943]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T17:38:17.033259 #28943]  INFO -- : ================================================================================
I, [2025-12-09T17:38:17.033270 #28943]  INFO -- : pre_search: send_msg 
I, [2025-12-09T17:38:17.033279 #28943]  INFO -- : ================================================================================
I, [2025-12-09T17:38:17.033289 #28943]  INFO -- : Response Class: NilClass
I, [2025-12-09T17:38:17.033298 #28943]  INFO -- : Response is nil?: true
E, [2025-12-09T17:38:17.033309 #28943] ERROR -- : Response  nil
I, [2025-12-09T17:38:17.033317 #28943]  INFO -- : ================================================================================
I, [2025-12-09T17:38:17.033332 #28943]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T17:38:17.033369 #28943] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T17:38:17.033413 #28943] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:212:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:109:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:54:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:40:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:34:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<main>'
I, [2025-12-09T17:51:58.373177 #32427]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:51:58.373716 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373772 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373781 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373791 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373796 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373803 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373808 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373836 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373841 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373849 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373854 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373860 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373865 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373877 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373892 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373903 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.373907 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.373916 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.506457 #32427]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:51:58.506512 #32427]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:51:58.506895 #32427]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:51:58.506935 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.506958 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.506966 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.506973 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.506977 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.506983 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.506998 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.507018 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.507022 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.507029 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.507033 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.507040 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.507043 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.507055 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.507059 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.507068 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.507073 #32427]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:51:58.507082 #32427]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:51:58.507303 #32427]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:51:58.507324 #32427]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:54:17.795566 #501]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:54:17.795642 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795681 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795688 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795697 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795702 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795709 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795713 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795736 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795741 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795748 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795753 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795760 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795764 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795775 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795780 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795790 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.795794 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.795804 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.910929 #501]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:54:17.910989 #501]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:54:17.911591 #501]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:54:17.911627 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911650 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911655 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911662 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911666 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911672 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911676 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911711 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911726 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911738 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911744 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911752 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911757 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911769 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911774 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911784 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.911787 #501]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:54:17.911797 #501]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:54:17.912034 #501]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:54:17.912055 #501]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:56:24.879112 #1134]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:56:24.879509 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879555 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879563 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879572 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879577 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879583 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879588 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879611 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879629 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879641 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879647 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879657 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879662 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879676 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879681 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879691 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.879696 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.879706 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.988841 #1134]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:56:24.988901 #1134]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T17:56:24.989243 #1134]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T17:56:24.989283 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989311 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989317 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989324 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989328 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989334 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989338 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989357 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989362 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989368 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989372 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989378 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989382 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989392 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989396 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989405 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989409 #1134]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T17:56:24.989418 #1134]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T17:56:24.989659 #1134]  INFO -- : Configuration loaded successfully
I, [2025-12-09T17:56:24.989681 #1134]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T18:05:39.730905 #4522]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T18:05:39.731781 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731836 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731844 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731854 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731859 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731867 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731872 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731904 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731923 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731936 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731942 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731952 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731957 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731971 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731976 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.731987 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.731992 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.732003 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.860138 #4522]  INFO -- : Configuration loaded successfully
I, [2025-12-09T18:05:39.860198 #4522]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T18:05:39.860957 #4522]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T18:05:39.861001 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861023 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861041 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861049 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861054 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861078 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861086 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861110 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861114 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861121 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861126 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861132 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861136 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861147 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861151 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861160 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861164 #4522]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:05:39.861174 #4522]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:05:39.861400 #4522]  INFO -- : Configuration loaded successfully
I, [2025-12-09T18:05:39.861421 #4522]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T18:06:00.154464 #4522]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf", :with_history=>true}
I, [2025-12-09T18:06:00.154491 #4522]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T18:06:00.154502 #4522]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T18:06:00.154517 #4522]  INFO -- : Create Conversation
I, [2025-12-09T18:06:00.154551 #4522]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T18:06:00.154946 #4522]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T18:06:00.154980 #4522]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T18:06:13.324113 #4522]  INFO -- : Successful send a message
I, [2025-12-09T18:06:13.324214 #4522]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T18:06:13.324259 #4522]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T18:06:13.926696 #4522]  INFO -- : Calling worker: pre_search with params: {:text=>" **esp idf** \n\n---\n\n### **1. **  \n ****  \n\n- ****  \n  ESP-IDFESP-IDF****  \n- ****  \n  -   \n  -   \n  -   \n  - \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** |  **** |\n| **** |  ****ESP-IDF  v4.x  v5.x |\n| **** |  **** **Espressif **  GitHub  ESP-IDF Forum |\n\n>  ****  \n> ** > GitHub  >  >  > **\n\n---\n\n### **3. **  \n\n####  ****  \n- `ESP-IDF architecture`  \n- `ESP-IDF structure`  \n- `ESP-IDF component system`  \n- `ESP-IDF directory layout`  \n- `ESP-IDF build system`\n\n####  ****  \n- `FreeRTOS`ESP-IDF   \n- `CMake`  \n- `Kconfig`  \n- `components/`   \n- `main/`   \n- `sdkconfig`  \n- `idf.py`\n\n####  ****  \n```bash\nsite:docs.espressif.com \"ESP-IDF structure\"  \nsite:github.com/espressif/esp-idf \"components\" \"directory\"  \nintitle:\"ESP-IDF\" \"architecture\"  \nfiletype:pdf \"ESP-IDF\" \"design\"  \n\"ESP-IDF\" (\"module\" OR \"component\" OR \"layer\") -forum -stackoverflow\n```\n\n>   `ESP-IDF tutorial`  `how to use ESP-IDF`\n\n####  ****  \n- `tutorial`  \n- `beginner` / `for beginners`  \n- `install` / `setup`  \n- `WiFi` / `Bluetooth`  \n- `stackoverflow`\n\n---\n\n### **4. **  \n\n####  ****  \n- **ArchitectureOverview**  \n   [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html)  \n  - **ESP-IDF Overview  Software Structure**  \n- **GitHub **  \n   [https://github.com/espressif/esp-idf](https://github.com/espressif/esp-idf)  \n  -  `components/``examples/``tools/``main/`   \n  -  `CMakeLists.txt`  `idf_component.yml`   \n- ****  \n  - `\"ESP-IDF architecture diagram\" filetype:pdf`\n\n####  ****  \n- **Espressif  YouTube **ESP-IDF Internal Architecture  \n- **IEEE Xplore / ACM Digital Library** `ESP-IDF AND (architecture OR design)`  \n- **CSDN**ESP-IDF \n\n####  ****  \n|  |  |  |\n|--------|------|----------|\n| **** | ESP-IDF v4.x  v5.x CMake  |  ESP-IDF v5.2 structure |\n| **** | OverviewComponentsBuild System |  |\n| **** |  |  Mermaid  |\n| **** |  |  |\n\n---\n\n###  ****\n\n1. **** [ESP-IDF  - Overview](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html)   Software Structure  \n2. **** GitHub  `components/`   \n3. **** `site:docs.espressif.com \"ESP-IDF component system\"`   \n4. **** `tree`  IDE  `CMakeLists.txt`   \n\n>  **** **ESP-IDF **  \n> - main  \n> - components  \n> - FreeRTOSLWIPdriver  \n> - HAL  \n> - CMake + idf.py  \n\n---\n\n ESP-IDF ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T18:06:13.926805 #4522]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T18:06:13.926819 #4522]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T18:06:13.926830 #4522]  INFO -- : Create Conversation
I, [2025-12-09T18:06:13.926857 #4522]  INFO -- : Use template pre_search
I, [2025-12-09T18:06:13.927327 #4522]  INFO -- : pre_search: About to call send_msg with params: {:text=>" **esp idf** \n\n---\n\n### **1. **  \n ****  \n\n- ****  \n  ESP-IDFESP-IDF****  \n- ****  \n  -   \n  -   \n  -   \n  - \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** |  **** |\n| **** |  ****ESP-IDF  v4.x  v5.x |\n| **** |  **** **Espressif **  GitHub  ESP-IDF Forum |\n\n>  ****  \n> ** > GitHub  >  >  > **\n\n---\n\n### **3. **  \n\n####  ****  \n- `ESP-IDF architecture`  \n- `ESP-IDF structure`  \n- `ESP-IDF component system`  \n- `ESP-IDF directory layout`  \n- `ESP-IDF build system`\n\n####  ****  \n- `FreeRTOS`ESP-IDF   \n- `CMake`  \n- `Kconfig`  \n- `components/`   \n- `main/`   \n- `sdkconfig`  \n- `idf.py`\n\n####  ****  \n```bash\nsite:docs.espressif.com \"ESP-IDF structure\"  \nsite:github.com/espressif/esp-idf \"components\" \"directory\"  \nintitle:\"ESP-IDF\" \"architecture\"  \nfiletype:pdf \"ESP-IDF\" \"design\"  \n\"ESP-IDF\" (\"module\" OR \"component\" OR \"layer\") -forum -stackoverflow\n```\n\n>   `ESP-IDF tutorial`  `how to use ESP-IDF`\n\n####  ****  \n- `tutorial`  \n- `beginner` / `for beginners`  \n- `install` / `setup`  \n- `WiFi` / `Bluetooth`  \n- `stackoverflow`\n\n---\n\n### **4. **  \n\n####  ****  \n- **ArchitectureOverview**  \n   [https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html)  \n  - **ESP-IDF Overview  Software Structure**  \n- **GitHub **  \n   [https://github.com/espressif/esp-idf](https://github.com/espressif/esp-idf)  \n  -  `components/``examples/``tools/``main/`   \n  -  `CMakeLists.txt`  `idf_component.yml`   \n- ****  \n  - `\"ESP-IDF architecture diagram\" filetype:pdf`\n\n####  ****  \n- **Espressif  YouTube **ESP-IDF Internal Architecture  \n- **IEEE Xplore / ACM Digital Library** `ESP-IDF AND (architecture OR design)`  \n- **CSDN**ESP-IDF \n\n####  ****  \n|  |  |  |\n|--------|------|----------|\n| **** | ESP-IDF v4.x  v5.x CMake  |  ESP-IDF v5.2 structure |\n| **** | OverviewComponentsBuild System |  |\n| **** |  |  Mermaid  |\n| **** |  |  |\n\n---\n\n###  ****\n\n1. **** [ESP-IDF  - Overview](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/index.html)   Software Structure  \n2. **** GitHub  `components/`   \n3. **** `site:docs.espressif.com \"ESP-IDF component system\"`   \n4. **** `tree`  IDE  `CMakeLists.txt`   \n\n>  **** **ESP-IDF **  \n> - main  \n> - components  \n> - FreeRTOSLWIPdriver  \n> - HAL  \n> - CMake + idf.py  \n\n---\n\n ESP-IDF ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T18:06:13.927457 #4522]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T18:06:13.927479 #4522]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T18:06:16.642560 #4522]  INFO -- : Successful send a message
I, [2025-12-09T18:06:16.642633 #4522]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T18:06:16.642667 #4522]  INFO -- : ================================================================================
I, [2025-12-09T18:06:16.642677 #4522]  INFO -- : pre_search: send_msg 
I, [2025-12-09T18:06:16.642682 #4522]  INFO -- : ================================================================================
I, [2025-12-09T18:06:16.642695 #4522]  INFO -- : Response Class: NilClass
I, [2025-12-09T18:06:16.642705 #4522]  INFO -- : Response is nil?: true
E, [2025-12-09T18:06:16.642712 #4522] ERROR -- : Response  nil
I, [2025-12-09T18:06:16.642716 #4522]  INFO -- : ================================================================================
I, [2025-12-09T18:06:16.642723 #4522]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T18:06:16.642747 #4522] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T18:06:16.642772 #4522] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T18:09:16.024115 #5407]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T18:09:16.024241 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024279 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024287 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024308 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024326 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024338 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024344 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024389 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024410 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024424 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024430 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024439 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024444 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024457 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024463 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024474 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.024479 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.024490 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.149389 #5407]  INFO -- : Configuration loaded successfully
I, [2025-12-09T18:09:16.149453 #5407]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T18:09:16.149843 #5407]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T18:09:16.149883 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.149929 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.149950 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.149973 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.149990 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150111 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150150 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150214 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150258 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150290 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150315 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150326 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150331 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150385 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150405 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150424 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150440 #5407]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T18:09:16.150461 #5407]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T18:09:16.150709 #5407]  INFO -- : Configuration loaded successfully
I, [2025-12-09T18:09:16.150738 #5407]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T18:09:30.777829 #5407]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"esp idf", :with_history=>true}
I, [2025-12-09T18:09:30.777875 #5407]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T18:09:30.777891 #5407]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T18:09:30.777911 #5407]  INFO -- : Create Conversation
I, [2025-12-09T18:09:30.777968 #5407]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T18:09:30.778460 #5407]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T18:09:30.778508 #5407]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T18:09:42.235708 #5407]  INFO -- : Successful send a message
I, [2025-12-09T18:09:42.235812 #5407]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T18:09:42.235834 #5407]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T18:09:42.838304 #5407]  INFO -- : Calling worker: pre_search with params: {:text=>"esp idf\n\n---\n\n### **1. **  \n****  \n\n- ****  \n  ESP-IDFAPI  \n  ****\n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | **** |\n| **** | ****ESP-IDF  v4.x  v5.x CMake **** v5.3+ |\n| **** | **** **Espressif ** GitHubEspressif ForumIEEE/ACM  |\n\n---\n\n### **3. **  \n\n#### ****  \n- `ESP-IDF architecture`  \n- `ESP-IDF structure`  \n- `ESP-IDF component system`  \n- `ESP-IDF directory layout`  \n- `ESP-IDF build system`  \n\n#### ****  \n- `FreeRTOS`  \n- `CMake`v4.0+  Make  \n- `SDK config` / `Kconfig`  \n- `main component` / `driver component`  \n- `bootloader` / `partition table`  \n\n#### ****  \n```plaintext\nsite:espressif.com \"ESP-IDF\" architecture  \nsite:github.com/espressif/esp-idf \"components\" directory  \nintitle:\"ESP-IDF\" \"project structure\"  \nfiletype:pdf \"ESP-IDF\" \"technical reference\"  \n\"ESP-IDF\" structure -tutorial -blog -youtube    \n```\n\n#### ****  \n- `-tutorial`  \n- `-blog`  \n- `-youtube`  \n- `-install` `-setup` `-beginner`  \n- `-Arduino` Arduino-ESP32   \n\n---\n\n### **4. **  \n\n#### ****  \n **Espressif **  \n- https://docs.espressif.com/projects/esp-idf/en/latest/esp32/  \n-   \n  - Project Structure  \n  - Components  \n  - Build System  \n  - Directory Layout  \n\n **GitHub **  \n- https://github.com/espressif/esp-idf  \n- `components/``examples/``tools/``main/`   \n- `README.md``docs/en/design/`   \n\n ** / **  \n- `\"ESP-IDF architecture diagram\" site:espressif.com`  \n- App  Components  SDK  HAL  Driver  Hardware  \n\n#### ****  \n- **Espressif **structurecomponents  \n- **Stack Overflow**`ESP-IDF folder structure`  \n- **YouTube ** Espressif   \n\n#### ****  \n ****  \n- v3.x Makefilev4.0+ CMake  \n-  2020   \n\n ****  \n- ESP-IDF  ESP-AT  Arduino for ESP32  \n- ESP32 SDKESP32 framework  \n\n ****  \n-   \n\n ****  \n- CSDN\n\n---\n\n###  ****  \n1. ****[https://docs.espressif.com/projects/esp-idf/en/latest/esp32/](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/)  \n2. ****  \n   - Project Structure  Directory Layout  \n   - Components  Component Structure  \n3. **** GitHub  `esp-idf/components/`   \n4. ****App  Components  SDK  HAL  \n5. ****** 2022  espressif.com  GitHub **\n\n---\n\n**** ESP-IDF ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T18:09:42.838509 #5407]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T18:09:42.838531 #5407]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T18:09:42.838548 #5407]  INFO -- : Create Conversation
I, [2025-12-09T18:09:42.838584 #5407]  INFO -- : Use template pre_search
I, [2025-12-09T18:09:42.839080 #5407]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T18:09:42.839143 #5407]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T18:09:45.365693 #5407]  INFO -- : Successful send a message
I, [2025-12-09T18:09:45.365781 #5407]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T18:09:45.365864 #5407]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T18:09:45.365917 #5407] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T18:09:45.365962 #5407] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T19:06:03.685053 #19446]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:06:03.685894 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.685956 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.685966 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.685976 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.685981 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.685988 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.685993 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.686022 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.686028 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.686036 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.686041 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.686047 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.686052 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.686069 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.686074 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.686108 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.686113 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.686123 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.826504 #19446]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:06:03.826571 #19446]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:06:03.827216 #19446]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:06:03.827264 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827287 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827292 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827299 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827303 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827310 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827314 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827335 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827340 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827347 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827351 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827357 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827361 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827371 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827376 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827388 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827417 #19446]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:06:03.827435 #19446]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:06:03.827702 #19446]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:06:03.827733 #19446]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:06:26.936710 #19446]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"stm32", :with_history=>true}
I, [2025-12-09T19:06:26.936736 #19446]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T19:06:26.936748 #19446]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T19:06:26.936764 #19446]  INFO -- : Create Conversation
I, [2025-12-09T19:06:26.936812 #19446]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T19:06:26.937208 #19446]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:06:26.937257 #19446]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:06:40.016030 #19446]  INFO -- : Successful send a message
I, [2025-12-09T19:06:40.016162 #19446]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:06:40.016194 #19446]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T19:06:40.618774 #19446]  INFO -- : Calling worker: pre_search with params: {:text=>"stm32\n\n---\n\n### **1. **\n\n** + **\n\n- ****STM32STM32\n- ****STM32\n\n>  ****\n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| ** vs ** | ****<br> |\n| **** | ****<br>STM32STM32U5H73Cortex-M |\n| **** | ****<br>STMicroelectronicsDatasheetReference ManualApplication NotesIEEEEDN |\n\n>  ****DMA\n\n---\n\n### **3. **\n\n#### ****\n- `STM32`\n- `STM32 microcontroller`\n- `STM32 overview`\n- `STM32 introduction`\n\n#### ****\n- Cortex-M\n- ARM\n-  / \n- GPIO / UART / SPI / I2C\n- STM32CubeMX / HAL / LL\n- STM32F1 / F4 / H7 / U5\n\n#### ****\n```plaintext\n\"STM32\" intitle:\"overview\" OR intitle:\"introduction\"\nsite:st.com \"STM32\" ()\nsite:st.com filetype:pdf \"reference manual\" \"STM32\"\n\"STM32\" AND (\"architecture\" OR \"features\" OR \"applications\")\n\"STM32\" -forum -reddit -blog \n```\n\n#### ****\n- `buy` / `price` / `amazon` / `aliexpress`\n- `tutorial` / `how to`\n- `comparison` / `vs`\n- `arduino`\n\n>  ****  \n> `\"STM32\" intitle:\"overview\" site:st.com`  \n> `\"STM32 microcontroller\" architecture features site:st.com filetype:pdf`\n\n---\n\n### **4. **\n\n#### ****\n- **STMicroelectronics **  \n  - [www.st.com/stm32](https://www.st.com/stm32)  \n  - Datasheet  \n  - Reference Manual  \n  - AN\n\n#### ****\n- ****  \n  - Wikipedia: STM32  \n  - AllAboutCircuits / Electronics Tutorials  \n  - YouTubeSTM32STM32 for Beginners\n- ****  \n  - GitHub  STM32   \n  - Stack OverflowLED\n\n#### ****\n|  |  |  |\n|------|------|----------|\n| **** |  | PDF |\n| **** | STM32STM32 | F0/F1/F4/H7 |\n| **** | Cortex-M4NVICSysTick | for beginnersexplained simply |\n| **** |  | CSDN |\n\n---\n\n###  ****\n\n1. ****  \n    [https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html](https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html)  \n    \n\n2. ****  \n   STM32F407 **Datasheet + Reference Manual**PDF  \n    1Introduction2Overview\n\n3. ****  \n   `\"STM32 introduction\" site:allaboutcircuits.com`  \n    YouTube*STM32 Explained - Full Beginner Tutorial by GreatScott!*\n\n4. ****  \n   STM32 \n\n---\n\n********STM32", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T19:06:40.618924 #19446]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T19:06:40.618942 #19446]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T19:06:40.618959 #19446]  INFO -- : Create Conversation
I, [2025-12-09T19:06:40.618993 #19446]  INFO -- : Use template pre_search
I, [2025-12-09T19:06:40.619386 #19446]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:06:40.619435 #19446]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:06:43.300736 #19446]  INFO -- : Successful send a message
I, [2025-12-09T19:06:43.300838 #19446]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:06:43.300923 #19446]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T19:06:43.300996 #19446] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T19:06:43.301031 #19446] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T19:11:46.014057 #21052]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:11:46.014973 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015035 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015054 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015067 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015073 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015081 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015086 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015117 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015122 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015130 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015134 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015141 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015146 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015158 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015163 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015174 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.015191 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.015208 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.133874 #21052]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:11:46.133941 #21052]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:11:46.134818 #21052]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:11:46.134884 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.134918 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.134925 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.134936 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.134954 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.134966 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.134972 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.134998 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.135013 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.135030 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.135036 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.135043 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.135058 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.135098 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.135121 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.135138 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.135145 #21052]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:11:46.135156 #21052]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:11:46.135517 #21052]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:11:46.135552 #21052]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:11:55.250508 #21052]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"stm32", :with_history=>true}
I, [2025-12-09T19:11:55.250533 #21052]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T19:11:55.250546 #21052]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T19:11:55.250560 #21052]  INFO -- : Create Conversation
I, [2025-12-09T19:11:55.250599 #21052]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T19:11:55.250971 #21052]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:11:55.251014 #21052]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:12:07.584602 #21052]  INFO -- : Successful send a message
I, [2025-12-09T19:12:07.584752 #21052]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:12:07.584789 #21052]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T19:12:08.187242 #21052]  INFO -- : Calling worker: pre_search with params: {:text=>"stm32\n\n---\n\n### **1. **  \n** + **  \n- ****STM32  \n- ****STM32ARM Cortex-M  \n>  ****STM32\n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** | ****STEEVblogAllAboutCircuitsCSDN |\n| **** | ****STM32STM32U5STM32H73Cortex-M |\n| **** | ****STMicroelectronicsDatasheetReference ManualARMIEEE/ACMMIT OpenCourseWareCoursera |\n\n---\n\n### **3. **  \n\n#### ****  \n- `STM32`  \n- `microcontroller` / `MCU`  \n- `ARM Cortex-M`  \n- `32-bit`  \n- `STMicroelectronics`  \n\n#### ****  \n- `STM32F1`, `STM32F4`, `STM32H7`, `STM32Cube`  \n- `GPIO`, `USART`, `DMA`, `RTOS`, `Bootloader`, `HAL/LL library`  \n- `embedded system`, `IoT`, `industrial control`, `motor control`  \n\n#### ****  \n```plaintext\n# \nsite:st.com \"STM32\" introduction  \nsite:st.com \"STM32\" datasheet  \nsite:arm.com \"Cortex-M\" STM32  \n\n# \nintitle:\"STM32 tutorial\" filetype:pdf  \n\"STM32 overview\" site:allaboutcircuits.com  \n\"STM32 architecture\" site:electronics.stackexchange.com  \n\n# \n\"STM32 \" site:cnblogs.com  \n\"STM32 \" site:csdn.net  \n```\n\n#### ****  \n- `cheap`, `buy`, `price`, `amazon`, `aliexpress`  \n- `crack`, ``, `keygen`  \n- `Arduino`  \n\n---\n\n### **4. **  \n\n#### ****  \n **STMicroelectronics **  \n- [www.st.com](https://www.st.com)  Products  Microcontrollers  STM32  \n-   \n  - *STM32 Overview*  \n  - *Reference Manual* RM0433 for STM32F4  \n  - *STM32CubeMX*   \n\n#### ****  \n- ****  \n  - EEVblogHackadayElectronics Stack Exchange  \n  - CSDN  \n- ****  \n  - CourseraEmbedded Systems Essentials  \n  - YouTubeSTM32 for Beginners by GreatScott!DroneBot Workshop  \n- ****  \n  - STM32  \n\n#### ****  \n **1**  \n- LED  \n ****  \n\n **2**  \n- STM32F1STM32H7STM32  \n ****STM32 family overviewSTM32 series comparison  \n\n **3**  \n- 2015StdPeriphHAL/LL  \n ****2020HAL librarySTM32Cube  \n\n---\n\n### ****  \n1. **** [ST STM32](https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html)OverviewProduct Selection Guide  \n2. ****Google `site:st.com \"STM32\" introduction filetype:pdf`PDF  \n3. ****YouTube `STM32 introduction for beginners 2024`510  \n4. ****STM32 Reference Manual1Overview2Architecture  \n\n>  ****STM32        \n\n--- \n\nSTM32", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T19:12:08.187428 #21052]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T19:12:08.187450 #21052]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T19:12:08.187471 #21052]  INFO -- : Create Conversation
I, [2025-12-09T19:12:08.187519 #21052]  INFO -- : Use template pre_search
I, [2025-12-09T19:12:08.188233 #21052]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:12:08.188308 #21052]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:12:10.681011 #21052]  INFO -- : Successful send a message
I, [2025-12-09T19:12:10.681168 #21052]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:12:12.683840 #21052]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:12:12.684063 #21052]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:12:15.233174 #21052]  INFO -- : Successful send a message
I, [2025-12-09T19:12:15.233302 #21052]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:12:19.237731 #21052]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:12:19.237874 #21052]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:12:21.154912 #21052]  INFO -- : Successful send a message
I, [2025-12-09T19:12:21.154999 #21052]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:12:21.155086 #21052]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T19:12:21.155125 #21052] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T19:12:21.155174 #21052] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T19:13:04.629856 #21521]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:13:04.629951 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.629991 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.629997 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630007 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630012 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630019 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630024 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630053 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630077 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630091 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630097 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630105 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630110 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630123 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630128 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630139 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.630160 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.630213 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.745745 #21521]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:13:04.745816 #21521]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:13:04.746458 #21521]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:13:04.746515 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746539 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746544 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746552 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746556 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746562 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746566 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746588 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746605 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746627 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746644 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746656 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746672 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746700 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746725 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746743 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.746758 #21521]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:13:04.746784 #21521]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:13:04.747020 #21521]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:13:04.747050 #21521]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:13:24.709538 #21521]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"stm32", :with_history=>true}
I, [2025-12-09T19:13:24.709566 #21521]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T19:13:24.709578 #21521]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T19:13:24.709595 #21521]  INFO -- : Create Conversation
I, [2025-12-09T19:13:24.709645 #21521]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T19:13:24.710024 #21521]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:13:24.710070 #21521]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:13:36.273510 #21521]  INFO -- : Successful send a message
I, [2025-12-09T19:13:36.273590 #21521]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:13:36.273609 #21521]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T19:13:36.273864 #21521]  INFO -- : Calling worker: pre_search with params: {:text=>"stm32\n\n---\n\n### **1. **\n\n** + **\n\n- ****  \n  stm32****  \n  - MCU  \n  - STM32XX  \n  - STM32  \n  - ********\n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| ** vs ** | ********STEEVblogHackaday |\n| **** | ****STM32STM32U5H7Cortex-M3 |\n| **** | ******STMicroelectronics**DatasheetReference ManualApplication NotesStack OverflowElectronics Stack ExchangeAll About CircuitsEmbedded.com |\n\n---\n\n### **3. **\n\n|  |  |\n|------|------------------|\n| **** | `STM32`, `STMicroelectronics STM32`, `ARM Cortex-M STM32` |\n| **** | `microcontroller`, `MCU`, `embedded system`, `peripherals (GPIO, UART, SPI, I2C)`, `cubeMX`, `HAL library`, `firmware development`, `bootloader`, `pinout`, `clock tree` |\n| **** | - `site:st.com \"STM32\" introduction`<br>- `site:st.com filetype:pdf \"STM32 reference manual\"`<br>- `intitle:\"STM32 overview\" site:electronics.stackexchange.com`<br>- `\"STM32\" AND (\"architecture\" OR \"features\") -buy -price -amazon` |\n| **** | `buy`, `price`, `cheap`, `amazon`, `aliexpress`, `review`, `test`, `comparison` |\n\n>  ****  \n> `site:st.com \"STM32\" introduction architecture features`  \n> `intitle:\"STM32 tutorial\" filetype:pdf -buy`  \n> `\"STM32 microcontroller\" site:allaboutcircuits.com`\n\n---\n\n### **4. **\n\n|  |  |\n|------|------|\n| **** | **ST**STM32 Reference ManualRMDatasheetGetting StartedSTM32CubeMX |\n| **** | - ****EEVblog YouTubeEmbedded.fmHackaday<br>- ****Coursera/edXEmbedded Systems - Shape the World<br>- ****GitHubSTM32STM32CubeIDE |\n| **** | - ****STM32F4H7G0U5<br>- ****Standard Peripheral LibraryHAL/LL<br>- ****<br>- ****IDESTM32CubeIDEST-Link |\n\n---\n\n###  ****\n\n1. ****  \n    [https://www.st.com](https://www.st.com)   STM32   **Reference Manual**  **Datasheet** STM32F407  STM32F103 \n\n2. ****  \n    `intitle:\"STM32 overview\" site:allaboutcircuits.com`  **STYouTube** STM32 Introduction\n\n3. ****  \n    `site:st.com \"STM32CubeMX tutorial\"`\n\n4. ****  \n    Stack Exchange  Reddit  r/STM32 DMA\n\n>  ****STM32\n\n---\n\n****STM32", :with_history=>true}
I, [2025-12-09T19:13:36.273927 #21521]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T19:13:36.273936 #21521]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T19:13:36.273946 #21521]  INFO -- : Create Conversation
I, [2025-12-09T19:13:36.273968 #21521]  INFO -- : Use template pre_search
I, [2025-12-09T19:13:36.274284 #21521]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:13:36.274318 #21521]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:13:43.540328 #21521]  INFO -- : Successful send a message
I, [2025-12-09T19:13:43.540528 #21521]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:13:43.540642 #21521]  INFO -- : Worker pre_search executed successfully
I, [2025-12-09T19:13:44.142737 #21521]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1  \n  - [] `site:st.com \"STM32\" introduction architecture features`  STSTM32  \n  - [] `site:st.com filetype:pdf \"STM32 Reference Manual\"`  RM0433 for STM32F4  \n  - [] `intitle:\"STM32 overview\" site:allaboutcircuits.com`  All About Circuits  \n  - [] `site:youtube.com \"STMicroelectronics STM32 introduction\"`  STYouTubeSTM32  \n  - [] `site:st.com \"STM32CubeMX user manual\"`    \n\n- 2  \n  - [] `\"STM32 F1 vs F4\" site:electronics.stackexchange.com`  F1F4  \n  - [] `\"HAL library vs Standard Peripheral Library\" site:stackoverflow.com`    \n  - [] `\"STM32 clock tree configuration error\" site:st.com community`  ST  \n  - [] `\"STM32 bootloader address\" site:embedded.com`  0x08000000  \n\n- 3  \n  - [] `\"STM32 how to enable USART with CubeMX and HAL\" site:st.com`  STM32CubeMX+HAL  \n  - [] `\"STM32 DMA not working with UART\" site:stackoverflow.com`  DMA  \n  - [] `\"STM32 external crystal not starting\" site:st.com application note`  STAN2867  \n  - [] `\"STM32 low power mode wake-up source configuration\" site:st.com`  WKUPMCU  \n\n- 4  \n  - [] `site:st.com \"STM32F407 reference manual\" chapter 2 clock system`  F407PLLHSEHSI  \n  - [] `site:github.com \"STM32CubeIDE\" \"blink example\" language:c`  GPIOHAL  \n  - [] `site:st.com \"STM32 memory map\" filetype:pdf`  STM32FlashSRAM  \n  - [] `site:st.com \"STM32 NVIC priority grouping\" application note`  NVIC  \n  - [] `site:st.com \"STM32H7\" \"dual-core architecture\" technical brief`  H7Cortex-M7 + M4IPC", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T19:13:44.142851 #21521]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-09T19:13:44.142865 #21521]  INFO -- : Create worker's name is smart_search
I, [2025-12-09T19:13:44.142876 #21521]  INFO -- : Create Conversation
I, [2025-12-09T19:13:44.142901 #21521]  INFO -- : Use template smart_search
I, [2025-12-09T19:13:44.143116 #21521]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:13:44.143153 #21521]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:13:50.624991 #21521]  INFO -- : Successful send a message
I, [2025-12-09T19:13:50.625116 #21521]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:13:50.625143 #21521]  INFO -- : Worker smart_search executed successfully
E, [2025-12-09T19:13:50.625201 #21521] ERROR -- : Error executing worker smart_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T19:13:50.625243 #21521] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:24:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T19:19:55.871623 #23145]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:19:55.872206 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872246 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872253 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872262 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872288 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872299 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872304 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872329 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872345 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872370 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872378 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872386 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872390 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872403 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872408 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872418 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.872432 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.872460 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.991530 #23145]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:19:55.991609 #23145]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:19:55.992332 #23145]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:19:55.992408 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992450 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992458 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992469 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992473 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992479 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992482 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992505 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992528 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992558 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992583 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992595 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992600 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992614 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992636 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992653 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992670 #23145]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:19:55.992696 #23145]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:19:55.992941 #23145]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:19:55.992971 #23145]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:20:11.517220 #23145]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"stm32", :with_history=>true}
I, [2025-12-09T19:20:11.517249 #23145]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T19:20:11.517262 #23145]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T19:20:11.517277 #23145]  INFO -- : Create Conversation
I, [2025-12-09T19:20:11.517330 #23145]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T19:20:11.517693 #23145]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:20:11.517758 #23145]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:20:26.176526 #23145]  INFO -- : Successful send a message
I, [2025-12-09T19:20:26.176637 #23145]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:20:26.176659 #23145]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T19:20:26.778770 #23145]  INFO -- : Calling worker: pre_search with params: {:text=>"stm32\n\n---\n\n### **1. **  \n****  \n- ****  \n  STM32STM32  \n  ****/  \n  ****\n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** | ****STM32Cortex-MF0/F1/F4/F7/H7 |\n| **** | ****STM322023STM32U53STM32F1 |\n| **** | ****STMicroelectronicsIEEE/ACMARMEEVblogST |\n\n---\n\n### **3. **  \n\n#### ****  \n- `STM32 series`  \n- `STM32 microcontroller family`  \n- `STM32 overview`  \n- `STM32 architecture`  \n\n#### ****  \n- ****`Cortex-M0/M3/M4/M7/M33``ARM Cortex-M``flash memory``DMA``ADC``TIM`  \n- ****`STM32F0``STM32F1``STM32F4``STM32F7``STM32H7``STM32L4``STM32U5`  \n- ****`STM32CubeMX``STM32CubeIDE``HAL library``LL library``Keil MDK``IAR Embedded Workbench`  \n- ****`industrial control``IoT device``motor control``medical device`  \n\n#### ****  \n```plaintext\nintitle:\"STM32 series overview\"  \nsite:st.com \"STM32 microcontroller family\"  \nfiletype:pdf \"STM32 reference manual\"  \n\"STM32\" (\"F4\" OR \"H7\" OR \"L4\") (\"architecture\" OR \"differences\")  \nsite:arm.com \"STM32 Cortex-M\"  \n```\n\n#### ****  \n- `buy``price``where to buy`  \n- `Arduino``Raspberry Pi`  \n- `repair``fault`  \n- `tutorial`  \n\n---\n\n### **4. **  \n\n#### ****  \n **STMicroelectronics **  \n- `www.st.com  Products  Microcontrollers  STM32 32-bit ARM MCUs`  \n-   \n  - STM32 Reference ManualsRM0433 for STM32F7  \n  - STM32 Family OverviewPDF  \n  - STM32 Selection Guide  \n\n ****  \n- IEEE Xplore `\"STM32\" AND (\"overview\" OR \"taxonomy\")`  \n- Springer/ElsevierMaking Embedded Systems  \n- ARMCortex-MSTM32  \n\n#### ****  \n ****  \n- HackadayEEVblogEmbedded.fm   \n- GitHub  STM32   \n- Reddit r/STM32Stack Overflow   \n\n ****  \n- CSDN   \n- /  \n\n#### ****  \n ****STM32****F1=F4=L4=H7=  \n ****Standard Peripheral Library**HAL/LL**2018  \n ****STAnalog DevicesNXP  \n ****  \n\n---\n\n### ****  \n1. **** [st.com/stm32](https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html)  STM32 Selection GuideSTM32 Family OverviewPDF  \n2. **** Google Scholar  IEEE Xplore  `\"STM32 architecture overview\"`5  \n3. **** `site:st.com \"STM32F4\" reference manual`   \n4. **** Stack Overflow  EEVblog STM32 vs other MCUs  \n5. ****ST  \n\n>  ****STM32\n\n--- \n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T19:20:26.778901 #23145]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T19:20:26.778915 #23145]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T19:20:26.778927 #23145]  INFO -- : Create Conversation
I, [2025-12-09T19:20:26.778956 #23145]  INFO -- : Use template pre_search
I, [2025-12-09T19:20:26.779291 #23145]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:20:26.779332 #23145]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:20:29.307052 #23145]  INFO -- : Successful send a message
I, [2025-12-09T19:20:29.307137 #23145]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:20:31.309377 #23145]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:20:31.309466 #23145]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:20:35.788980 #23145]  INFO -- : Successful send a message
I, [2025-12-09T19:20:35.789079 #23145]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:20:39.793276 #23145]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:20:39.793365 #23145]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:20:42.204233 #23145]  INFO -- : Successful send a message
I, [2025-12-09T19:20:42.204318 #23145]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:20:42.204477 #23145]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T19:20:42.204526 #23145] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T19:20:42.204578 #23145] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T19:20:48.441968 #23590]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:20:48.442054 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442086 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442092 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442100 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442104 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442111 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442115 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442144 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442149 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442156 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442160 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442167 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442171 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442183 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442188 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442198 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.442202 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.442212 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.509772 #23590]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:20:48.509846 #23590]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:20:48.510170 #23590]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:20:48.510222 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510259 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510275 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510285 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510291 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510298 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510302 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510324 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510356 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510371 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510375 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510382 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510386 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510399 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510404 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510414 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510418 #23590]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:20:48.510428 #23590]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:20:48.510693 #23590]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:20:48.510723 #23590]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:21:46.665326 #23590]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Introduction to the STM32 series chips", :with_history=>true}
I, [2025-12-09T19:21:46.665350 #23590]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T19:21:46.665363 #23590]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T19:21:46.665380 #23590]  INFO -- : Create Conversation
I, [2025-12-09T19:21:46.665415 #23590]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T19:21:46.665807 #23590]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:21:46.665865 #23590]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:22:04.890326 #23590]  INFO -- : Successful send a message
I, [2025-12-09T19:22:04.890549 #23590]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:22:04.890600 #23590]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T19:22:05.493459 #23590]  INFO -- : Calling worker: pre_search with params: {:text=>" **Introduction to the STM32 series chips** \n\n---\n\n### **1. **\n\n **Technical / Professional Knowledge**\n\n- ****  \n  Introduction to the STM32 series chips STM32********\n- ****\n  - Introduction\n  - STM32 series chips\n  - \n\n>  ********\n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| ** vs ** | ********Stack OverflowEEVblog |\n| **** | ****STM32STM32U5H7WB35Cortex-M0/M3ARM Cortex-M |\n| **** | ******STMicroelectronics****ARM****IEEE/ACM******Making Embedded Systems****MIT OpenCourseWareCoursera |\n\n>  ****** +  + **++\n\n---\n\n### **3. **\n\n#### ****\n- `STM32 series`\n- `STM32 microcontroller introduction`\n- `STM32 family overview`\n- `STM32 architecture`\n\n#### ****\n- ****`ARM Cortex-M`, `Flash memory`, `DMA`, `RTC`, `USB OTG`, `Low-power modes`\n- ****`STM32F0`, `STM32F1`, `STM32F4`, `STM32H7`, `STM32L4`, `STM32U5`\n- ****`IoT`, `industrial control`, `motor control`, `wearables`\n- ****`STM32 tutorial`, `STM32 datasheet`, `STM32 reference manual`\n\n#### ****\n```plaintext\n# \nsite:st.com \"STM32 series\" introduction\nsite:st.com \"STM32 family\" overview\nfiletype:pdf \"STM32 reference manual\"\n\n# \nsite:edu \"STM32\" introduction lecture\nsite:ieee.org \"STM32\" architecture\n\n# \nintitle:\"Introduction to STM32\" \n\"STM32 microcontroller\" AND (\"overview\" OR \"guide\" OR \"tutorial\")\n\n# \n- \"forum\" -\"reddit\" -\"quora\" -\"blog\" -\"amazon\" -\"aliexpress\"\n```\n\n>  ****  \n> -  `site:st.com`   \n> -  `filetype:pdf`   \n> - \n\n---\n\n### **4. **\n\n#### ****\n- **STMicroelectronics **  \n  - [https://www.st.com](https://www.st.com)  Products  Microcontrollers  STM32 32-bit MCUs  \n  - **STM32 Reference Manuals (RM)****Datasheets****STM32 Overview White Paper**\n- **/**  \n  - Coursera: Embedded Systems EssentialsST  \n  - MIT OpenCourseWare: Microcontroller Systems  \n- ****  \n  - Mastering STM32by Carmine Noviello  \n  - The Definitive Guide to ARM Cortex-Mby Joseph YiuSTM32\n\n#### ****\n- **YouTube **  \n  - GreatScott!, Andreas Spiess, Electronics Hub+  \n- **GitHub **  \n  -  `STM32` + `getting started`README  \n- ****  \n  - Stack OverflowEEVblog\n\n#### ****\n|  |  |  |\n|------|------|----------|\n| **** | STM32 | F1/F4/H7/L4 |\n| **** |  |  |\n| **** | M0/M4/M7 | `Cortex-M0+` vs `Cortex-M4F` vs `Cortex-M7` |\n| **** | Keil/IAR/STM32CubeMX |  |\n\n---\n\n###  ****\n\n1. **** [ST STM32](https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html)STM32 Overview\n2. **** `site:st.com \"STM32 family\" overview filetype:pdf`\n3. ****Google ScholarIEEE Xplore `\"STM32 architecture\" introduction`\n4. ****Mastering STM32Coursera\n5. ********\n\n>  ********STM32\n\n--- \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T19:22:05.493646 #23590]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T19:22:05.493671 #23590]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T19:22:05.493688 #23590]  INFO -- : Create Conversation
I, [2025-12-09T19:22:05.493729 #23590]  INFO -- : Use template pre_search
I, [2025-12-09T19:22:05.494328 #23590]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:22:05.494446 #23590]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:22:08.632550 #23590]  INFO -- : Successful send a message
I, [2025-12-09T19:22:08.632713 #23590]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:22:10.635213 #23590]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:22:10.635423 #23590]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:22:15.060649 #23590]  INFO -- : Successful send a message
I, [2025-12-09T19:22:15.060735 #23590]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:22:19.065214 #23590]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:22:19.065393 #23590]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:22:22.184309 #23590]  INFO -- : Successful send a message
I, [2025-12-09T19:22:22.184432 #23590]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:22:22.184545 #23590]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T19:22:22.184631 #23590] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T19:22:22.184682 #23590] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-09T19:43:28.378192 #28609]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:43:28.378867 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.378913 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.378931 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.378943 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.378949 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.378957 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.378962 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.378989 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.379006 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.379033 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.379041 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.379049 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.379054 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.379080 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.379099 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.379132 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.379158 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.379186 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.494197 #28609]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:43:28.494271 #28609]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:43:28.494838 #28609]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-09T19:43:28.494909 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495088 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495151 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495167 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495183 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495196 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495202 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495229 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495253 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495267 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495274 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495282 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495287 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495354 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495393 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495415 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495431 #28609]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-09T19:43:28.495461 #28609]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-09T19:43:28.495721 #28609]  INFO -- : Configuration loaded successfully
I, [2025-12-09T19:43:28.495750 #28609]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-09T19:45:17.217155 #28609]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Introduction to the STM32 series chips", :with_history=>true}
I, [2025-12-09T19:45:17.217181 #28609]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-09T19:45:17.217197 #28609]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-09T19:45:17.217229 #28609]  INFO -- : Create Conversation
I, [2025-12-09T19:45:17.217293 #28609]  INFO -- : Use template analyze_search_scope
I, [2025-12-09T19:45:17.217735 #28609]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:45:17.217774 #28609]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:45:31.421873 #28609]  INFO -- : Successful send a message
I, [2025-12-09T19:45:31.422001 #28609]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:45:31.422036 #28609]  INFO -- : Worker analyze_search_scope executed successfully
I, [2025-12-09T19:45:32.024605 #28609]  INFO -- : Calling worker: pre_search with params: {:text=>" **Introduction to the STM32 series chips** \n\n---\n\n### **1. **\n\n **Technical Expertise / Educational Overview**\n\n- ****  \n  Introduction to the STM32 series chips **** STM32 STM32F4 ****\n- ****\n  - \n  - \n  - \n\n>  ****  \n> -   \n> - MCU  \n> -   \n> - \n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| ** vs ** | ********<br> / |\n| **** | ****<br> STM32  STM32U5STM32C03 Cortex-M  |\n| **** | ****<br>  **STMicroelectronics **<br> IEEE/ACM  ARMKeilIAR |\n\n>  \n\n---\n\n### **3. **\n\n####  ****\n- `STM32 series`\n- `STM32 introduction`\n- `STM32 overview`\n- `STM32 microcontroller family`\n- `STM32 architecture`\n\n####  ****\n- `Cortex-M`\n- `ARM`\n- `MCU` / `Microcontroller Unit`\n- `peripherals`UART, SPI, I2C, ADC, DMA\n- `STM32Cube`\n- `STM32F0/F1/F4/F7/H7/U5`\n\n####  ****\n```plaintext\n# \nsite:st.com \"STM32 series\" introduction\nsite:st.com \"STM32 overview\" filetype:pdf\n\n# /\nsite:edu \"STM32 introduction\" lecture\nsite:ieee.org \"STM32 microcontroller\" tutorial\n\n# \nintitle:\"STM32\" \"getting started\" -forum -reddit\n\n# \nfiletype:pdf \"STM32 reference manual\"\n```\n\n####  ****\n- `-forum -reddit -quora -youtube -amazon`//\n- `-repair -fix -error -bug`\n- `-price -buy -cheap`\n\n---\n\n### **4. **\n\n####  ****\n- **STMicroelectronics **  \n   [https://www.st.com](https://www.st.com)  Products  Microcontrollers  STM32  \n     \n  - **Reference Manual** RM0433 for STM32F4  \n  - **Data Sheet**  \n  - **STM32CubeMX**   \n  - **STM32 Overview Whitepaper / Brochure**\n\n- **/**  \n  - Mastering STM32Carmine Noviello  \n  - Coursera/edX  University of Colorado  \n  - ARM  Cortex-M \n\n####  ****\n- ****  \n  - Hackaday, Embedded.fm, GitHub  STM32  README   \n- ****  \n  -  `site:edu \"stm32 introduction\" pdf`PPT\n\n####  ****\n|  |  |  |\n|--------|------|----------|\n| **** |  |  +  |\n| **** | STM32 F4H7 | STM32 family overview |\n| **** | DMANVIC  | STM32 for beginnersSTM32 glossary |\n| **** |  |  |\n\n---\n\n###  ****\n\n1. **** [STMicroelectronics STM32 ](https://www.st.com/en/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html)  \n     **STM32 Product Overview PDF**  **STM32CubeMX User Manual**\n\n2. ****Google   \n   ```plaintext\n   site:st.com \"STM32 series\" introduction filetype:pdf\n   site:edu \"STM32 introduction\" lecture\n   ```\n\n3. ****  \n    Mastering STM32The Definitive Guide to ARM Cortex-M\n\n4. **** GitHub  `stm32 getting started`\n\n5. ****  \n   **Cortex-M F0/F1/F4/H7/U5   STM32Cube RTOS, HAL/LL**\n\n---\n\n**** STM32 STM32 DMA STM32  ESP32 ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-09T19:45:32.024821 #28609]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-09T19:45:32.024849 #28609]  INFO -- : Create worker's name is pre_search
I, [2025-12-09T19:45:32.024866 #28609]  INFO -- : Create Conversation
I, [2025-12-09T19:45:32.024906 #28609]  INFO -- : Use template pre_search
I, [2025-12-09T19:45:32.025440 #28609]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:45:32.025508 #28609]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:45:34.542543 #28609]  INFO -- : Successful send a message
I, [2025-12-09T19:45:34.542656 #28609]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:45:36.545050 #28609]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:45:36.545198 #28609]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:45:38.375717 #28609]  INFO -- : Successful send a message
I, [2025-12-09T19:45:38.375834 #28609]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:45:42.380105 #28609]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-09T19:45:42.380197 #28609]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-09T19:45:44.474255 #28609]  INFO -- : Successful send a message
I, [2025-12-09T19:45:44.474367 #28609]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-09T19:45:44.474431 #28609]  INFO -- : Worker pre_search executed successfully
E, [2025-12-09T19:45:44.474484 #28609] ERROR -- : Error executing worker pre_search: undefined method `dig' for nil:NilClass
D, [2025-12-09T19:45:44.474552 #28609] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:87:in `call_worker'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:103:in `call_worker'
/home/nix/SmartResearch/agents/smarter_search.rb:10:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli.rb:215:in `call_agent_simple'
/home/nix/SmartResearch/lib/smart_research_cli.rb:112:in `chat_mode'
/home/nix/SmartResearch/lib/smart_research_cli.rb:56:in `block in run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `loop'
/home/nix/SmartResearch/lib/smart_research_cli.rb:42:in `run'
/home/nix/SmartResearch/lib/smart_research_cli.rb:36:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:15:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T11:07:16.420381 #26611]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:07:16.421009 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421045 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421053 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421067 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421071 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421081 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421084 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421110 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421115 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421121 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421125 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421131 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421134 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421148 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421152 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421161 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.421165 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.421174 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557110 #26611]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:07:16.557173 #26611]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:07:16.557764 #26611]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:07:16.557812 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557839 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557844 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557851 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557856 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557862 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557866 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557889 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557894 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557901 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557905 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557911 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557915 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557926 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557934 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557944 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.557948 #26611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:07:16.557958 #26611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:07:16.558365 #26611]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:07:16.558395 #26611]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:08:46.589833 #27036]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:08:46.589948 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590016 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590023 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590031 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590036 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590043 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590100 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590128 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590135 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590142 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590147 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590199 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590206 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590220 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590224 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590234 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.590238 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.590285 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.667828 #27036]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:08:46.667889 #27036]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:08:46.668381 #27036]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:08:46.668429 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668451 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668456 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668462 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668466 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668472 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668476 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668540 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668558 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668570 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668575 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668583 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668587 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668599 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668603 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668613 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668620 #27036]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:08:46.668629 #27036]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:08:46.668907 #27036]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:08:46.668935 #27036]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:08:49.194726 #27036]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-10T11:08:49.194733 #27036]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:08:49.194740 #27036]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:08:49.194752 #27036]  INFO -- : Create Conversation
I, [2025-12-10T11:08:49.194780 #27036]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:08:49.195112 #27036]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:08:49.195146 #27036]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:09:00.575498 #27036]  INFO -- : Successful send a message
I, [2025-12-10T11:09:00.575585 #27036]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:09:00.575606 #27036]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:11:28.798962 #27848]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:11:28.799556 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799601 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799608 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799617 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799622 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799629 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799633 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799657 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799662 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799669 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799673 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799679 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799683 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799694 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799698 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799712 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.799716 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.799725 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.931683 #27848]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:11:28.931748 #27848]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:11:28.932399 #27848]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:11:28.932445 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932478 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932483 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932491 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932495 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932501 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932504 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932531 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932535 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932543 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932546 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932553 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932557 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932568 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932575 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932584 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932588 #27848]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:11:28.932598 #27848]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:11:28.932865 #27848]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:11:28.932892 #27848]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:11:31.080358 #27848]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-10T11:11:31.080367 #27848]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:11:31.080375 #27848]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:11:31.080453 #27848]  INFO -- : Create Conversation
I, [2025-12-10T11:11:31.080490 #27848]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:11:31.080849 #27848]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:11:31.080880 #27848]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:11:38.208170 #27848]  INFO -- : Successful send a message
I, [2025-12-10T11:12:31.997375 #28248]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:12:31.997467 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997500 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997506 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997519 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997524 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997531 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997535 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997559 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997564 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997571 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997576 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997582 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997586 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997598 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997602 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997616 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:31.997621 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:31.997630 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.058848 #28248]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:12:32.058913 #28248]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:12:32.059236 #28248]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:12:32.059272 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059291 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059297 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059305 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059309 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059316 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059322 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059353 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059370 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059382 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059389 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059397 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059402 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059429 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059446 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059474 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059490 #28248]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:12:32.059507 #28248]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:12:32.059749 #28248]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:12:32.059778 #28248]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:12:34.557607 #28248]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-10T11:12:34.557620 #28248]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:12:34.557631 #28248]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:12:34.557647 #28248]  INFO -- : Create Conversation
I, [2025-12-10T11:12:34.557682 #28248]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:12:34.558128 #28248]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:12:34.558163 #28248]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:12:41.658218 #28248]  INFO -- : Successful send a message
I, [2025-12-10T11:13:30.702112 #28611]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:13:30.702187 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702221 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702227 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702236 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702240 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702247 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702251 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702276 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702281 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702288 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702292 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702299 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702303 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702314 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702318 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702328 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.702333 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.702342 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.766426 #28611]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:13:30.766486 #28611]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:13:30.766946 #28611]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:13:30.766984 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767003 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767008 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767015 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767020 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767026 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767030 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767051 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767067 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767079 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767085 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767096 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767101 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767113 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767127 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767137 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767141 #28611]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:13:30.767151 #28611]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:13:30.767398 #28611]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:13:30.767419 #28611]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:13:33.367420 #28611]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"STM32", :with_history=>true}
I, [2025-12-10T11:13:33.367436 #28611]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:13:33.367445 #28611]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:13:33.367459 #28611]  INFO -- : Create Conversation
I, [2025-12-10T11:13:33.367489 #28611]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:13:33.367812 #28611]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:13:33.367845 #28611]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:13:40.359896 #28611]  INFO -- : Successful send a message
I, [2025-12-10T11:19:25.998818 #30002]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:19:25.998890 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.998920 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.998926 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.998935 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.998940 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.998947 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.998951 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.998971 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.998976 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.998982 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.998986 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.998993 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.998997 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.999010 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.999014 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.999024 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:25.999028 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:25.999037 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063068 #30002]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:19:26.063121 #30002]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:19:26.063497 #30002]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:19:26.063539 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063559 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063565 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063572 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063576 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063582 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063586 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063607 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063612 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063627 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063631 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063637 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063641 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063651 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063655 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063664 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063668 #30002]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:26.063677 #30002]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:26.063889 #30002]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:19:26.063912 #30002]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:19:40.977310 #30156]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:19:40.977381 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977410 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977415 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977457 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977467 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977476 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977480 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977501 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977505 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977516 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977519 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977527 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977531 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977544 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977548 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977557 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:40.977561 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:40.977571 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040039 #30156]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:19:41.040107 #30156]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:19:41.040407 #30156]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:19:41.040443 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040458 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040463 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040470 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040474 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040480 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040484 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040502 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040506 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040513 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040516 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040522 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040526 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040543 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040546 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040555 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040559 #30156]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:19:41.040568 #30156]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:19:41.040782 #30156]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:19:41.040805 #30156]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:20:41.156915 #30488]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:20:41.157000 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157036 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157042 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157051 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157056 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157063 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157068 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157095 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157102 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157110 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157114 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157120 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157125 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157136 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157141 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157153 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.157157 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.157167 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.222559 #30488]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:20:41.222623 #30488]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:20:41.222927 #30488]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:20:41.222969 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.222987 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.222993 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223000 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223004 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223010 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223016 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223060 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223085 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223104 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223118 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223133 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223148 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223170 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223225 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223247 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223272 #30488]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:20:41.223290 #30488]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:20:41.223557 #30488]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:20:41.223576 #30488]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:00.505804 #30919]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:22:00.505883 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.505917 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.505924 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.505934 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.505939 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.505946 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.505951 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.505974 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.505979 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.505987 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.505991 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.505998 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.506003 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.506015 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.506020 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.506030 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.506035 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.506049 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.573085 #30919]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:22:00.573146 #30919]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:00.573827 #30919]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:22:00.573876 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.573899 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.573904 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.573911 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.573916 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.573923 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.573940 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.573971 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.573976 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.574172 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.574198 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.574211 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.574216 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.574262 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.574280 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.574298 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.574305 #30919]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:00.574316 #30919]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:00.574563 #30919]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:22:00.574585 #30919]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:29.743195 #31071]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:22:29.743261 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743291 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743296 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743304 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743308 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743314 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743318 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743340 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743344 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743350 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743353 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743359 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743362 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743373 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743377 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743387 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.743391 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.743400 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.810562 #31071]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:22:29.810620 #31071]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:29.811064 #31071]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:22:29.811102 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811133 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811138 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811145 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811149 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811155 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811159 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811213 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811218 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811224 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811228 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811234 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811237 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811247 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811251 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811260 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811264 #31071]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:29.811272 #31071]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:29.811491 #31071]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:22:29.811513 #31071]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:39.512087 #31158]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:22:39.512160 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512189 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512202 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512210 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512214 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512220 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512224 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512244 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512248 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512254 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512258 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512263 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512267 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512279 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512286 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512298 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.512302 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.512311 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.579542 #31158]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:22:39.579604 #31158]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:39.580089 #31158]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:22:39.580124 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580141 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580146 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580153 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580157 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580163 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580166 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580201 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580218 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580229 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580235 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580241 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580245 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580257 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580261 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580269 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580273 #31158]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:22:39.580284 #31158]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:22:39.580499 #31158]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:22:39.580521 #31158]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:22:41.672417 #31158]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hi", :with_history=>true}
I, [2025-12-10T11:22:41.672425 #31158]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:22:41.672432 #31158]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:22:41.672443 #31158]  INFO -- : Create Conversation
I, [2025-12-10T11:22:41.672468 #31158]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:22:41.672849 #31158]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:22:41.672959 #31158]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:22:52.209678 #31158]  INFO -- : Successful send a message
I, [2025-12-10T11:22:52.209749 #31158]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:22:52.209766 #31158]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:27:19.459010 #32310]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:27:19.459593 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459627 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459634 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459642 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459647 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459654 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459658 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459681 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459686 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459693 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459697 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459703 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459707 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.459718 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.459724 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.461864 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.461910 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.461938 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587100 #32310]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:27:19.587165 #32310]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:27:19.587517 #32310]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:27:19.587551 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587582 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587588 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587595 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587600 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587608 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587613 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587633 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587638 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587644 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587649 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587655 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587660 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587670 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587674 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587684 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587688 #32310]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:27:19.587698 #32310]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:27:19.587917 #32310]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:27:19.587941 #32310]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:27:22.344884 #32310]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hi", :with_history=>true}
I, [2025-12-10T11:27:22.344892 #32310]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:27:22.344900 #32310]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:27:22.344911 #32310]  INFO -- : Create Conversation
I, [2025-12-10T11:27:22.345001 #32310]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:27:22.345309 #32310]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:27:22.345338 #32310]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:27:31.180187 #32310]  INFO -- : Successful send a message
I, [2025-12-10T11:27:31.180258 #32310]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:27:31.180274 #32310]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:28:11.101854 #32585]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:28:11.101959 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102009 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102019 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102032 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102039 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102055 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102062 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102094 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102122 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102139 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102148 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102160 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102168 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.102190 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.102197 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.104657 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.104717 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.104760 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.171654 #32585]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:28:11.171723 #32585]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:28:11.172063 #32585]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:28:11.172103 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172124 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172130 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172138 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172300 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172317 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172323 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172381 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172401 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172413 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172419 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172427 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172432 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172456 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172461 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172471 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172476 #32585]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:28:11.172485 #32585]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:28:11.172729 #32585]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:28:11.172752 #32585]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:28:13.625355 #32585]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hi", :with_history=>true}
I, [2025-12-10T11:28:13.625363 #32585]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:28:13.625371 #32585]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:28:13.625384 #32585]  INFO -- : Create Conversation
I, [2025-12-10T11:28:13.625413 #32585]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:28:13.625792 #32585]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:28:13.625830 #32585]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:28:22.077201 #32585]  INFO -- : Successful send a message
I, [2025-12-10T11:28:22.077277 #32585]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:28:22.077294 #32585]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:28:22.680029 #32585]  INFO -- : Calling worker: pre_search with params: {:text=>"true", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:28:22.680182 #32585]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:28:22.680201 #32585]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:28:22.680213 #32585]  INFO -- : Create Conversation
I, [2025-12-10T11:28:22.680248 #32585]  INFO -- : Use template pre_search
I, [2025-12-10T11:28:22.680621 #32585]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:28:22.680656 #32585]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:28:23.377886 #32585]  INFO -- : Successful send a message
I, [2025-12-10T11:28:23.378011 #32585]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:28:23.378086 #32585]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:34:07.540814 #1475]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:34:07.541368 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541416 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.541424 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541459 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.541469 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541477 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.541482 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541505 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.541513 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541521 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.541526 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541532 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.541537 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.541551 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.543779 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.543856 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.543876 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.543890 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.673545 #1475]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:34:07.673598 #1475]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:34:07.674173 #1475]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:34:07.674213 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674247 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674441 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674456 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674461 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674468 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674472 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674526 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674544 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674556 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674562 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674569 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674574 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674587 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674591 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674601 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674606 #1475]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:34:07.674615 #1475]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:34:07.674876 #1475]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:34:07.674907 #1475]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:34:10.331365 #1475]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"test", :with_history=>true}
I, [2025-12-10T11:34:10.331379 #1475]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:34:10.331386 #1475]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:34:10.331411 #1475]  INFO -- : Create Conversation
I, [2025-12-10T11:34:10.331438 #1475]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:34:10.331942 #1475]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:34:10.331993 #1475]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:34:19.579348 #1475]  INFO -- : Successful send a message
I, [2025-12-10T11:34:19.579436 #1475]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:34:19.579455 #1475]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:34:20.182254 #1475]  INFO -- : Calling worker: pre_search with params: {:text=>"true", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:34:20.182399 #1475]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:34:20.182422 #1475]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:34:20.182438 #1475]  INFO -- : Create Conversation
I, [2025-12-10T11:34:20.182477 #1475]  INFO -- : Use template pre_search
I, [2025-12-10T11:34:20.182980 #1475]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:34:20.183029 #1475]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:34:20.772435 #1475]  INFO -- : Successful send a message
I, [2025-12-10T11:34:20.772500 #1475]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:34:20.772551 #1475]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:36:40.216313 #2490]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:36:40.216405 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216436 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216445 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216454 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216459 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216482 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216486 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216510 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216515 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216522 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216526 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216533 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216538 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216549 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216554 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216568 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.216572 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.216581 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.280773 #2490]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:36:40.280834 #2490]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:36:40.281290 #2490]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:36:40.281338 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281356 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281361 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281369 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281373 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281379 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281383 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281403 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281412 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281419 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281423 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281437 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281442 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281453 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281458 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281468 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281472 #2490]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:36:40.281481 #2490]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:36:40.281706 #2490]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:36:40.281727 #2490]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:36:55.293498 #2490]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"\"test\"", :with_history=>true}
I, [2025-12-10T11:36:55.293507 #2490]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:36:55.293515 #2490]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:36:55.293530 #2490]  INFO -- : Create Conversation
I, [2025-12-10T11:36:55.293572 #2490]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:36:55.293964 #2490]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:36:55.293992 #2490]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:37:04.994439 #2490]  INFO -- : Successful send a message
I, [2025-12-10T11:37:04.994522 #2490]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:37:04.994540 #2490]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:39:05.154612 #3152]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:39:05.154898 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.154935 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.154942 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.154951 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.154957 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.154963 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.154968 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.154990 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.154996 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.155003 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.155007 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.155014 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.155018 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.155029 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.155034 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.155044 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.155048 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.155061 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.283966 #3152]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:39:05.284182 #3152]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:39:05.284767 #3152]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:39:05.284809 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284833 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284839 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284847 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284852 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284858 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284863 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284886 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284891 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284898 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284903 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284912 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284917 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284928 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284932 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284945 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.284950 #3152]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:39:05.284960 #3152]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:39:05.285201 #3152]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:39:05.285227 #3152]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:39:07.902667 #3152]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Hello, how are you?", :with_history=>true}
I, [2025-12-10T11:39:07.902675 #3152]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:39:07.902684 #3152]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:39:07.902696 #3152]  INFO -- : Create Conversation
I, [2025-12-10T11:39:07.902723 #3152]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:39:07.903032 #3152]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:39:07.903058 #3152]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:39:17.055190 #3152]  INFO -- : Successful send a message
I, [2025-12-10T11:39:17.055266 #3152]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:39:17.055281 #3152]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:40:18.729679 #3516]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:40:18.730275 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.730328 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.730351 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.730365 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.730370 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.730378 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.730382 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.730405 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.730411 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.730418 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.730422 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.730428 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.730433 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.732367 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.732477 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.732511 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.732517 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.732530 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.869467 #3516]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:40:18.869532 #3516]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:40:18.870153 #3516]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:40:18.870201 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870224 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870230 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870239 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870244 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870251 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870255 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870280 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870285 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870293 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870297 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870312 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870316 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870328 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870332 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870344 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870348 #3516]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:40:18.870358 #3516]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:40:18.870602 #3516]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:40:18.870627 #3516]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:40:21.569082 #3516]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Hello", :with_history=>true}
I, [2025-12-10T11:40:21.569091 #3516]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:40:21.569099 #3516]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:40:21.569112 #3516]  INFO -- : Create Conversation
I, [2025-12-10T11:40:21.569142 #3516]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:40:21.569505 #3516]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:40:21.569541 #3516]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:40:31.031029 #3516]  INFO -- : Successful send a message
I, [2025-12-10T11:40:31.031102 #3516]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:40:31.031120 #3516]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:41:57.783871 #4084]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:41:57.784133 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.784172 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.784179 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.784188 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.784193 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.784200 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.784207 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.784229 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.784234 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.784241 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.784245 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.784252 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.784257 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.786262 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.786341 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.786381 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.786388 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.786400 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909184 #4084]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:41:57.909241 #4084]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:41:57.909800 #4084]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:41:57.909840 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.909861 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909870 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.909878 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909932 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.909945 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909949 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.909972 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909977 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.909984 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909988 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.909994 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.909998 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.910009 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.910017 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.910027 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.910031 #4084]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:41:57.910040 #4084]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:41:57.910261 #4084]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:41:57.910286 #4084]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:42:00.128925 #4084]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-10T11:42:00.128937 #4084]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:42:00.128946 #4084]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:42:00.128957 #4084]  INFO -- : Create Conversation
I, [2025-12-10T11:42:00.128988 #4084]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:42:00.129286 #4084]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:42:00.129312 #4084]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:42:07.812768 #4084]  INFO -- : Successful send a message
I, [2025-12-10T11:42:07.812845 #4084]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:42:07.812862 #4084]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:42:50.233400 #4432]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:42:50.233486 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.233519 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.233525 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.233534 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.233538 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.233545 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.233549 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.233574 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.233579 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.233586 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.233591 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.233597 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.233602 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.235508 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.235570 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.235625 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.235640 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.235671 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.299578 #4432]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:42:50.299651 #4432]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:42:50.300093 #4432]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:42:50.300134 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300156 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300161 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300167 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300171 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300177 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300181 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300201 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300217 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300228 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300234 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300241 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300245 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300258 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300262 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300271 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300275 #4432]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:42:50.300284 #4432]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:42:50.300512 #4432]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:42:50.300532 #4432]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:42:52.927977 #4432]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Hello", :with_history=>true}
I, [2025-12-10T11:42:52.928001 #4432]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:42:52.928011 #4432]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:42:52.928023 #4432]  INFO -- : Create Conversation
I, [2025-12-10T11:42:52.928051 #4432]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:42:52.928357 #4432]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:42:52.928385 #4432]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:43:01.132718 #4432]  INFO -- : Successful send a message
I, [2025-12-10T11:43:01.132798 #4432]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:43:01.132815 #4432]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:43:01.734799 #4432]  INFO -- : Calling worker: pre_search with params: {:text=>"true", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:43:01.734959 #4432]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:43:01.734982 #4432]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:43:01.734999 #4432]  INFO -- : Create Conversation
I, [2025-12-10T11:43:01.735043 #4432]  INFO -- : Use template pre_search
I, [2025-12-10T11:43:01.735522 #4432]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:43:01.735575 #4432]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:43:02.325245 #4432]  INFO -- : Successful send a message
I, [2025-12-10T11:43:02.325341 #4432]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:43:02.325579 #4432]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:44:48.032161 #5007]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:44:48.032240 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.032277 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.032291 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.032372 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.032398 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.032409 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.032414 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.032452 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.032461 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.034655 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.034704 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.034719 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.034724 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.034748 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.034753 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.034763 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.034767 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.034776 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.103696 #5007]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:44:48.103757 #5007]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:44:48.104080 #5007]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:44:48.104113 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104134 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104139 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104145 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104150 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104156 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104159 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104179 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104184 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104191 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104195 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104201 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104204 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104215 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104219 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104228 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104232 #5007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:44:48.104240 #5007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:44:48.104467 #5007]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:44:48.104493 #5007]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:44:50.454967 #5007]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-10T11:44:50.454974 #5007]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:44:50.454986 #5007]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:44:50.454997 #5007]  INFO -- : Create Conversation
I, [2025-12-10T11:44:50.455035 #5007]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:44:50.455389 #5007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:44:50.455422 #5007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:44:58.701700 #5007]  INFO -- : Successful send a message
I, [2025-12-10T11:44:58.701866 #5007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:44:58.701896 #5007]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:44:59.303962 #5007]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### 1. ****  \n**/**  \n\n  \n- ****  \n- ****  \n- ****\n\n---\n\n### 2. ****  \n**N/A**  \n\n- ****  \n- ****  \n- ****  \n- ****  \n\n>  ****\n\n---\n\n### 3. ****  \n****  \n-   \n\n****  \n|  |  |\n|----------|------------|\n|  | AI |\n| / | QA |\n| / |  |\n|  |  |\n\n****  \n- `intitle:\"\" site:stackoverflow.com`    \n- `filetype:pdf \"\" methodology`    \n- `\"\" -site:wikipedia.org`    \n\n****  \n- `- - -`    \n\n>  ****\n\n---\n\n### 4. ****  \n\n****  \n- ****  \n\n****  \n1. ****AIAPI  \n2. ****/  \n3. ****App  \n4. **/**  \n\n****  \n-  **** vs WiFi  \n-  ****  \n-  ****  \n\n---\n\n###  ****\n\n|  |  |\n|------|----------|\n| 1 | **** |\n| 2 | ****  \n>  |\n| 3 | **** |\n| 4 | **** |\n\n---\n\n****  \n********  \n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:44:59.304067 #5007]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:44:59.304081 #5007]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:44:59.304092 #5007]  INFO -- : Create Conversation
I, [2025-12-10T11:44:59.304122 #5007]  INFO -- : Use template pre_search
I, [2025-12-10T11:44:59.304451 #5007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:44:59.304476 #5007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:45:01.510853 #5007]  INFO -- : Successful send a message
I, [2025-12-10T11:45:01.510937 #5007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:45:01.510992 #5007]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:45:02.113399 #5007]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1\n  - [] \n\n- 2\n  - [] \n\n- 3\n  - [] \n\n- 4\n  - [] \n\n---\n\n****  \n  \n****  \n> AI  \n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:45:02.113533 #5007]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T11:45:02.113549 #5007]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T11:45:02.113560 #5007]  INFO -- : Create Conversation
I, [2025-12-10T11:45:02.113582 #5007]  INFO -- : Use template smart_search
I, [2025-12-10T11:45:02.113797 #5007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:45:02.113826 #5007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:45:02.715020 #5007]  INFO -- : Successful send a message
I, [2025-12-10T11:45:02.715122 #5007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:45:02.715142 #5007]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T11:45:02.715746 #5007]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:45:02.715780 #5007]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T11:45:02.715792 #5007]  INFO -- : Create worker's name is summary
I, [2025-12-10T11:45:02.715805 #5007]  INFO -- : Create Conversation
I, [2025-12-10T11:45:02.715829 #5007]  INFO -- : Use template summarize
I, [2025-12-10T11:45:02.716112 #5007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:45:02.716146 #5007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:45:09.431171 #5007]  INFO -- : Successful send a message
I, [2025-12-10T11:45:09.431258 #5007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:45:09.431273 #5007]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T11:46:16.821250 #5416]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:46:16.821335 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.821371 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.821378 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.821387 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.821392 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.821399 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.821404 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.821434 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.821441 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.821452 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.821456 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.823279 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.823323 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.823353 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.823359 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.823370 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.823375 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.823385 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.890618 #5416]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:46:16.890680 #5416]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:46:16.891142 #5416]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:46:16.891180 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891198 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891204 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891212 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891216 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891223 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891228 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891275 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891280 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891287 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891292 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891298 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891303 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891314 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891318 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891328 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891333 #5416]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:46:16.891342 #5416]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:46:16.891562 #5416]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:46:16.891586 #5416]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:46:19.116727 #5416]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Ruby?", :with_history=>true}
I, [2025-12-10T11:46:19.116735 #5416]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:46:19.116743 #5416]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:46:19.116763 #5416]  INFO -- : Create Conversation
I, [2025-12-10T11:46:19.116788 #5416]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:46:19.117147 #5416]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:46:19.117178 #5416]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:46:30.114273 #5416]  INFO -- : Successful send a message
I, [2025-12-10T11:46:30.114341 #5416]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:46:30.114358 #5416]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:46:30.716604 #5416]  INFO -- : Calling worker: pre_search with params: {:text=>" **Ruby** \n\n---\n\n### **1. **  \n ****  \n\n- ****RubyRuby  \n- ****  \n  - Python/JavaScript  \n  -   \n  - RubyXX  \n  - Ruby  \n\n> ********\n\n---\n\n### **2. **  \n\n|  |  |  |\n|------|------|------|\n| ** vs ** | **** | GC |\n| **** | **** | Ruby2000Ruby 3.x |\n| **** | **** | ruby-lang.orgWikipediaIEEE/ACMMDNCourseraThe Well-Grounded Rubyist |\n\n> ********\n\n---\n\n### **3. **  \n\n|  | / |\n|------|----------------|\n| **** | `Ruby programming language`, `Ruby definition`, `what is Ruby` |\n| **** | `Ruby creator`, `Ruby history`, `Ruby features`, `Ruby vs Python`, `Ruby on Rails` |\n| **** | - `site:ruby-lang.org \"what is ruby\"`<br>- `intitle:\"what is Ruby\" programming`<br>- `filetype:pdf \"Ruby programming language introduction\"`<br>- `\"Ruby\" language \"object-oriented\" \"dynamic\"` |\n| **** | `-tutorial -course -download -install -beginner`<br>`-job -salary -career` |\n\n> ****  \n> `\"what is Ruby programming language\" site:ruby-lang.org`  \n> `\"Ruby language\" definition site:en.wikipedia.org`\n\n---\n\n### **4. **  \n\n|  |  |\n|------|------|\n| **** | ** + **<br>- Rubyruby-lang.orgAbout Ruby<br>- Ruby (programming language)<br>- Microsoft Learn / IBM Developer / Oracle |\n| **** | - The Ruby Programming Languageby Matz<br>- Stack Overflow What is Ruby?<br>- CourseraIntroduction to Ruby |\n| **** |  **1**Ruby on Rails<br> **2**dynamic typing<br> **3**AIRubyPython |\n\n> ****  \n> - Yukihiro Matsumoto  \n> - 1995  \n> -   \n> -   \n> - Web  \n\n---\n\n###  ****\n\n1. ****Google  \n   `site:ruby-lang.org \"what is Ruby\"`  \n      \n\n2. ****  \n   `intitle:\"Ruby programming language\" site:en.wikipedia.org`  \n      \n\n3. ****  \n    `\"Ruby language\" features \"dynamic typing\" \"object-oriented\"`  \n      \n\n4. ****  \n   `site:stackoverflow.com \"what is Ruby\"`  \n      \n\n> ********Ruby\n\n--- \n\n********", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:46:30.716763 #5416]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:46:30.716789 #5416]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:46:30.716805 #5416]  INFO -- : Create Conversation
I, [2025-12-10T11:46:30.716842 #5416]  INFO -- : Use template pre_search
I, [2025-12-10T11:46:30.717333 #5416]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:46:30.717375 #5416]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:46:31.888734 #5416]  INFO -- : Successful send a message
I, [2025-12-10T11:46:31.888815 #5416]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:46:31.888937 #5416]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:49:01.855321 #6074]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:49:01.855613 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.855660 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857512 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857634 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857648 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857657 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857663 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857689 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857695 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857702 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857707 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857714 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857718 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857730 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857735 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857754 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:01.857758 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:01.857768 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.039269 #6074]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:49:02.039490 #6074]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:49:02.040160 #6074]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:49:02.040205 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040231 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040236 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040243 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040248 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040253 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040257 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040280 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040285 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040291 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040295 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040301 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040306 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040316 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040321 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040333 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040337 #6074]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:49:02.040351 #6074]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:49:02.040579 #6074]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:49:02.040603 #6074]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:49:04.263339 #6074]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Ruby", :with_history=>true}
I, [2025-12-10T11:49:04.263353 #6074]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:49:04.263362 #6074]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:49:04.263376 #6074]  INFO -- : Create Conversation
I, [2025-12-10T11:49:04.263412 #6074]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:49:04.263729 #6074]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:49:04.263763 #6074]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:49:16.995605 #6074]  INFO -- : Successful send a message
I, [2025-12-10T11:49:16.995706 #6074]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:49:16.995726 #6074]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:49:17.597704 #6074]  INFO -- : Calling worker: pre_search with params: {:text=>" **Ruby** \n\n---\n\n### **1. **  \n ** + **  \n\n- **** Ruby   \n- ****Ruby  PythonJavaScript   \n\n>   Ruby  Ruby \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | ****<br> |\n| **** | ****<br>Ruby  1.9+  3.0+ refinementsRactors 5  Ruby 1.8  |\n| **** | ****<br>ruby-lang.orgThe Well-Grounded Rubyist RubyDoc.infoGitHub  |\n\n---\n\n### **3. **  \n\n####  ****  \n- `Ruby language features`  \n- `Ruby programming language characteristics`  \n- `Ruby syntax and design principles`\n\n####  ****  \n- dynamic typing  \n- object-oriented  \n- metaprogramming  \n- blocks and closures  \n- developer-friendly  \n- permissive syntax  \n- Ruby on Rails\n\n####  ****  \n```plaintext\n# \nsite:ruby-lang.org \"Ruby features\"  \nsite:ruby-doc.org \"language characteristics\"\n\n# \nfiletype:pdf \"Ruby language design\"  \nintitle:\"Ruby\" (\"features\" OR \"characteristics\")\n\n# \n\"the well-grounded rubyist\" features  \n\"why's poignant guide to ruby\" characteristics\n\n# \nsite:stackoverflow.com \"Ruby features explained\"  \nsite:medium.com \"Ruby design philosophy\"\n```\n\n####  ****  \n- `install` / `download` / `tutorial`  \n- `Rails` Web   \n- `best` / `worst` / `comparison`  \n- `job` / `salary`\n\n---\n\n### **4. **  \n\n####  ****  \n- **Ruby **ruby-lang.org  \n- ****The Well-Grounded Rubyist1-3  \n- **RubyDoc.info** `Object`, `Module`, `Proc`  \n- **Ruby (programming language)**\n\n####  ****  \n- **Stack Overflow ** What makes Ruby different from other languages?  \n- **** [Ruby Weekly](https://rubyweekly.com/) [Dev.to](https://dev.to/t/ruby)   \n- **** Google Scholar  Ruby language design  dynamic language evaluation\n\n####  ****  \n|  |  |  |\n|------|------|----------|\n| **** |  Rails  Ruby  |  \"Rails\" core Ruby  |\n| **** |  Ruby 1.8/1.9  `symbol.to_s`  |  Ruby 3.0+  |\n| **** | Ruby  | // |\n| **** | Principle of Least Surprise |  Ruby design philosophy  Yukihiro Matsumoto quotes |\n\n---\n\n###  ****  \n1. **** [https://www.ruby-lang.org/en/documentation/](https://www.ruby-lang.org/en/documentation/)   Ruby Language   \n2. **** Google   \n   ```  \n   site:ruby-doc.org \"Ruby language features\"  \n   ```  \n3. ****The Well-Grounded Rubyist1PDF   \n4. **** Stack Overflow   \n   ```  \n   \"Ruby features\" intitle:question site:stackoverflow.com  \n   ```  \n   >50 upvotes  \n\n>  **** vs Python\n\n--- \n\n**** Ruby ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:49:17.597834 #6074]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:49:17.597848 #6074]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:49:17.597863 #6074]  INFO -- : Create Conversation
I, [2025-12-10T11:49:17.597893 #6074]  INFO -- : Use template pre_search
I, [2025-12-10T11:49:17.598244 #6074]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:49:17.598275 #6074]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:49:19.518239 #6074]  INFO -- : Successful send a message
I, [2025-12-10T11:49:19.518351 #6074]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:49:19.518537 #6074]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:50:26.316312 #6520]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:50:26.316611 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.316659 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318526 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318545 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318551 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318558 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318563 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318590 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318595 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318601 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318606 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318612 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318616 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318627 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318631 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318641 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.318645 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.318654 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.453697 #6520]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:50:26.453758 #6520]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:50:26.454392 #6520]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:50:26.454436 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454466 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454471 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454478 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454482 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454487 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454492 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454513 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454518 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454524 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454528 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454534 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454537 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454548 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454552 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454565 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454569 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:50:26.454579 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:50:26.454816 #6520]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:50:26.454838 #6520]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:50:28.923815 #6520]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"MCP", :with_history=>true}
I, [2025-12-10T11:50:28.923827 #6520]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:50:28.923835 #6520]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:50:28.923848 #6520]  INFO -- : Create Conversation
I, [2025-12-10T11:50:28.923878 #6520]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:50:28.924177 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:28.924203 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:50:41.773409 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:41.773544 #6520]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:50:41.773562 #6520]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:50:42.375559 #6520]  INFO -- : Calling worker: pre_search with params: {:text=>"MCP\n\n---\n\n### **1. **  \n ****  \n- MCP****/****  \n-   \n- ****\n\n---\n\n### **2. **  \n- ****  \n  MCP ****  \n- ****  \n  ****  \n- ********  \n  AIMCP1  \n- ********  \n  MCP****\n\n---\n\n### **3. **  \n\n#### ****  \n- `MCP`  \n- `what is MCP`  \n- `MCP definition`  \n\n#### ****  \nMCP   \n|  |  |  |\n|------|----------|------|\n|  | **Metacarpophalangeal joint** |  |\n|  | **Master Control Program** | IBM |\n|  | **Multi-Channel Protocol** |  |\n|  | **Management Control Program** |  |\n| / | **Methyl CpG Binding Protein** |  |\n| / | **Minecraft Protocol** |  |\n| / | **Military Command Post** |  |\n\n>  ****\n\n#### ****  \n- `intitle:\"MCP\" definition`    \n- `\"MCP\" site:edu OR site:gov OR site:med`    \n- `\"MCP\" -game -minecraft -forum`    \n- `MCP filetype:pdf`    \n- `define:MCP`  Google\n\n#### ****  \n- `-game` `-minecraft` `-forum` `-reddit` `-quora`  \n- `-movie` `-music`  \n- `-MCP as a service`\n\n---\n\n### **4. **  \n\n#### ****  \n **/**  \n- `Metacarpophalangeal joint`  \n- ****  \n\n **/**  \n- `Master Control Program`  \n- `Multi-Channel Protocol`/  \n- `Methyl CpG Binding Protein`\n\n#### ****  \n- /`Management Control Program`  \n- /`Military Command Post`  \n- //MCPMCP Software\n\n#### ****  \n ****  \n- MCP ****  \n- ****MCPMicrosoft Certified Professional **MCP**  \n   ****MCPMicrosoft Certified Professional****\n\n ****  \n> **MCP**  \n> ********\n\n---\n\n###  ****\n\n1. ****  \n   - Google`define:MCP`  \n   - \n\n2. ****  \n   - `\"MCP\" definition site:edu site:gov site:med`  \n   - `\"MCP\" \"Microsoft Certified Professional\"`  \n   -  `site:ncbi.nlm.nih.gov` \n\n3. ****  \n   - `-game -forum -reddit -quora`\n\n4. ****  \n   - MCP  \n   - MCPITMCP\n\n---\n\n###    \n> ** +  + **  \n> ******IT**** + **\n\n****MCP", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:50:42.375676 #6520]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:50:42.375696 #6520]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:50:42.375707 #6520]  INFO -- : Create Conversation
I, [2025-12-10T11:50:42.375732 #6520]  INFO -- : Use template pre_search
I, [2025-12-10T11:50:42.376030 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:42.376059 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:50:44.167100 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:44.167204 #6520]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:50:44.167362 #6520]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:50:46.591898 #6520]  INFO -- : Calling worker: get_topic with params: {:topics=>"[]", :search_result=>"[{\"formattedUrl\":\"https://modelcontextprotocol.io/\",\"link\":\"https://modelcontextprotocol.io/\",\"snippet\":\"What is the Model Context Protocol (MCP)? ... MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.\",\"title\":\"What is the Model Context Protocol (MCP)? - Model Context Protocol\"},{\"formattedUrl\":\"https://www.anthropic.com/news/model-context-protocol\",\"link\":\"https://www.anthropic.com/news/model-context-protocol\",\"snippet\":\"Nov 25, 2024 ... The Model Context Protocol (MCP) is an open standard for connecting AI assistants to the systems where data lives, including content...\",\"title\":\"Introducing the Model Context Protocol \\\\ Anthropic\"},{\"formattedUrl\":\"https://en.wikipedia.org/wiki/Model_Context_Protocol\",\"link\":\"https://en.wikipedia.org/wiki/Model_Context_Protocol\",\"snippet\":\"The Model Context Protocol (MCP) is an  MCP was announced by  MCP defines a standardized framework for integrating AI systems with external data sources and...\",\"title\":\"Model Context Protocol - Wikipedia\"},{\"formattedUrl\":\"https://www.ibm.com/think/topics/model-context-protocol\",\"link\":\"https://www.ibm.com/think/topics/model-context-protocol\",\"snippet\":\"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools,...\",\"title\":\"What is Model Context Protocol (MCP)? | IBM\"},{\"formattedUrl\":\"https://www.descope.com/learn/post/mcp\",\"link\":\"https://www.descope.com/learn/post/mcp\",\"snippet\":\"Sep 5, 2025 ... The Model Context Protocol uses a client-server architecture partially inspired by the Language Server Protocol (LSP), which helps different...\",\"title\":\"What Is the Model Context Protocol (MCP) and How It Works\"},{\"formattedUrl\":\"https://www.reddit.com/.../still_confused_about_how_mcp_works_heres_th...\",\"link\":\"https://www.reddit.com/r/ClaudeAI/comments/1ioxu5r/still_confused_about_how_mcp_works_heres_the/\",\"snippet\":\"Feb 14, 2025 ... While it's cool to add pre-built MCP servers from github, what is mind-blowing is when you can create them on the fly. I gave Cline an API key...\",\"title\":\"Still Confused About How MCP Works? Here's the Explanation That ...\"},{\"formattedUrl\":\"https://zapier.com/blog/mcp/\",\"link\":\"https://zapier.com/blog/mcp/\",\"snippet\":\"Apr 4, 2025 ... Model Context Protocol (MCP) is a method of giving AI models the context they need and allowing them to take real action in other apps. So let's...\",\"title\":\"What is MCP (Model Context Protocol)? | Zapier\"},{\"formattedUrl\":\"https://medium.com/.../mcp-explained-the-new-standard-connecting-ai-to-e...\",\"link\":\"https://medium.com/@elisowski/mcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288\",\"snippet\":\"Apr 15, 2025 ... What Is MCP, Really? ... Model Context Protocol (MCP) is an open standard developed by Anthropic, the company behind Claude. While it may sound...\",\"title\":\"MCP Explained: The New Standard Connecting AI to Everything | by ...\"},{\"formattedUrl\":\"https://www.apollographql.com/docs/apollo-mcp-server/define-tools\",\"link\":\"https://www.apollographql.com/docs/apollo-mcp-server/define-tools\",\"snippet\":\"Define MCP Tools ... You can manually define the GraphQL operations that are exposed by Apollo MCP Server as MCP tools. You can define these operations using:.\",\"title\":\"Define MCP Tools - Apollo GraphQL Docs\"},{\"formattedUrl\":\"https://www.k2view.com/blog/mcp-server/\",\"link\":\"https://www.k2view.com/blog/mcp-server/\",\"snippet\":\"An MCP server manages the data communication between AI models and source systems. It implements conversational latency, which guarantees immediate response...\",\"title\":\"What is an MCP server?\"}]", :with_history=>false}
I, [2025-12-10T11:50:46.591977 #6520]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:50:46.591994 #6520]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T11:50:46.592014 #6520]  INFO -- : Create Conversation
I, [2025-12-10T11:50:46.592045 #6520]  INFO -- : Use template get_topic
I, [2025-12-10T11:50:46.592403 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:46.592446 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:50:46.804358 #6520] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:50:46.804497 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:46.804535 #6520]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:50:49.507486 #6520]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://pubmed.ncbi.nlm.nih.gov/11240971/\",\"link\":\"https://pubmed.ncbi.nlm.nih.gov/11240971/\",\"snippet\":\"Biomarkers and surrogate endpoints: preferred definitions and conceptual framework. Clin Pharmacol Ther. 2001 Mar;69(3):89-95. doi: 10.1067/mcp.2001.113989.\",\"title\":\"Biomarkers and surrogate endpoints: preferred definitions and ...\"},{\"formattedUrl\":\"https://www.mass.gov/.../310-CMR-400000-massachusetts-contingency-pla...\",\"link\":\"https://www.mass.gov/regulations/310-CMR-400000-massachusetts-contingency-plan\",\"snippet\":\"310 CMR 40.0000: Massachusetts Contingency Plan (\\\"MCP\\\"). Recently Promulgated Amendments. Final PFAS-Related Revisions to the MCP (2019)  Revisions to the...\",\"title\":\"310 CMR 40.0000: Massachusetts Contingency Plan | Mass.gov\"},{\"formattedUrl\":\"https://pubmed.ncbi.nlm.nih.gov/21628617/\",\"link\":\"https://pubmed.ncbi.nlm.nih.gov/21628617/\",\"snippet\":\"Updates on definition, consequences, and management of obstructive sleep apnea. Mayo Clin Proc. 2011 Jun;86(6):549-54; quiz 554-5. doi: 10.4065/mcp.2010.0810.\",\"title\":\"Updates on definition, consequences, and management of ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5084443/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5084443/\",\"snippet\":\"Oct 28, 2016 ... Meaning-Centered Psychotherapy (MCP) is a structured psychotherapeutic intervention originally developed by our group to target existential distress and...\",\"title\":\"Meaning-Centered Psychotherapy for Cancer Caregivers (MCP-C ...\"},{\"formattedUrl\":\"https://www.dhcs.ca.gov/.../DHCS-Community-Supports-Policy-Guide.pdf\",\"link\":\"https://www.dhcs.ca.gov/Documents/MCQMD/DHCS-Community-Supports-Policy-Guide.pdf\",\"snippet\":\"9 The MCP Contract sets forth the eligibility criteria and clinically oriented service definition for each Community Support. Greater detail, additional...\",\"title\":\"Community Supports Policy Guide: Volume 1\"},{\"formattedUrl\":\"https://www.dmv.ca.gov/portal/vehicle-industry.../motor-carrier-permits/\",\"link\":\"https://www.dmv.ca.gov/portal/vehicle-industry-services/motor-carrier-services-mcs/motor-carrier-permits/\",\"snippet\":\"The following types of drivers and/or vehicle operation do not require an MCP: Household goods and/or passenger carriers as defined in 5109 of the Public...\",\"title\":\"Motor Carrier Permits - California DMV\"},{\"formattedUrl\":\"https://www.dhcs.ca.gov/formsandpubs/Documents/.../APL21-011.pdf\",\"link\":\"https://www.dhcs.ca.gov/formsandpubs/Documents/MMCDAPLsandPolicyLetters/APL2021/APL21-011.pdf\",\"snippet\":\"8 The MCP must treat these grievances as appeals under federal regulations. MCPs must use the federal definition of appeal and comply with all existing state...\",\"title\":\"APL 21-011 (ca.gov)\"},{\"formattedUrl\":\"https://nvd.nist.gov/vuln/detail/CVE-2025-53100\",\"link\":\"https://nvd.nist.gov/vuln/detail/CVE-2025-53100\",\"snippet\":\"Jul 1, 2025 ... 2, the MCP server is written in a way that is vulnerable to command injection attacks as part of some of its MCP Server tools definition and...\",\"title\":\"CVE-2025-53100 - NVD\"},{\"formattedUrl\":\"https://www.dhcs.ca.gov/formsandpubs/Documents/.../APL23-020.pdf\",\"link\":\"https://www.dhcs.ca.gov/formsandpubs/Documents/MMCDAPLsandPolicyLetters/APL2023/APL23-020.pdf\",\"snippet\":\"Jul 26, 2023 ... 12 HSC sections 1371(a)(4) and 1371.35(e). 13 See definition of Working Days at MCP Contract, Exhibit E, Attachment 1. 14 HSC section 1371 (a)(...\",\"title\":\"DATE: October 12, 2023 ALL PLAN LETTER 23-020 (REVISED) TO ...\"},{\"formattedUrl\":\"https://www.cms.gov/files/document/mcp-rfa.pdf\",\"link\":\"https://www.cms.gov/files/document/mcp-rfa.pdf\",\"snippet\":\"Aug 14, 2023 ... This Request for Applications (RFA) introduces Making Care Primary (MCP), a new Center for Medicare and Medicaid Innovation (CMS Innovation...\",\"title\":\"Making Care Primary Request for Applications Version: 1\"}]", :with_history=>false}
I, [2025-12-10T11:50:49.507527 #6520]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:50:49.507571 #6520]  INFO -- : Use template get_topic
I, [2025-12-10T11:50:49.507955 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:49.508005 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:50:49.699411 #6520] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:50:49.699492 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:49.699511 #6520]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:50:51.795541 #6520]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.reddit.com/r/microsoft/comments/r02w58/mcp_certification/\",\"link\":\"https://www.reddit.com/r/microsoft/comments/r02w58/mcp_certification/\",\"snippet\":\"Nov 23, 2021 ... How do I find info about the MCP (Microsoft Certified Professional) certification? Heard about it but can't seem to find it on microsoft's website or anywhere...\",\"title\":\"MCP certification : r/microsoft\"},{\"formattedUrl\":\"https://en.wikipedia.org/wiki/Microsoft_Certified_Professional\",\"link\":\"https://en.wikipedia.org/wiki/Microsoft_Certified_Professional\",\"snippet\":\"In the 2020s, Microsoft announced that it was retiring all existing Microsoft Certified Professional (MCP), Microsoft Certified Solutions Developer (MCSD)...\",\"title\":\"Microsoft Certified Professional - Wikipedia\"},{\"formattedUrl\":\"https://www.certifiedskills.academy/microsoft-certified-professional/\",\"link\":\"https://www.certifiedskills.academy/microsoft-certified-professional/\",\"snippet\":\"Nov 22, 2019 ... Microsoft Certified Professional (MCP) certification validates IT professional and developer technical expertise through rigorous, industry-proven, and...\",\"title\":\"What is Microsoft Certified Professional (MCP) certification?\"},{\"formattedUrl\":\"https://learn.microsoft.com/en.../microsoft-certified-professional-certificates\",\"link\":\"https://learn.microsoft.com/en-us/answers/questions/849499/microsoft-certified-professional-certificates\",\"snippet\":\"May 14, 2022 ... Microsoft Certified Professional Certificates. Rolens Carry 1 ... mcp/forum/mcp_prof-mcp_mcid. Certification Profile/Account Linking...\",\"title\":\"Microsoft Certified Professional Certificates - Microsoft Q\\u0026A\"},{\"formattedUrl\":\"https://devblogs.microsoft.com/.../how-to-link-your-mcp-profile-to-a-partn...\",\"link\":\"https://devblogs.microsoft.com/premier-developer/how-to-link-your-mcp-profile-to-a-partner-organization/\",\"snippet\":\"Mar 22, 2019 ... Anyone who has ever passed at least one of the Microsoft certification exams has a Microsoft Certified Professional (MCP) profile created with...\",\"title\":\"How to link your MCP profile to a partner organization - Developer ...\"},{\"formattedUrl\":\"https://learn.microsoft.com/.../how-can-i-retrieve-my-mcp-details-if-they-n...\",\"link\":\"https://learn.microsoft.com/en-us/answers/questions/1705944/how-can-i-retrieve-my-mcp-details-if-they-not-appe\",\"snippet\":\"Jun 19, 2024 ... Since February 2019, Microsoft have decommissioned the issuance of MCP (Microsoft Certified Professional) certification and have replaced it...\",\"title\":\"How can i retrieve my MCP details if they not appearing on my ...\"},{\"formattedUrl\":\"https://www.webopedia.com/definitions/microsoft-certified-professional/\",\"link\":\"https://www.webopedia.com/definitions/microsoft-certified-professional/\",\"snippet\":\"Sep 10, 2010 ... An MCP is an individual who completes a certification program by Microsoft ... A Microsoft Certified Professional is a person who completes a...\",\"title\":\"What is MCP? | Webopedia\"},{\"formattedUrl\":\"https://learn.microsoft.com/en-us/.../where-are-all-my-achieved-certification...\",\"link\":\"https://learn.microsoft.com/en-us/answers/questions/1476181/where-are-all-my-achieved-certifications\",\"snippet\":\"Jan 3, 2024 ... Use the same credentials you used on the old MCP (Microsoft Certified Professional) site. Access your profile: Once signed in, click on your...\",\"title\":\"Where are all my achieved certifications? - Microsoft Q\\u0026A\"},{\"formattedUrl\":\"https://trainingsupport.microsoft.com/.../mcp/.../1dfeaafc-7116-46e0-bae0-...\",\"link\":\"https://trainingsupport.microsoft.com/en-us/mcp/forum/all/how-can-i-find-my-certifications/1dfeaafc-7116-46e0-bae0-ae7e6a71f6fe\",\"snippet\":\"Jan 7, 2022 ... Copy and paste this link into the private window's address bar https://mcp.microsoft.com/mcp/home/migrate ... Microsoft Certified Professional...\",\"title\":\"How can I find my certifications? - Training, Certification, and ...\"},{\"formattedUrl\":\"https://learn.microsoft.com/.../request-for-pdf-copies-of-my-microsoft-certi...\",\"link\":\"https://learn.microsoft.com/en-us/answers/questions/5598876/request-for-pdf-copies-of-my-microsoft-certified-p\",\"snippet\":\"Oct 26, 2025 ... Request for PDF copies of my Microsoft Certified Professional (MCP) certifications  TS: Configuring Microsoft Windows Vista Client  Exam 620 ...\",\"title\":\"Request for PDF copies of my Microsoft Certified Professional (MCP ...\"}]", :with_history=>false}
I, [2025-12-10T11:50:51.795576 #6520]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:50:51.795602 #6520]  INFO -- : Use template get_topic
I, [2025-12-10T11:50:51.795875 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:51.795915 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:50:52.038343 #6520] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:50:52.038464 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:52.038494 #6520]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:50:54.397609 #6520]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://pubmed.ncbi.nlm.nih.gov/37245426/\",\"link\":\"https://pubmed.ncbi.nlm.nih.gov/37245426/\",\"snippet\":\"... (Mcp-1), interleukin (IL)-1, IL-6, and increased the level of endothelial ... Methyl-CpG-Binding Protein 2.\",\"title\":\"Exercise-induced endothelial Mecp2 lactylation suppresses ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC4422180/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC4422180/\",\"snippet\":\"... MCP-3 in spinal cord [46]. Interleukin 6 may be involved in this response as ... The MBD family is composed of methyl-CpG-binding protein 2 (MeCP2) and MBD14.\",\"title\":\"Epigenetic regulation of chronic pain - PMC\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC2808261/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC2808261/\",\"snippet\":\"... proteins such as tau, synucleins, and methyl CpG-binding protein 2. ... Articles from Molecular \\u0026 Cellular Proteomics : MCP are provided here courtesy of American...\",\"title\":\"Enrichment and Site Mapping of O-Linked N-Acetylglucosamine by ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC7353744/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC7353744/\",\"snippet\":\"Jul 11, 2020 ... ... MCP-1 protein levels were significantly higher in the MetS group. In ... Methylation status of CpG sites in the MCP-1 promoter is...\",\"title\":\"The role of DNA methylation in the pathogenesis of type 2 diabetes ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC4844557/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC4844557/\",\"snippet\":\"... MCP-1, adiponectin, high-sensitivity C-reactive protein, tumor necrosis ... methyl CpG binding protein 2. n-3 PUFA. omega-3 PUFA. SNP. single nucleotide...\",\"title\":\"The effects of omega-3 polyunsaturated fatty acids and genetic ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5798978/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5798978/\",\"snippet\":\"Perhaps MeCP2 is the mostly studied protein of the Methyl-CpG Binding Protein ... doi: 10.1074/mcp.M700170-MCP200. [DOI] [PubMed] [Google Scholar]; Tropea D...\",\"title\":\"Rett Syndrome and MeCP2 - PMC\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC7226738/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC7226738/\",\"snippet\":\"... protein 1 and repressed by methyl-CpG binding proteins. Nucleus. 2017;8:548 ... doi: 10.1074/mcp.M113.036392. [DOI] [PMC free article] [PubMed] [Google...\",\"title\":\"MeCP2 and Chromatin Compartmentalization - PMC\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC2652210/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC2652210/\",\"snippet\":\"doi: 10.1074/mcp.M700460-MCP200. [DOI] [PubMed] [Google Scholar]; Gygi S.P. ... methyl CpG binding protein Kaiso. Mol. Cell. 2003;12:723734. doi...\",\"title\":\"A SILAC-based DNA protein interaction screen that identifies ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC6685237/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC6685237/\",\"snippet\":\"Aug 7, 2019 ... ... (MCP-1), and adhesion molecules, e.g., intercellular adhesion ... methyl-CpGbinding domain protein 2. MCP-1. Monocyte chemoattractant...\",\"title\":\"Atherosclerosis and flow: roles of epigenetic modulation in vascular ...\"},{\"formattedUrl\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC1382219/\",\"link\":\"https://pmc.ncbi.nlm.nih.gov/articles/PMC1382219/\",\"snippet\":\"Abbreviations: MeCP  Methyl-CpG-binding protein, MBD  methyl-CpG binding domain. ... (MCP) by up-regulating NF-B activity (a). Oxidative stress can also prevent...\",\"title\":\"Epigenetics and airways disease - PMC\"}]", :with_history=>false}
I, [2025-12-10T11:50:54.397634 #6520]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:50:54.397663 #6520]  INFO -- : Use template get_topic
I, [2025-12-10T11:50:54.397891 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:54.397920 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:50:54.646768 #6520] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:50:54.646955 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:54.646999 #6520]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:50:57.098669 #6520]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.ibm.com/docs/en/zos/3.1.0?topic=iee399i-iee305i\",\"link\":\"https://www.ibm.com/docs/en/zos/3.1.0?topic=iee399i-iee305i\",\"snippet\":\"A command valid only at initial program load (IPL) was used after IPL. A ... control program (MCP). Source. Master scheduler. Module. IEEMB815, IEE0403D...\",\"title\":\"IEE305I\"},{\"formattedUrl\":\"https://community.ibm.com/.../debug-issues-in-machineconfig-when-installi...\",\"link\":\"https://community.ibm.com/community/user/cloudpakfordata/blogs/da-wei-zhang/2022/03/21/debug-issues-in-machineconfig-when-installing-clou\",\"snippet\":\"Mar 24, 2022 ... MCP Issues. When installing cloud pak for data, we can use this command to watch mcp status. watch -n1 'oc get mcp -o wide; echo; oc get node...\",\"title\":\"Debug issues in machineconfig when installing cloud pak for data\"},{\"formattedUrl\":\"https://research.ibm.com/people/frederico-araujo\",\"link\":\"https://research.ibm.com/people/frederico-araujo\",\"snippet\":\"We currently maintain and contribute to open-source projects in this space, including MCP Context Forge and BeeAI. ... control, compilers, programming languages,...\",\"title\":\"Fred Araujo - IBM Research\"},{\"formattedUrl\":\"https://www.redbooks.ibm.com/redbooks/pdfs/sg247156.pdf\",\"link\":\"https://www.redbooks.ibm.com/redbooks/pdfs/sg247156.pdf\",\"snippet\":\"May 16, 2006 ... ... Control Language (OCL) . . . 265. 10.4.3 Tivoli Workload Scheduler ... MCP. - Modify the Current Plan. 6 QCP. - Query the status of work in...\",\"title\":\"IBM Tivoli Workload Scheduler for z/OS Best Practices - End-to-end ...\"},{\"formattedUrl\":\"https://www.ibm.com/docs/en/rsct/3.2?topic=concepts-management...\",\"link\":\"https://www.ibm.com/docs/en/rsct/3.2?topic=concepts-management-domains-peer-domains\",\"snippet\":\"A management server is also known as a management control point (MCP). Consists of a number of nodes with no distinguished or master node. All nodes are...\",\"title\":\"Management domains and peer domains\"},{\"formattedUrl\":\"https://www.redbooks.ibm.com/redbooks/pdfs/sg245444.pdf\",\"link\":\"https://www.redbooks.ibm.com/redbooks/pdfs/sg245444.pdf\",\"snippet\":\"... Control Program. For. Layer 2 support, the z/VM Control Program owns the ... (MCP) cable. The MCP cables are 2 m long and have a link loss of up to 5.0...\",\"title\":\"IBM Z Connectivity Handbook\"},{\"formattedUrl\":\"https://www.ibm.com/docs/en/ts4500-tape-library?topic=information...\",\"link\":\"https://www.ibm.com/docs/en/ts4500-tape-library?topic=information-glossary\",\"snippet\":\"... program or system errors or malfunctions. Backup recovery and media ... See Medium Changer card pack. MCP: See Medium Changer card pack. mebibyte...\",\"title\":\"Glossary\"},{\"formattedUrl\":\"https://www.redbooks.ibm.com/redbooks/pdfs/sg246669.pdf\",\"link\":\"https://www.redbooks.ibm.com/redbooks/pdfs/sg246669.pdf\",\"snippet\":\"This prohibition includes ESCON Director control programs and ... infrastructure, the use of Mode Conditioning Patch (MCP) cables allows reuse of that.\",\"title\":\"IBM System z9 109 Technical Introduction\"},{\"formattedUrl\":\"https://www.ibm.com/docs/en/SSLTBW_2.4.0/pdf/ieah700_v2r4.pdf\",\"link\":\"https://www.ibm.com/docs/en/SSLTBW_2.4.0/pdf/ieah700_v2r4.pdf\",\"snippet\":\"Apr 6, 2021 ... ... program issues a completion code when abnormally ending ... MCP to build internal control blocks, or the PGFN macro failed for...\",\"title\":\"z/OS: z/OS MVS System Codes\"},{\"formattedUrl\":\"https://www.ibm.com/docs/SSRULV_9.3.0/com.ibm...9.../eqqi1mst.pdf\",\"link\":\"https://www.ibm.com/docs/SSRULV_9.3.0/com.ibm.tivoli.itws.doc_9.3/eqqi1mst.pdf\",\"snippet\":\"The IBM Workload Scheduler for z/OS Application Programming Interface (API) uses advanced program-to-program communication (APPC) services. ... MCP dialog to...\",\"title\":\"IBM Workload Scheduler for z/OS: Planning and Installation\"}]", :with_history=>false}
I, [2025-12-10T11:50:57.098696 #6520]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:50:57.098722 #6520]  INFO -- : Use template get_topic
I, [2025-12-10T11:50:57.098951 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:57.098982 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:50:57.362527 #6520] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:50:57.362615 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:50:57.362633 #6520]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:50:57.429109 #6520]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:50:57.429133 #6520]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T11:50:57.429141 #6520]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T11:50:57.429149 #6520]  INFO -- : Create Conversation
I, [2025-12-10T11:50:57.429171 #6520]  INFO -- : Use template generate_search_plan
I, [2025-12-10T11:50:57.429417 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:50:57.429463 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:51:14.373081 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:51:14.373186 #6520]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:51:14.373206 #6520]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T11:51:14.975885 #6520]  INFO -- : Calling worker: smart_search with params: {:text=>"### **MCP**\n\n---\n\n#### **1. **\n\n** **  \n- [] **MCP**Model Context ProtocolAI20242025AnthropicIBMZapierWikipedia  \n- [] **MCP**ITMicrosoft Certified Professional2019  \n- [] **MCP**Massachusetts Contingency PlanMeaning-Centered Psychotherapy//\n\n** **  \n- [] **MCPMethyl CpG Binding Protein**  \n- [] **IBMMaster Control Program**/IT  \n- [] **MCP/**Massachusetts Contingency Plan\n\n** **  \n- [] **WikipediaAnthropicIBMModel Context Protocol**  \n- [] **MCP**Microsoft LearnWikipedia2019  \n- [] **MCPPubMedMethyl CpG Binding ProteinMonocyte Chemoattractant Protein**MCP-1\n\n---\n\n#### **2. **\n\n** ****Model Context ProtocolAI**  \n- ****  \n  - **70%**AnthropicIBMWikipediaZapierApollo GraphQL  \n  - **20242025****2025MCP**  \n  - AI****\n\n** **  \n1. **Microsoft Certified ProfessionalIT**  \n   - ****MCPAZ  \n2. **Massachusetts Contingency Plan**  \n   - ****Mass.gov  \n3. **Meaning-Centered Psychotherapy**  \n   - ****NCBI/PubMed/\n\n** **  \n- **Minecraft Protocol**Reddit/  \n- **Military Command Post**/defense.govMCPMCPMilitary Command Post  \n- **Generic MCP Software**MCP\n\n---\n\n#### **3. **\n\n|  |  |\n|------|----------------|\n| **** | `\"Model Context Protocol\" definition`<br>`\"MCP\" \"Microsoft Certified Professional\" retired`<br>`\"MCP\" \"Massachusetts Contingency Plan\"`<br>`\"Methyl CpG Binding Protein\" MCP` |\n| **** | `What is MCP in AI?`<br>`Is Microsoft MCP certification still valid?`<br>`MCP meaning in environmental regulation`<br>`MCP protein in epigenetics` |\n| **** | `MCP` `` `` `` |\n| **** | `site:anthropic.com \"MCP\"`<br>`site:ibm.com \"Master Control Program\"`<br>`site:ncbi.nlm.nih.gov \"MCP\" AND \"protein\"`<br>`site:mass.gov \"MCP\" definition`<br>`\"MCP\" -game -minecraft -forum -reddit` |\n\n---\n\n#### **4. **\n\n** **  \n1. ****`\"Model Context Protocol\" definition`AI  \n2. ****`\"MCP\" \"Microsoft Certified Professional\" retired`  \n3. ****`\"MCP\" \"Massachusetts Contingency Plan\"`/  \n4. ****`\"Methyl CpG Binding Protein\" site:ncbi.nlm.nih.gov`  \n5. ****`\"Master Control Program\" site:ibm.com`  \n\n** **  \n- 3  \n- 10\n\n** **  \n- **1**AnthropicIBMMicrosoft LearnMass.govNCBI  \n- **2**PubMedPMC  \n- ****Reddit/  \n\n** **  \n- **Model Context Protocol****3**AnthropicIBMWikipedia**MCP**Microsoft Learn  \n- /Methyl CpG Binding Protein\n\n---\n\n#### **5. **\n\n|  |  |\n|------|------|\n| **** |  **1520**<br>- AIModel Context Protocol8<br>- 4<br>- /3<br>- 3 |\n| **** | - <br>- 20242025<br>-  |\n| **** | - **Anthropic.com**MCP<br>- **Microsoft Learn**<br>- **Mass.gov**<br>- **NCBI/PubMed**<br>- **Wikipedia** |\n\n---\n\n###  ****  \n> ****  \n> **1. **Model Context ProtocolAI2024Anthropic  \n> **2. **Microsoft Certified Professional2019AZ-900  \n> **3. **  \n> - Massachusetts Contingency Plan  \n> - Meaning-Centered Psychotherapy  \n> - Methyl CpG Binding ProteinMeCP2  \n\n> **Model Context Protocol******", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:51:14.976106 #6520]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T11:51:14.976141 #6520]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T11:51:14.976158 #6520]  INFO -- : Create Conversation
I, [2025-12-10T11:51:14.976285 #6520]  INFO -- : Use template smart_search
I, [2025-12-10T11:51:14.976725 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:51:14.976772 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:51:16.770381 #6520]  INFO -- : Successful send a message
I, [2025-12-10T11:51:16.770459 #6520]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:51:16.770475 #6520]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T11:51:19.056627 #6520]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://modelcontextprotocol.io/\",\"link\":\"https://modelcontextprotocol.io/\",\"snippet\":\"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or...\",\"title\":\"Model Context Protocol\"},{\"formattedUrl\":\"https://www.anthropic.com/news/model-context-protocol\",\"link\":\"https://www.anthropic.com/news/model-context-protocol\",\"snippet\":\"Nov 25, 2024 ... The Model Context Protocol (MCP) is an open standard for connecting AI assistants to the systems where data lives, including content...\",\"title\":\"Introducing the Model Context Protocol \\\\ Anthropic\"},{\"formattedUrl\":\"https://en.wikipedia.org/wiki/Model_Context_Protocol\",\"link\":\"https://en.wikipedia.org/wiki/Model_Context_Protocol\",\"snippet\":\"The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial...\",\"title\":\"Model Context Protocol - Wikipedia\"},{\"formattedUrl\":\"https://www.anthropic.com/engineering/code-execution-with-mcp\",\"link\":\"https://www.anthropic.com/engineering/code-execution-with-mcp\",\"snippet\":\"Nov 4, 2025 ... The Model Context Protocol (MCP) is an open standard for connecting ... definition with schemas) also helps the agent conserve context and find...\",\"title\":\"Code execution with MCP: building more efficient AI agents \\\\ Anthropic\"},{\"formattedUrl\":\"https://www.ibm.com/think/topics/model-context-protocol\",\"link\":\"https://www.ibm.com/think/topics/model-context-protocol\",\"snippet\":\"What is Model Context Protocol (MCP)?  Author  Tools provide meaning  MCP establishes a standard  MCP architecture  Benefits of MCP  The future of MCP.\",\"title\":\"What is Model Context Protocol (MCP)? | IBM\"},{\"formattedUrl\":\"https://github.com/modelcontextprotocol\",\"link\":\"https://github.com/modelcontextprotocol\",\"snippet\":\"The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.\",\"title\":\"Model Context Protocol  GitHub\"},{\"formattedUrl\":\"https://stytch.com/blog/model-context-protocol-introduction/\",\"link\":\"https://stytch.com/blog/model-context-protocol-introduction/\",\"snippet\":\"Mar 28, 2025 ... Model Context Protocol (MCP) is an open standard that bridges AI ... defined protocol. Building and deploying MCP servers. Building and...\",\"title\":\"Model Context Protocol (MCP): A comprehensive introduction for ...\"},{\"formattedUrl\":\"https://www.descope.com/learn/post/mcp\",\"link\":\"https://www.descope.com/learn/post/mcp\",\"snippet\":\"Sep 5, 2025 ... Relationship between function calling \\u0026 Model Context Protocol  Defining a consistent way to specify tools (functions) across any AI system.\",\"title\":\"What Is the Model Context Protocol (MCP) and How It Works\"},{\"formattedUrl\":\"https://cloud.google.com/discover/what-is-model-context-protocol\",\"link\":\"https://cloud.google.com/discover/what-is-model-context-protocol\",\"snippet\":\"Learn how the Model Context Protocol (MCP) standard allows LLMs to safely access external data and use tools, making AI more powerful and reliable.\",\"title\":\"What is Model Context Protocol (MCP)? A guide | Google Cloud\"},{\"formattedUrl\":\"https://aws.amazon.com/.../unlocking-the-power-of-model-context-protocol...\",\"link\":\"https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/\",\"snippet\":\"Jun 3, 2025 ... Communication flow between clients and servers follows a well-defined protocol that can run locally or remotely ... The Model Context Protocol (...\",\"title\":\"Unlocking the power of Model Context Protocol (MCP) on AWS ...\"}]", :with_history=>false}
I, [2025-12-10T11:51:19.056719 #6520]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:51:19.056763 #6520]  INFO -- : Use template get_topic
I, [2025-12-10T11:51:19.057101 #6520]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:51:19.057147 #6520]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:57:10.045658 #1573]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:57:10.046079 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.046121 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.046129 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048074 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048121 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048136 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048141 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048168 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048173 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048180 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048184 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048190 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048194 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048205 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048209 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048219 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.048223 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.048232 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.181537 #1573]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:57:10.181595 #1573]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:57:10.182392 #1573]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:57:10.182446 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182470 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182476 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182484 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182489 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182496 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182501 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182524 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182530 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182537 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182542 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182548 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182553 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182565 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182570 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182580 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182585 #1573]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:57:10.182596 #1573]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:57:10.182881 #1573]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:57:10.182912 #1573]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:57:12.653401 #1573]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Ruby", :with_history=>true}
I, [2025-12-10T11:57:12.653416 #1573]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:57:12.653434 #1573]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:57:12.653452 #1573]  INFO -- : Create Conversation
I, [2025-12-10T11:57:12.653491 #1573]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:57:12.653898 #1573]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:57:12.653933 #1573]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:57:25.268651 #1573]  INFO -- : Successful send a message
I, [2025-12-10T11:57:25.268723 #1573]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:57:25.268737 #1573]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:57:25.871078 #1573]  INFO -- : Calling worker: pre_search with params: {:text=>" **Ruby** \n\n---\n\n### **1. **\n\n** + **\n\n- ****Ruby\n- ****RubyRubyGemsRailsPython/JavaScript\n- ****\n  - \n  - \n  - \n\n>  ********\n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| ** vs ** | **** |\n| **** | ****Ruby3.0+Rails32010 |\n| **** | ****GitHubStack Overflow |\n\n>  ************\n\n---\n\n### **3. **\n\n#### ****\n- `Ruby programming language`\n- `Ruby language overview`\n- `Ruby programming basics`\n- `Ruby creator`Yukihiro Matsumoto\n- `Ruby on Rails`\n\n#### ****\n- RubyGems, Bundler, RVM, rbenv\n- Dynamic typing, metaprogramming, blocks, mixins\n- Object-oriented, functional programming in Ruby\n- Ruby 3.0 performance, JIT compiler\n\n#### ****\n```plaintext\n# \nsite:ruby-lang.org \"Ruby programming language\"\n\n# 5\n\"Ruby language\" after:2019\n\n# /PDF\nfiletype:pdf \"Ruby programming\" site:.edu OR site:.org\n\n# \n\"Ruby design philosophy\" intitle:\"Ruby\"\n\n# \nintitle:\"Learn Ruby\" site:rubyguides.com OR site:rubyonrails.org\n```\n\n#### ****\n- `download`\n- `free course`\n- `crack` / `keygen`\n- `Python` / `JavaScript`\n\n>  ****  \n> `\"Ruby programming language\" site:ruby-lang.org after:2019`  \n> `\"Ruby design philosophy\" intitle:\"Ruby\"`  \n> `filetype:pdf \"Ruby programming\" site:.edu`\n\n---\n\n### **4. **\n\n#### ****\n- ****[https://www.ruby-lang.org](https://www.ruby-lang.org)  \n- ****Ruby DocsRuby on Rails GuidesThe Well-Grounded Rubyist\n- ****Stack Overflow #rubyGitHubRuby\n- ****Yukihiro MatsumotoThe Ruby Programming LanguageFlanagan & Matsumoto\n\n#### ****\n- ****Ruby vs Python for web devRuby vs JavaScript in backend\n- ****Ruby in startupsRuby in legacy systemsRubys decline in popularity\n- ****Ruby on Rails\n\n#### ****\n|  |  |  |\n|------|------|----------|\n| **** | Ruby 2.x vs 3.x  | 2020JITRactors |\n| **Rails** | RailsRubyCLI | Ruby without RailsRuby standard library |\n| **** | Ruby | GitHubRuby WeeklyRubyConf |\n| **** |  | Ruby China |\n\n---\n\n###  ****\n\n1. **** [ruby-lang.org](https://www.ruby-lang.org) \n2. **** `site:ruby-lang.org \"Ruby language\"` + `after:2019` \n3. **** `filetype:pdf \"Ruby programming\" site:.edu` /\n4. ****Stack Overflow `ruby [language-design]`  `ruby vs python`\n5. **** [GitHub Octoverse](https://octoverse.github.com/)  [TIOBE Index](https://www.tiobe.com/tiobe-index/) Ruby\n6. **** `\"Ruby learning path 2024\"` + `site:freeCodeCamp.org`  `site:codenewbie.org`\n\n>  ********\n\n--- \n\nRuby", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:57:25.871249 #1573]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:57:25.871283 #1573]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:57:25.871300 #1573]  INFO -- : Create Conversation
I, [2025-12-10T11:57:25.871373 #1573]  INFO -- : Use template pre_search
I, [2025-12-10T11:57:25.871869 #1573]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:57:25.871907 #1573]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:57:29.647289 #1573]  INFO -- : Successful send a message
I, [2025-12-10T11:57:29.647388 #1573]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:57:29.647407 #1573]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:57:31.685059 #1573]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://try.ruby-lang.org/playground/\",\"link\":\"https://try.ruby-lang.org/playground/\",\"snippet\":\"Dec 7, 2024 ... Ruby Documentation. Welcome to the official Ruby programming language documentation. Getting Started. New to Ruby? Start with our Getting Started Guide. Core...\",\"title\":\"TryRuby playground\"},{\"formattedUrl\":\"https://try.ruby-lang.org/\",\"link\":\"https://try.ruby-lang.org/\",\"snippet\":\"Mar 8, 2020 ... Ruby is a programming language from Japan which is revolutionizing software development. The beauty of Ruby is found in its balance between simplicity and...\",\"title\":\"TryRuby: Learn programming with Ruby\"},{\"formattedUrl\":\"https://try.ruby-lang.org/?ref=jaminologist.com\",\"link\":\"https://try.ruby-lang.org/?ref=jaminologist.com\",\"snippet\":\"Apr 12, 2023 ... Ruby is a programming language from Japan which is revolutionizing software development. The beauty of Ruby is found in its balance between simplicity and power...\",\"title\":\"Learn programming with Ruby - TryRuby\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/en/3.2/security_rdoc.html\",\"link\":\"https://docs.ruby-lang.org/en/3.2/security_rdoc.html\",\"snippet\":\"Feb 24, 2023 ... The Ruby programming language is large and complex and there are many ... Ruby programs for configuration and database persistence of Ruby object trees.\",\"title\":\"security - Documentation for Ruby 3.2\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/en/3.3/\",\"link\":\"https://docs.ruby-lang.org/en/3.3/\",\"snippet\":\"Dec 26, 2023 ... Ruby is an interpreted object-oriented programming language often used for web development. It also offers many scripting features to process plain text and...\",\"title\":\"Documentation for Ruby 3.3\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2025/.../ruby-4-0-0-preview2-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2025/11/17/ruby-4-0-0-preview2-released/\",\"snippet\":\"Nov 17, 2025 ... Ruby 4.0 updates its Unicode version to 17,0.0, and so on. Language changes. *nil no longer calls nil.to_a , similar to how **nil does not call...\",\"title\":\"Ruby 4.0.0 preview2 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2022/12/06/ruby-3-2-0-rc1-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2022/12/06/ruby-3-2-0-rc1-released/\",\"snippet\":\"Dec 6, 2022 ... PubGrub is the next generation solving algorithm used by pub package manager for the Dart programming language. ... RubyGems still uses Molinillo resolver in Ruby...\",\"title\":\"Ruby 3.2.0 RC 1 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/\",\"snippet\":\"Dec 25, 2024 ... Language changes. String literals in files without a frozen_string_literal comment ... Merry Christmas, Happy Holidays, and enjoy programming with Ruby 3.4!\",\"title\":\"Ruby 3.4.0 Released\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/capi/en/master/d6/d84/rhash_8h.html\",\"link\":\"https://docs.ruby-lang.org/capi/en/master/d6/d84/rhash_8h.html\",\"snippet\":\"6 days ago ... This file is a part of the programming language Ruby. Permission is hereby granted, to either redistribute and/or modify this file, provided that the conditions...\",\"title\":\"include/ruby/internal/core/rhash.h File Reference - Ruby\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/capi/en/master/d9/dab/select_8h.html\",\"link\":\"https://docs.ruby-lang.org/capi/en/master/d9/dab/select_8h.html\",\"snippet\":\"Jul 27, 2024 ... This file is a part of the programming language Ruby. Permission is hereby granted, to either redistribute and/or modify this file, provided that the conditions...\",\"title\":\"include/ruby/internal/intern/select.h File Reference - Ruby\"}]", :with_history=>false}
I, [2025-12-10T11:57:31.685120 #1573]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:57:31.685132 #1573]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T11:57:31.685147 #1573]  INFO -- : Create Conversation
I, [2025-12-10T11:57:31.685173 #1573]  INFO -- : Use template get_topic
I, [2025-12-10T11:57:31.685474 #1573]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:57:31.685505 #1573]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:57:31.880988 #1573] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:57:31.881079 #1573]  INFO -- : Successful send a message
I, [2025-12-10T11:57:31.881100 #1573]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:57:34.410254 #1573]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.artima.com/articles/the-philosophy-of-ruby\",\"link\":\"https://www.artima.com/articles/the-philosophy-of-ruby\",\"snippet\":\"Sep 29, 2003 ... Yukihiro Matsumoto, the creator of the Ruby programming language, talks with Bill Venners about Ruby's design philosophy.\",\"title\":\"The Philosophy of Ruby - artima\"},{\"formattedUrl\":\"https://dev.to/hopsoft/ruby-is-designed-for-humans-2o4\",\"link\":\"https://dev.to/hopsoft/ruby-is-designed-for-humans-2o4\",\"snippet\":\"Jan 19, 2020 ... Honestly before trying Ruby I hadn't given much thought to what sort of philosophy lay behind language design. 1 like Like Reply. Code of...\",\"title\":\"Ruby is designed for humans - DEV Community\"},{\"formattedUrl\":\"https://medium.com/.../exploring-the-power-and-versatility-of-ruby-an-intr...\",\"link\":\"https://medium.com/@AlexanderObregon/exploring-the-power-and-versatility-of-ruby-an-introduction-to-the-programming-language-48eb37ab65de\",\"snippet\":\"Feb 16, 2023 ... The Philosophy of Ruby. Ruby's design philosophy centers around the idea that programming should be enjoyable for developers. Matz designed Ruby...\",\"title\":\"Exploring Ruby: A Versatile Programming Language | Medium\"},{\"formattedUrl\":\"https://www.reddit.com/r/ruby/.../design_principle_minimize_dependencies...\",\"link\":\"https://www.reddit.com/r/ruby/comments/1j6ihsg/design_principle_minimize_dependencies/\",\"snippet\":\"Mar 8, 2025 ... Dependency Inversion (DIP) and the Single Responsibility Principle (SRP) are valuable for structuring code to reduce internal coupling and...\",\"title\":\"Design Principle: Minimize Dependencies : r/ruby\"},{\"formattedUrl\":\"https://medium.com/.../solid-design-principles-in-ruby-8d039dbe2ef7\",\"link\":\"https://medium.com/@allegranzia/solid-design-principles-in-ruby-8d039dbe2ef7\",\"snippet\":\"Mar 17, 2019 ... This principle states that any class, module, etc. should have single responsibility over the function of a program. A class should only have one reason to...\",\"title\":\"SOLID Design Principles in Ruby. A quick rundown of SOLID and ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/ruby/comments/1fup5gu/good_ruby_books/\",\"link\":\"https://www.reddit.com/r/ruby/comments/1fup5gu/good_ruby_books/\",\"snippet\":\"Oct 2, 2024 ... So Ruby syntax, language features, best practices, styles, most popular packages, design philosophy for Ruby, that kind of thing. And after...\",\"title\":\"Good Ruby books? : r/ruby\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/about/\",\"link\":\"https://www.ruby-lang.org/en/about/\",\"snippet\":\"Ruby is a language of careful balance. Its creator, Yukihiro Matz Matsumoto, blended parts of his favorite languages (Perl, Smalltalk, Eiffel, Ada, and Lisp)\",\"title\":\"About Ruby\"},{\"formattedUrl\":\"https://www.honeybadger.io/blog/ruby-solid-design-principles/\",\"link\":\"https://www.honeybadger.io/blog/ruby-solid-design-principles/\",\"snippet\":\"Mar 15, 2021 ... SOLID design helps to decouple the code and make change less painful. It is important to design programs in such a way that they are decoupled, reusable, and...\",\"title\":\"SOLID Design Principles in Ruby - Honeybadger Developer Blog\"},{\"formattedUrl\":\"https://www.amazon.com/Practical-Object...Design-Ruby.../0321721330\",\"link\":\"https://www.amazon.com/Practical-Object-Oriented-Design-Ruby-Addison-Wesley/dp/0321721330\",\"snippet\":\"This book teaches techniques for writing maintainable, extensible, and pleasing Ruby applications using real-world object-oriented design principles and...\",\"title\":\"Practical Object-Oriented Design in Ruby: An Agile Primer (Addison ...\"},{\"formattedUrl\":\"https://www.ruby-hotels.com/en\",\"link\":\"https://www.ruby-hotels.com/en\",\"snippet\":\"Explore Europe in style with Ruby's characterful city-centre design hotels and workspaces ... Our Lean Luxury philosophy is at the heart of every Ruby...\",\"title\":\"Ruby Hotels \\u0026 Workspaces | Start your journey\"}]", :with_history=>false}
I, [2025-12-10T11:57:34.410277 #1573]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:57:34.410299 #1573]  INFO -- : Use template get_topic
I, [2025-12-10T11:57:34.410550 #1573]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:57:34.410575 #1573]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:57:34.595627 #1573] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:57:34.595709 #1573]  INFO -- : Successful send a message
I, [2025-12-10T11:57:34.595728 #1573]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:58:09.781289 #2007]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:58:09.781366 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.781403 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.781410 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783611 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783672 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783689 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783694 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783725 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783731 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783738 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783743 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783750 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783754 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783766 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783771 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783781 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.783786 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.783796 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.848937 #2007]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:58:09.849010 #2007]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:58:09.849842 #2007]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T11:58:09.849892 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.849929 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.849938 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.849945 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.849950 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.849957 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.849961 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.850036 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.850056 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.850069 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.850083 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.850090 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.850094 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.850108 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.850113 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.850122 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.850126 #2007]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T11:58:09.850136 #2007]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T11:58:09.850474 #2007]  INFO -- : Configuration loaded successfully
I, [2025-12-10T11:58:09.850503 #2007]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T11:58:12.058719 #2007]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Ruby?", :with_history=>true}
I, [2025-12-10T11:58:12.058728 #2007]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T11:58:12.058736 #2007]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T11:58:12.058749 #2007]  INFO -- : Create Conversation
I, [2025-12-10T11:58:12.058806 #2007]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T11:58:12.059128 #2007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:58:12.059161 #2007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:58:23.661718 #2007]  INFO -- : Successful send a message
I, [2025-12-10T11:58:23.661791 #2007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:58:23.661811 #2007]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T11:58:24.263829 #2007]  INFO -- : Calling worker: pre_search with params: {:text=>"Ruby?\n\n---\n\n### **1. **  \n ****  \n\n- ****Ruby/  \n- ****  \n  -   \n  -   \n  -   \n\n---\n\n### **2. **  \n- ****   \n  - ****Ruby   \n  -  Ruby  Ruby   \n\n- ****   \n  -  Rails****  \n\n- ****  \n  - Ruby 2000  \n\n- ****  \n  -  WikipediaRuby-lang.orgMDNIEEE/ACM   \n\n---\n\n### **3. **  \n\n####    \n- `Ruby`  \n- `programming language`  \n\n####    \n- `Yukihiro Matsumoto`  \n- `Ruby on Rails`  \n- `dynamic language` / `object-oriented` / `scripting language`  \n- `ruby gem`  \n- `red gemstone`  \n\n####    \n|  |  |  |\n|------|----------|------|\n|  | `\"What is Ruby\"` |  |\n|  | `Ruby programming language` |  |\n|  | `site:ruby-lang.org \"What is Ruby\"` |  |\n|  | `Ruby -gemstone -jewelry -color` |  |\n|  | `intitle:\"Ruby Programming\" site:ruby-lang.org` | Programming |\n\n####    \n- `gemstone`, `jewelry`, `red`, `color`, `name`  \n- `how to`, `install`, `tutorial`  \n\n---\n\n### **4. **  \n\n####  ****  \n- ****`ruby-lang.org`  About Ruby  What is Ruby?   \n- ****WikipediaRuby (programming language)TechTargetEncyclopedia Britannica  \n- ****MDN Web DocsJSStack Overflow   \n\n####  ****  \n- ****Ruby  \n- **** CourseraUdemy  Ruby   \n- **** HashiCorpGitHub Blog   \n\n####  ****  \n|  |  |  |\n|------|------|----------|\n| **** |  |  `programming language`  `site:ruby-lang.org`  |\n| **** |  |  |\n| **** |  Rails  |  |\n| **** |  Ruby  | 5 |\n\n---\n\n###  ****  \n> ****  \n> `site:ruby-lang.org \"What is Ruby\"`  \n> ****  \n> `\"Ruby programming language\" definition`  \n> ****  \n>  Wikipedia  Ruby (programming language)   \n> ****  \n>  `-gemstone -jewelry`  \n\n****  \n- Yukihiro Matsumoto  \n- 1995  \n-   \n- Web  \n\n**30**\n\n--- \n\nRuby  Python  Ruby********", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:58:24.263927 #2007]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T11:58:24.263943 #2007]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T11:58:24.263954 #2007]  INFO -- : Create Conversation
I, [2025-12-10T11:58:24.263981 #2007]  INFO -- : Use template pre_search
I, [2025-12-10T11:58:24.264283 #2007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:58:24.264317 #2007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:58:25.370941 #2007]  INFO -- : Successful send a message
I, [2025-12-10T11:58:25.371044 #2007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:58:25.371067 #2007]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T11:58:27.447900 #2007]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"snippet\":\"What is Ruby? Ruby is a simple and powerful object-oriented programming language, created by Yukihiro Matsumoto (who goes by the handle Matz in this...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/\",\"snippet\":\"Dec 25, 2024 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.4.0 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2022/12/25/ruby-3-2-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2022/12/25/ruby-3-2-0-released/\",\"snippet\":\"Dec 25, 2022 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.2.0 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2023/12/25/ruby-3-3-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2023/12/25/ruby-3-3-0-released/\",\"snippet\":\"Dec 25, 2023 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.3.0 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/\",\"snippet\":\"Dec 25, 2020 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993 and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.0.0 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2024/12/12/ruby-3-4-0-rc1-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2024/12/12/ruby-3-4-0-rc1-released/\",\"snippet\":\"Dec 12, 2024 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.4.0 rc1 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2020/.../ruby-3-0-0-preview2-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2020/12/08/ruby-3-0-0-preview2-released/\",\"snippet\":\"Dec 8, 2020 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.0.0 Preview 2 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2019/12/25/ruby-2-7-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2019/12/25/ruby-2-7-0-released/\",\"snippet\":\"Dec 25, 2019 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 2.7.0 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2021/12/25/ruby-3-1-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2021/12/25/ruby-3-1-0-released/\",\"snippet\":\"Dec 25, 2021 ... What is Ruby. Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple...\",\"title\":\"Ruby 3.1.0 Released\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2013/02/.../ruby-2-0-0-p0-is-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2013/02/24/ruby-2-0-0-p0-is-released/\",\"snippet\":\"Feb 24, 2013 ... What is Ruby 2.0.0. New Features. Some of the highlights: Language core features. Keyword arguments, which give flexibility to API design...\",\"title\":\"Ruby 2.0.0-p0 is released\"}]", :with_history=>false}
I, [2025-12-10T11:58:27.447933 #2007]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:58:27.447940 #2007]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T11:58:27.447954 #2007]  INFO -- : Create Conversation
I, [2025-12-10T11:58:27.447974 #2007]  INFO -- : Use template get_topic
I, [2025-12-10T11:58:27.448212 #2007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:58:27.448244 #2007]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:58:27.586133 #2007] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:58:27.586254 #2007]  INFO -- : Successful send a message
I, [2025-12-10T11:58:27.586341 #2007]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:58:29.434314 #2007]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://en.wikipedia.org/wiki/Ruby_(programming_language)\",\"link\":\"https://en.wikipedia.org/wiki/Ruby_(programming_language)\",\"snippet\":\"Ruby (programming language). Article  Talk. Language; Loading Download PDF ... defined for, a single instance rather than being defined on the class).\",\"title\":\"Ruby (programming language) - Wikipedia\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/\",\"link\":\"https://www.ruby-lang.org/en/\",\"snippet\":\"A dynamic, open source programming language with a focus on simplicity and productivity. It has an elegant syntax that is natural to read and easy to write.\",\"title\":\"Ruby Programming Language\"},{\"formattedUrl\":\"https://www.pluralsight.com/.../what-is-the-ruby-programming-language\",\"link\":\"https://www.pluralsight.com/resources/blog/cloud/what-is-the-ruby-programming-language\",\"snippet\":\"These programs are generally procedural in nature, meaning they are read from top to bottom. ... The Ruby programming language is a highly portable general-...\",\"title\":\"What is the Ruby programming language? | Online Courses ...\"},{\"formattedUrl\":\"https://www.geeksforgeeks.org/ruby/ruby-programming-language/\",\"link\":\"https://www.geeksforgeeks.org/ruby/ruby-programming-language/\",\"snippet\":\"Ruby Programming Language. Last Updated : 04 Sep, 2025 ... In this section, we'll explore Ruby methods, including how to define them, pass arguments,...\",\"title\":\"Ruby Programming Language - GeeksforGeeks\"},{\"formattedUrl\":\"https://www.oracle.com/developer/what-is-ruby-for-developers/\",\"link\":\"https://www.oracle.com/developer/what-is-ruby-for-developers/\",\"snippet\":\"You don't have to spend much time researching computing programming before you come across mentions of Ruby on Rails or the Ruby programming language. But...\",\"title\":\"What is Ruby?\"},{\"formattedUrl\":\"https://builtin.com/software-engineering.../ruby-programming-language\",\"link\":\"https://builtin.com/software-engineering-perspectives/ruby-programming-language\",\"snippet\":\"Nov 1, 2022 ... What Is the Ruby Programming Language? Ruby is a general-purpose ... This means there's no HTML file behind the URL you visit. This...\",\"title\":\"What Is the Ruby Programming Language? (Definition) | Built In\"},{\"formattedUrl\":\"https://www.reddit.com/.../fuzzy_ruby_server_10_release_an_lsp_for_large...\",\"link\":\"https://www.reddit.com/r/ruby/comments/17w1lo5/fuzzy_ruby_server_10_release_an_lsp_for_large/\",\"snippet\":\"Nov 16, 2023 ... ... definition lookups. Manually searching for definitions is just ... Celebrate the weird and wonderful Ruby programming language with us!\",\"title\":\"Fuzzy Ruby Server 1.0 release - An LSP for large codebases with ...\"},{\"formattedUrl\":\"https://www.quora.com/Ruby-programming-language-There-is-any-case-of...\",\"link\":\"https://www.quora.com/Ruby-programming-language-There-is-any-case-of-paid-gem\",\"snippet\":\"Jan 9, 2013 ... Ruby programming language is a primarily object-oriented programming language. ... What is the definition of a gem on Ruby on Rails? Gems...\",\"title\":\"Ruby (programming language): There is any case of paid gem ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../setting_up_vs_code_for_ruby_development_wit...\",\"link\":\"https://www.reddit.com/r/ruby/comments/1cgsxzh/setting_up_vs_code_for_ruby_development_with/\",\"snippet\":\"Apr 30, 2024 ... Navigate to definition on Cmd+Click. Documentation on hover. Code ... Celebrate the weird and wonderful Ruby programming language with us!\",\"title\":\"Setting up VS Code for Ruby development with theme, click to ...\"},{\"formattedUrl\":\"https://medium.com/.../what-is-the-purpose-of-attr-accessor-in-ruby-3bf3f4...\",\"link\":\"https://medium.com/@rossabaker/what-is-the-purpose-of-attr-accessor-in-ruby-3bf3f423f573\",\"snippet\":\"Mar 18, 2020 ... learning a ton about the Ruby programming language, I decided to dive deeper into the purpose of the attr_accessor method, what it does and...\",\"title\":\"What is the purpose of attr_accessor in Ruby? | by Ross Baker ...\"}]", :with_history=>false}
I, [2025-12-10T11:58:29.434366 #2007]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:58:29.434406 #2007]  INFO -- : Use template get_topic
I, [2025-12-10T11:58:29.434776 #2007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:58:29.434822 #2007]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:58:29.568077 #2007] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:58:29.568178 #2007]  INFO -- : Successful send a message
I, [2025-12-10T11:58:29.568200 #2007]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:58:31.581252 #2007]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://en.wikipedia.org/wiki/Ruby_(programming_language)\",\"link\":\"https://en.wikipedia.org/wiki/Ruby_(programming_language)\",\"snippet\":\"Ruby (programming language) ... Not to be confused with Ruby on Rails or Ruby (hardware description language). Ruby is a general-purpose programming language. It...\",\"title\":\"Ruby (programming language) - Wikipedia\"},{\"formattedUrl\":\"https://simple.wikipedia.org/wiki/Ruby_(programming_language)\",\"link\":\"https://simple.wikipedia.org/wiki/Ruby_(programming_language)\",\"snippet\":\"Ruby (programming language) ... Not to be confused with Ruby on Rails. Ruby is the name of a programming language that was created in the mid-1990s by Yukihiro \\\"...\",\"title\":\"Ruby (programming language) - Simple English Wikipedia, the free ...\"},{\"formattedUrl\":\"https://en.wikipedia.org/wiki/Ruby_on_Rails\",\"link\":\"https://en.wikipedia.org/wiki/Ruby_on_Rails\",\"snippet\":\"Not to be confused with Ruby (programming language). Ruby on Rails (simplified as Rails) is a server-side web application framework written in Ruby under...\",\"title\":\"Ruby on Rails - Wikipedia\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/\",\"link\":\"https://www.ruby-lang.org/en/\",\"snippet\":\"A dynamic, open source programming language with a focus on simplicity and productivity. It has an elegant syntax that is natural to read and easy to write.\",\"title\":\"Ruby Programming Language\"},{\"formattedUrl\":\"https://dev.to/eminarium/introducing-ruby-programming-language-27o4\",\"link\":\"https://dev.to/eminarium/introducing-ruby-programming-language-27o4\",\"snippet\":\"Oct 21, 2020 ... ... wikipedia.org/wiki/Yukihiro_Matsumoto, in 1995. ... This is the official web page of \\\"Ruby\\\" programming language https://www.ruby-lang.org/ .\",\"title\":\"Introducing Ruby Programming Language - DEV Community\"},{\"formattedUrl\":\"https://tech.churchofjesuschrist.org/forum/viewtopic.php?t=3422\\u0026start...\",\"link\":\"https://tech.churchofjesuschrist.org/forum/viewtopic.php?t=3422\\u0026start=10\",\"snippet\":\"... Ruby programming language: http://en.wikipedia.org/wiki/Yukihiro_Matsumoto  http://en.wikipedia.org/wiki/Ruby_(programming_language). This knowledge alone...\",\"title\":\"Mormons in Technology - Page 2 - Tech Forum\"},{\"formattedUrl\":\"https://en.wikibooks.org/wiki/Ruby_Programming\",\"link\":\"https://en.wikibooks.org/wiki/Ruby_Programming\",\"snippet\":\"Wikipedia has related information at Ruby Programming Language. Ruby ... Ruby programming language. Learning Ruby. edit  Ruby in Twenty Minutes - A small...\",\"title\":\"Ruby Programming - Wikibooks, open books for an open world\"},{\"formattedUrl\":\"https://ha.wikipedia.org/wiki/Ruby_(programming_language)\",\"link\":\"https://ha.wikipedia.org/wiki/Ruby_(programming_language)\",\"snippet\":\"Ruby (programming language) ; functional programming  Fassara , imperative programming  Fassara , object-oriented programming  Fassara da reflective programming...\",\"title\":\"Ruby (programming language) - Wikipedia\"},{\"formattedUrl\":\"https://tech.churchofjesuschrist.org/forum/viewtopic.php?t=3422\",\"link\":\"https://tech.churchofjesuschrist.org/forum/viewtopic.php?t=3422\",\"snippet\":\"... Ruby programming language: http://en.wikipedia.org/wiki/Yukihiro_Matsumoto  http://en.wikipedia.org/wiki/Ruby_(programming_language). Here's a great statement...\",\"title\":\"Mormons in Technology - Tech Forum\"},{\"formattedUrl\":\"http://wazza-is-awesome.com/.../how-i-learned-to-stop-worrying-and-love-t...\",\"link\":\"http://wazza-is-awesome.com/cloud/how-i-learned-to-stop-worrying-and-love-the-cloud.html\",\"snippet\":\"When I first read the list of language features in the [Wikipedia entry on the Ruby programming language](https://en.wikipedia.org/wiki/Ruby_(...\",\"title\":\"How I learned to stop worrying and love the cloud\"}]", :with_history=>false}
I, [2025-12-10T11:58:31.581276 #2007]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T11:58:31.581299 #2007]  INFO -- : Use template get_topic
I, [2025-12-10T11:58:31.581545 #2007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:58:31.581576 #2007]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T11:58:31.766137 #2007] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T11:58:31.766229 #2007]  INFO -- : Successful send a message
I, [2025-12-10T11:58:31.766249 #2007]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T11:58:31.818022 #2007]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T11:58:31.818060 #2007]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T11:58:31.818070 #2007]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T11:58:31.818079 #2007]  INFO -- : Create Conversation
I, [2025-12-10T11:58:31.818099 #2007]  INFO -- : Use template generate_search_plan
I, [2025-12-10T11:58:31.818348 #2007]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T11:58:31.818373 #2007]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T11:58:38.080120 #2007]  INFO -- : Successful send a message
I, [2025-12-10T11:58:38.080197 #2007]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T11:58:38.080213 #2007]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T12:00:32.472782 #2707]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:00:32.472992 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473044 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473051 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473060 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473065 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473071 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473075 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473098 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473103 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473110 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473114 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473120 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473124 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473134 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473138 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473148 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.473152 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.473161 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.540432 #2707]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:00:32.540497 #2707]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:00:32.541063 #2707]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:00:32.541104 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541125 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541130 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541137 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541141 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541148 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541152 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541173 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541178 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541184 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541188 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541194 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541198 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541209 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541214 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541223 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541227 #2707]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:00:32.541237 #2707]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:00:32.541540 #2707]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:00:32.541576 #2707]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:00:34.853476 #2707]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Ruby", :with_history=>true}
I, [2025-12-10T12:00:34.853509 #2707]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T12:00:34.853520 #2707]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T12:00:34.853533 #2707]  INFO -- : Create Conversation
I, [2025-12-10T12:00:34.853559 #2707]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T12:00:34.853856 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:00:34.853889 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:00:46.792264 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:00:46.792457 #2707]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:00:46.792507 #2707]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T12:00:47.394470 #2707]  INFO -- : Calling worker: pre_search with params: {:text=>" **Ruby** \n\n---\n\n### **1. **  \n ****  \n\n****  \n- RubyRuby  \n- Python/Perl1.82.03.0  \n- \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | **** |\n| **** | ****Ruby1995Ruby 3.0JRuby/RbxRails2000 |\n| **** | ****RubyYukihiro Matsumoto/Rubyruby-lang.orgACM/IEEEPragmatic ProgrammersInfoQThe Changelog |\n\n---\n\n### **3. **  \n\n####  ****  \n- `Ruby programming language history`  \n- `Ruby language origins`  \n- `Yukihiro Matsumoto Ruby creation`  \n- `Ruby evolution timeline`  \n\n####  ****  \n- `Ruby vs Perl`  \n- `Ruby on Rails emergence`Ruby  \n- `Ruby 1.8 Ruby 2.0 Ruby 3.0 differences`  \n- `Object-oriented scripting languages history`  \n\n####  ****  \n```  \nsite:ruby-lang.org \"history\" OR \"development\"  \nintitle:\"Ruby language history\"  \nfiletype:pdf \"Ruby creation\" Matsumoto  \nsite:acm.org \"Ruby\" AND (\"history\" OR \"design\")  \nsite:en.wikipedia.org \"Ruby (programming language)\"  \n\"Ruby\" AND (\"origin\" OR \"influence\" OR \"design philosophy\")  \n```  \n\n####  ****  \n- `-tutorial -guide -beginner -how to`  \n- `-job -salary -interview`  \n- `-Rails`  \n\n>  ****Rails`\"Ruby language\" -\"Rails\"` \n\n---\n\n### **4. **  \n\n####  ****  \n- ****The Art of RubyMatz Speaksruby-talk  \n- ****Ruby  \n- ****RubyRailsRuby20042010  \n- ****Ruby  \n\n####  ****  \n- ****Ruby vs SmalltalkRuby vs Python vs   \n- ****Matsumoto `site:ruby-lang.org lang:ja`  \n- **/**YouTube/TEDRuby: The Language of Happiness  \n\n####  ****  \n|  |  |  |\n|------|------|----------|\n| **** | 1990 |  [Internet Archive (archive.org)]  `ruby-lang.org`  |\n| **Rails** | /RubyRails |  `\"Ruby language\"` +  `Rails` |\n| **** | Ruby |  |\n| **** |  | MatsumotoRuby |\n\n---\n\n###  ****  \n1. **** [https://www.ruby-lang.org/en/about/](https://www.ruby-lang.org/en/about/)    \n2. ****Google `site:ruby-lang.org \"history\"` + `intitle:\"Ruby language history\"`  \n3. ****Google Scholar `\"Ruby programming language\" design history`20002020  \n4. ****YouTube `Matsumoto Ruby interview`2012 OSCON  \n5. **** `Ruby (programming language)`The Ruby Programming Languageby Flanagan & Matsumoto  \n\n>  ****19932024\n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:00:47.394601 #2707]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T12:00:47.394617 #2707]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T12:00:47.394630 #2707]  INFO -- : Create Conversation
I, [2025-12-10T12:00:47.394664 #2707]  INFO -- : Use template pre_search
I, [2025-12-10T12:00:47.395056 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:00:47.395090 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:00:51.153779 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:00:51.153851 #2707]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:00:51.153865 #2707]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T12:00:52.948131 #2707]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://try.ruby-lang.org/articles/try-ruby-version-4/\",\"link\":\"https://try.ruby-lang.org/articles/try-ruby-version-4/\",\"snippet\":\"History. This is the fourth iteration of the TryRuby website. TryRuby was ... Used middleman as development environment; Added some articles with more...\",\"title\":\"TryRuby's history\"},{\"formattedUrl\":\"https://try.ruby-lang.org/articles/web-development/\",\"link\":\"https://try.ruby-lang.org/articles/web-development/\",\"snippet\":\"One of the areas of software development where Ruby really shines is web development. From creating a simple website to a full cloud based webservice, it is...\",\"title\":\"Web development\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/en/3.3/IRB.html\",\"link\":\"https://docs.ruby-lang.org/en/3.3/IRB.html\",\"snippet\":\"Input Command History . By default, IRB stores a history of up to 1000 input commands in a file named .irb_history . The history file will be in the same...\",\"title\":\"module IRB - Documentation for Ruby 3.3\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/community/ruby-core/\",\"link\":\"https://www.ruby-lang.org/en/community/ruby-core/\",\"snippet\":\"Improving Ruby, Patch by Patch; Note about branches. Using Git to Track Ruby Development. The current primary repository of the latest Ruby source code is git.\",\"title\":\"Ruby Core\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/installation/\",\"link\":\"https://www.ruby-lang.org/en/documentation/installation/\",\"snippet\":\"Bitnami Ruby Stack provides a complete development environment for Rails. It supports macOS, Linux, Windows, virtual machines, and cloud images. Managers. Many...\",\"title\":\"Installing Ruby\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"snippet\":\"(Based on an explanation from Matz in [ruby-talk:00394] on June 11, 1999.) What is the history of Ruby? The following is a summary of a posting made by Matz in...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/\",\"link\":\"https://www.ruby-lang.org/en/documentation/\",\"snippet\":\"A very good set of exercises with explanations that guide you from the absolute basics of Ruby all the way to OOP and web development. Programming Ruby: The...\",\"title\":\"Documentation\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/news/2007/12/25/ruby-1-9-0-released/\",\"link\":\"https://www.ruby-lang.org/en/news/2007/12/25/ruby-1-9-0-released/\",\"snippet\":\"Ruby 1.9.0 Released. Posted by james on 25 Dec 2007. Matz announced the release of Ruby 1.9.0, a development release. You can fetch it from:.\",\"title\":\"Ruby 1.9.0 Released\"},{\"formattedUrl\":\"https://try.ruby-lang.org/articles/\",\"link\":\"https://try.ruby-lang.org/articles/\",\"snippet\":\"Testing 123. Testing software is one of the most important aspects of software development. TryRuby's history. Some information about the history of TryRuby and...\",\"title\":\"TryRuby Articles\"},{\"formattedUrl\":\"https://try.ruby-lang.org/articles/testing/\",\"link\":\"https://try.ruby-lang.org/articles/testing/\",\"snippet\":\"Testing software is one of the most important aspects of software development. It ensures that the code you are writing is doing what it is supposed to do.\",\"title\":\"Testing, testing. Testing 123\"}]", :with_history=>false}
I, [2025-12-10T12:00:52.948157 #2707]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:00:52.948164 #2707]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T12:00:52.948176 #2707]  INFO -- : Create Conversation
I, [2025-12-10T12:00:52.948195 #2707]  INFO -- : Use template get_topic
I, [2025-12-10T12:00:52.948490 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:00:52.948520 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:00:53.093518 #2707] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:00:53.093597 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:00:53.093636 #2707]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:00:55.150888 #2707]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T12:00:55.150905 #2707]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:00:55.150934 #2707]  INFO -- : Use template get_topic
I, [2025-12-10T12:00:55.151408 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:00:55.151561 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:00:55.340950 #2707] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:00:55.341090 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:00:55.341120 #2707]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:00:57.194226 #2707]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://flatironschool.com/blog/the-father-of-ruby-yukihiro-matsumoto/\",\"link\":\"https://flatironschool.com/blog/the-father-of-ruby-yukihiro-matsumoto/\",\"snippet\":\"Aug 27, 2015 ... You may not have heard Yukihiro Matsumoto's ... He released the language for widespread use by 1996, and the elements that drove Ruby's creation...\",\"title\":\"The Father of Ruby: Yukihiro Matsumoto | Flatiron School\"}]", :with_history=>false}
I, [2025-12-10T12:00:57.194241 #2707]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:00:57.194261 #2707]  INFO -- : Use template get_topic
I, [2025-12-10T12:00:57.194470 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:00:57.194496 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:00:57.330365 #2707] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:00:57.330443 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:00:57.330461 #2707]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:00:58.543073 #2707]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:00:58.543100 #2707]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T12:00:58.543111 #2707]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T12:00:58.543123 #2707]  INFO -- : Create Conversation
I, [2025-12-10T12:00:58.543146 #2707]  INFO -- : Use template generate_search_plan
I, [2025-12-10T12:00:58.543420 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:00:58.543448 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:01:01.429025 #2707] ERROR -- : Unexpected error during OpenAI request: the server responded with status 400 for POST http://120.133.75.248:39095/v1/chat/completions
I, [2025-12-10T12:01:01.429139 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:01:01.429189 #2707]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T12:01:02.032067 #2707]  INFO -- : Calling worker: smart_search with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:01:02.032167 #2707]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T12:01:02.032180 #2707]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T12:01:02.032191 #2707]  INFO -- : Create Conversation
I, [2025-12-10T12:01:02.032213 #2707]  INFO -- : Use template smart_search
I, [2025-12-10T12:01:02.032432 #2707]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:01:02.032468 #2707]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:01:02.096058 #2707]  INFO -- : Successful send a message
I, [2025-12-10T12:01:11.816765 #2981]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:01:11.816858 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816896 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.816903 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816913 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.816926 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816933 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.816937 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816959 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.816964 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816970 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.816974 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816980 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.816984 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.816997 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.817001 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.817011 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.817015 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.817024 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.881787 #2981]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:01:11.881853 #2981]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:01:11.882404 #2981]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:01:11.882446 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882468 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882473 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882480 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882484 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882490 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882494 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882548 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882566 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882580 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882586 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882593 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882598 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882611 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882615 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882624 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882628 #2981]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:01:11.882637 #2981]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:01:11.882876 #2981]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:01:11.882897 #2981]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:01:14.102334 #2981]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-10T12:01:14.102343 #2981]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T12:01:14.102351 #2981]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T12:01:14.102365 #2981]  INFO -- : Create Conversation
I, [2025-12-10T12:01:14.102393 #2981]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T12:01:14.102721 #2981]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:01:14.102746 #2981]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:01:22.725904 #2981]  INFO -- : Successful send a message
I, [2025-12-10T12:01:22.725976 #2981]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:01:22.726003 #2981]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T12:01:23.328410 #2981]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n** / **  \n\n- ****  \n    \n- ****  \n  \n\n>  ********  \n\n---\n\n### **2. **  \n****  \n\n- ****    \n- ****    \n- ****    \n- ****    \n\n>  ********\n\n---\n\n### **3. **  \n****  \n\n- ****  \n      \n- ****  \n    \n- ****  \n   `site:`, `filetype:`   \n- ****  \n    \n\n>  ********\n\n---\n\n### **4. **  \n\n- ****  \n  ********  \n  >   \n\n- ****  \n  - Python   ****  \n  - 2024AI   ****  \n  - ChatGPTClaude   ****  \n\n- ****  \n  - ****  \n  - ****  \n  - ****  \n    - ****  \n    - ****  \n    - ****hi/\n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| **** |  ****   |\n| **** |  **** |\n| **** |    |\n| **** |  |\n\n---\n\n****  \n****************", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:01:23.328665 #2981]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T12:01:23.328692 #2981]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T12:01:23.328709 #2981]  INFO -- : Create Conversation
I, [2025-12-10T12:01:23.328748 #2981]  INFO -- : Use template pre_search
I, [2025-12-10T12:01:23.329259 #2981]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:01:23.329316 #2981]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:01:25.454113 #2981]  INFO -- : Successful send a message
I, [2025-12-10T12:01:25.454185 #2981]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:01:25.454202 #2981]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T12:01:26.056517 #2981]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1\n  - [] \n\n- 2\n  - [] \n\n- 3\n  - [] \n\n- 4\n  - [] \n\n---\n\n****  \n********  \n\n****  \n  \n>     \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:01:26.056647 #2981]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T12:01:26.056667 #2981]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T12:01:26.056684 #2981]  INFO -- : Create Conversation
I, [2025-12-10T12:01:26.056717 #2981]  INFO -- : Use template smart_search
I, [2025-12-10T12:01:26.057026 #2981]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:01:26.057067 #2981]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:01:26.564521 #2981]  INFO -- : Successful send a message
I, [2025-12-10T12:01:26.564595 #2981]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:01:26.564610 #2981]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T12:01:26.565015 #2981]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:01:26.565043 #2981]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T12:01:26.565053 #2981]  INFO -- : Create worker's name is summary
I, [2025-12-10T12:01:26.565064 #2981]  INFO -- : Create Conversation
I, [2025-12-10T12:01:26.565085 #2981]  INFO -- : Use template summarize
I, [2025-12-10T12:01:26.565321 #2981]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:01:26.565349 #2981]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:01:30.445769 #2981]  INFO -- : Successful send a message
I, [2025-12-10T12:01:30.445853 #2981]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:01:30.445869 #2981]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T12:03:58.449324 #3797]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:03:58.449405 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449477 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449489 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449500 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449504 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449511 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449515 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449543 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449547 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449554 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449558 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449563 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449577 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449587 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449592 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449601 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.449605 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.449614 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.519702 #3797]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:03:58.519763 #3797]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:03:58.520125 #3797]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:03:58.520162 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520183 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520188 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520195 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520199 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520205 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520209 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520229 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520233 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520239 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520243 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520249 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520252 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520262 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520266 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520276 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520280 #3797]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:03:58.520288 #3797]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:03:58.520518 #3797]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:03:58.520540 #3797]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:04:00.726623 #3797]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Ruby", :with_history=>true}
I, [2025-12-10T12:04:00.726631 #3797]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T12:04:00.726638 #3797]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T12:04:00.726648 #3797]  INFO -- : Create Conversation
I, [2025-12-10T12:04:00.726673 #3797]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T12:04:00.726963 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:00.726989 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:04:10.714591 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:10.714661 #3797]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:04:10.714675 #3797]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T12:04:11.316602 #3797]  INFO -- : Calling worker: pre_search with params: {:text=>"Ruby\n\n---\n\n### **1. **  \n**** + ****  \n\n- ****  \n  Ruby****  \n  ********  \n  -  Python/JavaScript  \n  -  RubyWeb  \n  -  Ruby\n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | ****12 |\n| **** | ****Ruby2000**Ruby 3.x** 1.8/1.9 |\n| **** | ****ruby-lang.orgStack OverflowGitHubThe Well-Grounded Rubyist |\n\n---\n\n### **3. **  \n\n|  | / |\n|------|------------------|\n| **** | `Ruby programming language`, `Ruby language overview`, `what is Ruby` |\n| **** | `Ruby creator`, `Ruby history`, `Ruby features`, `Ruby vs Python`, `Ruby on Rails`, `object-oriented Ruby`, `dynamic typing Ruby` |\n| **** | - `site:ruby-lang.org \"Ruby language\"`<br>- `intitle:\"Introduction to Ruby\"`<br>- `filetype:pdf \"Ruby programming guide\"`<br>- `\"Ruby\" \"design philosophy\"` |\n| **** | `-job -salary -tutorial -code -example -install`<br> Rails `-Rails`  |\n\n>  ****  \n> `intitle:\"What is Ruby\" site:ruby-lang.org OR site:wikipedia.org`  \n> `Ruby programming language features history -Rails -tutorial`\n\n---\n\n### **4. **  \n\n|  |  |\n|------|------|\n| **** | ** +  + **RubyYukihiro MatsumotoMRI/YARVWeb |\n| **** | - ****Programming RubyPickaxe Book<br>- ****MediumDev.to Ruby in 2024<br>- ****Ruby |\n| **** | - ** Rails**RubyRuby on Rails<br>- **** Ruby 1.9  2.02020<br>- ****Ruby |\n\n---\n\n###  ****  \n1. ****`ruby-lang.org``wikipedia.org``stackoverflow.com``geeksforgeeks.org``tutorialspoint.com`  \n2. ****`site:ruby-lang.org` + `intitle:\"What is\"` +  `-Rails -tutorial`  \n3. **** Ruby 3.0+/  \n4. ********\n\nRuby", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:04:11.316720 #3797]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T12:04:11.316735 #3797]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T12:04:11.316747 #3797]  INFO -- : Create Conversation
I, [2025-12-10T12:04:11.316777 #3797]  INFO -- : Use template pre_search
I, [2025-12-10T12:04:11.317121 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:11.317151 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:04:13.729765 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:13.729838 #3797]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:04:13.729853 #3797]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T12:04:16.161780 #3797]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T12:04:16.161794 #3797]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:04:16.161802 #3797]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T12:04:16.161814 #3797]  INFO -- : Create Conversation
I, [2025-12-10T12:04:16.161834 #3797]  INFO -- : Use template get_topic
I, [2025-12-10T12:04:16.162082 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:16.162120 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:04:16.356075 #3797] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:04:16.356168 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:16.356191 #3797]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:04:18.351333 #3797]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"snippet\":\"Ruby is a simple and powerful object-oriented programming language, created by Yukihiro Matsumoto (who goes by the handle Matz in this document and on the...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://www.reddit.com/.../is_julia_programming_language_destined_to_fa...\",\"link\":\"https://www.reddit.com/r/Julia/comments/18s0ubz/is_julia_programming_language_destined_to_fade/\",\"snippet\":\"Dec 27, 2023 ... Julia is objectively excellent as a language - combining Python's accessibility with C++'s performance is a killer feature on paper - but...\",\"title\":\"Is Julia Programming Language Destined to Fade Away ? : r/Julia\"},{\"formattedUrl\":\"http://python-history.blogspot.com/.../origin-of-metaclasses-in-python.html\",\"link\":\"http://python-history.blogspot.com/2013/10/origin-of-metaclasses-in-python.html\",\"snippet\":\"Oct 24, 2013 ... ... Ruby. It did not. And as long as we are speculating about the origins of language features, I feel the need to set the record straight. I...\",\"title\":\"Origin of metaclasses in Python - The History of Python\"},{\"formattedUrl\":\"https://www.reddit.com/.../programmingcirclejerk/.../i_personally_think_ty...\",\"link\":\"https://www.reddit.com/r/programmingcirclejerk/comments/gyvc8n/i_personally_think_type_safety_is_the_most/\",\"snippet\":\"Jun 8, 2020 ... Total number of times I wished I had a refactoring shortcut for \\\"extract interface\\\", \\\"rename method\\\", \\\"introduce parameter object\\\" in a Ruby...\",\"title\":\"\\\"I personally think type safety is the most overrated language feature ...\"},{\"formattedUrl\":\"https://zverok.space/blog/2022-01-13-it-evolves.html\",\"link\":\"https://zverok.space/blog/2022-01-13-it-evolves.html\",\"snippet\":\"Jan 13, 2022 ... Working on changelogs, though, brought a lot to discover and understand about Ruby's development process. And now I am telling this story.\",\"title\":\"Following the programming language evolution, and taking it ...\"},{\"formattedUrl\":\"https://www.hillelwayne.com/post/influential-dead-languages/\",\"link\":\"https://www.hillelwayne.com/post/influential-dead-languages/\",\"snippet\":\"Mar 25, 2020 ... History is complicated! Detecting Influence. Before we start, a quick primer on finding influence. Just knowing that X was the first language...\",\"title\":\"10 Most(ly dead) Influential Programming Languages\"},{\"formattedUrl\":\"https://groups.google.com/a/dartlang.org/g/misc/c/y1aGAtgwUvI\",\"link\":\"https://groups.google.com/a/dartlang.org/g/misc/c/y1aGAtgwUvI\",\"snippet\":\"It was the rage back then. And so it was a story that started with client-side in Delphi, went to server-side with Ruby and.\",\"title\":\"Dart's the best programming language I've ever used\"},{\"formattedUrl\":\"https://medium.com/.../grokking-pattern-matching-and-list-comprehensions...\",\"link\":\"https://medium.com/pragmatic-programmers/grokking-pattern-matching-and-list-comprehensions-two-language-features-that-rock-832b406b77d2\",\"snippet\":\"May 17, 2022 ... (A functional programming language is composed entirely of mathematical functions. The strictest functional languages allow no side effects...\",\"title\":\"Grokking Pattern Matching and List Comprehensions: Two ...\"},{\"formattedUrl\":\"https://softwareengineering.stackexchange.com/.../why-do-build-tools-use-a...\",\"link\":\"https://softwareengineering.stackexchange.com/questions/297847/why-do-build-tools-use-a-scripting-language-different-than-underlying-programmin\",\"snippet\":\"Sep 21, 2015 ... The choice of what programming language to use to get anything done must depend on the specific features of that goal and not on the other...\",\"title\":\"history - Why do build tools use a scripting language different than ...\"},{\"formattedUrl\":\"https://corecursive.com/032-bob-nystrom-on-building-an-interpreter/\",\"link\":\"https://corecursive.com/032-bob-nystrom-on-building-an-interpreter/\",\"snippet\":\"May 31, 2019 ... ... programming language history and language features. And I don't know ... What's interesting is, that looks a lot like languages like Ruby, where...\",\"title\":\"How to Build a Programming Language And Why With Bob Nystrom ...\"}]", :with_history=>false}
I, [2025-12-10T12:04:18.351355 #3797]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:04:18.351380 #3797]  INFO -- : Use template get_topic
I, [2025-12-10T12:04:18.351612 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:18.351638 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:04:18.542073 #3797] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:04:18.542181 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:18.542232 #3797]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:04:21.013856 #3797]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:04:21.013884 #3797]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T12:04:21.013894 #3797]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T12:04:21.013905 #3797]  INFO -- : Create Conversation
I, [2025-12-10T12:04:21.013927 #3797]  INFO -- : Use template generate_search_plan
I, [2025-12-10T12:04:21.014191 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:21.014216 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:04:21.776528 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:21.776641 #3797]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:04:21.776665 #3797]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T12:04:22.381029 #3797]  INFO -- : Calling worker: smart_search with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:04:22.381130 #3797]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T12:04:22.381143 #3797]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T12:04:22.381165 #3797]  INFO -- : Create Conversation
I, [2025-12-10T12:04:22.381186 #3797]  INFO -- : Use template smart_search
I, [2025-12-10T12:04:22.381420 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:22.381520 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:04:23.089935 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:23.090008 #3797]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:04:23.090023 #3797]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T12:04:24.743668 #3797]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.ruby-lang.org/en/\",\"link\":\"https://www.ruby-lang.org/en/\",\"snippet\":\"A dynamic, open source programming language with a focus on simplicity and productivity. It has an elegant syntax that is natural to read and easy to write.\",\"title\":\"Ruby Programming Language\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/2/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/2/\",\"snippet\":\"Python is a hybrid language. It has functions for procedural programming and objects for OO programming. Python bridges the two worlds by allowing functions and...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/1/\",\"snippet\":\"Ruby is a simple and powerful object-oriented programming language, created by Yukihiro Matsumoto (who goes by the handle Matz in this document and on the...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/8/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/8/\",\"snippet\":\"Classes and modules. Can a class definition be repeated? A class can be defined repeatedly. Each definition is added to the last definition. If a method...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/quickstart/\",\"link\":\"https://www.ruby-lang.org/en/documentation/quickstart/\",\"snippet\":\"... Ruby statements you feed it. Playing with Ruby code in interactive sessions like this is a terrific way to learn the language. Open up IRB (which stands for...\",\"title\":\"Ruby in Twenty Minutes\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/quickstart/2/\",\"link\":\"https://www.ruby-lang.org/en/documentation/quickstart/2/\",\"snippet\":\"What if we want to say Hello a lot without getting our fingers all tired? We need to define a method! ... The code def hi starts the definition of the method.\",\"title\":\"Ruby in Twenty Minutes\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/capi/en/master/d9/d3f/ruby_8h.html\",\"link\":\"https://docs.ruby-lang.org/capi/en/master/d9/d3f/ruby_8h.html\",\"snippet\":\"This file is a part of the programming language Ruby. Permission is hereby ... Definition in file ruby.h. Macro Definition Documentation.\",\"title\":\"include/ruby.h File Reference - Ruby\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/faq/5/\",\"link\":\"https://www.ruby-lang.org/en/documentation/faq/5/\",\"snippet\":\"Iterators are used to produce user-defined control structuresespecially loops. ... The each method of the array data is passed the do ... end block, and executes...\",\"title\":\"Official Ruby FAQ\"},{\"formattedUrl\":\"https://docs.ruby-lang.org/en/master/syntax/methods_rdoc.html\",\"link\":\"https://docs.ruby-lang.org/en/master/syntax/methods_rdoc.html\",\"snippet\":\"methods: Methods Methods implement the functionality of your program. def one_plus_one 1 + 1 end A method definition consists of the +def+ keyword, a m.\",\"title\":\"methods - Documentation for Ruby 4.0\"},{\"formattedUrl\":\"https://www.ruby-lang.org/en/documentation/ruby-from-other-languages/\",\"link\":\"https://www.ruby-lang.org/en/documentation/ruby-from-other-languages/\",\"snippet\":\"When you first look at some Ruby code, it will likely remind you of other programming languages you've used. This is on purpose. Much of the syntax is...\",\"title\":\"Ruby From Other Languages\"}]", :with_history=>false}
I, [2025-12-10T12:04:24.743712 #3797]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:04:24.743738 #3797]  INFO -- : Use template get_topic
I, [2025-12-10T12:04:24.743956 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:24.743985 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:04:24.924123 #3797] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:04:24.924211 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:24.924228 #3797]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:04:24.978551 #3797]  INFO -- : Calling worker: summary with params: {:text=>"Ruby", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:04:24.978576 #3797]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T12:04:24.978584 #3797]  INFO -- : Create worker's name is summary
I, [2025-12-10T12:04:24.978593 #3797]  INFO -- : Create Conversation
I, [2025-12-10T12:04:24.978611 #3797]  INFO -- : Use template summarize
I, [2025-12-10T12:04:24.978821 #3797]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:04:24.978845 #3797]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:04:32.423258 #3797]  INFO -- : Successful send a message
I, [2025-12-10T12:04:32.423345 #3797]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:04:32.423360 #3797]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T12:06:50.895753 #4811]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:06:50.896139 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896188 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896212 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896225 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896231 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896238 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896242 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896269 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896287 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896299 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896305 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896313 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896318 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896331 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896336 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896345 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:50.896349 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:50.896359 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022154 #4811]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:06:51.022207 #4811]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:06:51.022723 #4811]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:06:51.022760 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022781 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022786 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022793 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022797 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022803 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022807 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022832 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022848 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022860 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022866 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022874 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022878 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022891 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022896 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022906 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.022910 #4811]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:06:51.022921 #4811]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:06:51.023146 #4811]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:06:51.023165 #4811]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:06:53.422047 #4811]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"hello", :with_history=>true}
I, [2025-12-10T12:06:53.422072 #4811]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T12:06:53.422084 #4811]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T12:06:53.422099 #4811]  INFO -- : Create Conversation
I, [2025-12-10T12:06:53.422134 #4811]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T12:06:53.422454 #4811]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:06:53.422483 #4811]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:07:03.053546 #4811]  INFO -- : Successful send a message
I, [2025-12-10T12:07:03.053614 #4811]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:07:03.053630 #4811]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T12:07:03.656546 #4811]  INFO -- : Calling worker: pre_search with params: {:text=>"hello\n\n---\n\n### **1. **\n\n** /  / **\n\n- ****\n- ****\n  - hello\n  - \n  - \n\n>  ********\n\n---\n\n### **2. **\n\n****\n\n- ****  \n- ****  \n- ****  hello\n- ****  \n\n>  ********\n\n---\n\n### **3. **\n\n****\n\n- ****  \n  - hello  AI\n\n- ****  \n  - greeting, salutation, English greeting, AI chatbot opening, cultural greetings  \n  - \n\n- ****  \n  - `intitle:\"hello\"`  hello  \n  - `site:edu \"hello\"`  hello  \n  - `filetype:pdf \"hello\"`  PDFhello  \n  - ****\n\n- ****  \n  - `-robot -AI -chatbot`  \n  - `-Spanish -French`  \n  - \n\n>  ********\n\n---\n\n### **4. **\n\n- ****  \n   ****\n\n- ****  \n  - **  common English greetings for beginners  \n  - *AI*  Hello! How can I help you today?  \n  - *hello*  hello world programming language  \n  - **  greetings around the world cultural differences\n\n- ****  \n  -  ****  \n  -  helloHello appHello KittyHello neighbor game  \n  -  \n\n---\n\n###  ****\n\n> ****  \n> ****\n\n>    \n> - hello  \n> - Hello, World!  \n> - \n\n---\n\n###  \n\n|  |  |\n|------|------|\n| **** |  |\n| **** |    |\n| **** |  |\n| **** |  |\n| **** | **** |\n\n---\n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:07:03.656705 #4811]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T12:07:03.656728 #4811]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T12:07:03.656744 #4811]  INFO -- : Create Conversation
I, [2025-12-10T12:07:03.656928 #4811]  INFO -- : Use template pre_search
I, [2025-12-10T12:07:03.657741 #4811]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:07:03.657791 #4811]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:07:07.353325 #4811]  INFO -- : Successful send a message
I, [2025-12-10T12:07:07.353396 #4811]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:07:07.353411 #4811]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T12:07:07.955588 #4811]  INFO -- : Calling worker: smart_search with params: {:text=>"hello****\n\n> ****\n\n\n-  AI Hello KittyHello \n- \n- \n- \n\n---\n\n###  \n\n****  \n****\n\n---\n\n###  \n\n>    \n> - hello  \n> - Hello, World!  \n> -   \n> - \n\n---\n\n###    \n****\n\n-   \n  - []   \n\n-   \n  - []   \n\n-   \n  - []   \n\n-   \n  - []   \n\n---\n\n###    \n****  \n****0  \n****  \n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:07:07.955739 #4811]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T12:07:07.955761 #4811]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T12:07:07.955776 #4811]  INFO -- : Create Conversation
I, [2025-12-10T12:07:07.955810 #4811]  INFO -- : Use template smart_search
I, [2025-12-10T12:07:07.956147 #4811]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:07:07.956204 #4811]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:07:08.238674 #4811]  INFO -- : Successful send a message
I, [2025-12-10T12:07:08.238748 #4811]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:07:08.238767 #4811]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T12:07:08.239209 #4811]  INFO -- : Calling worker: summary with params: {:text=>"hello", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:07:08.239260 #4811]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T12:07:08.239272 #4811]  INFO -- : Create worker's name is summary
I, [2025-12-10T12:07:08.239283 #4811]  INFO -- : Create Conversation
I, [2025-12-10T12:07:08.239307 #4811]  INFO -- : Use template summarize
I, [2025-12-10T12:07:08.239594 #4811]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:07:08.239621 #4811]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:07:14.485316 #4811]  INFO -- : Successful send a message
I, [2025-12-10T12:07:14.485370 #4811]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:07:14.485382 #4811]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T12:08:17.608456 #5430]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:08:17.608539 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608573 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608579 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608587 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608592 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608612 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608619 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608648 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608653 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608661 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608665 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608671 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608675 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608686 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608691 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608700 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.608704 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.608714 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.669510 #5430]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:08:17.669576 #5430]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:08:17.670079 #5430]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:08:17.670121 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670142 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670148 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670155 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670160 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670166 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670171 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670191 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670196 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670203 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670215 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670221 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670225 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670236 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670240 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670249 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670254 #5430]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:08:17.670263 #5430]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:08:17.670489 #5430]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:08:17.670514 #5430]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:10:20.019888 #5866]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:10:20.019974 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020012 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020019 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020029 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020034 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020041 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020046 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020077 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020082 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020089 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020094 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020100 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020105 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020128 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020148 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020166 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.020174 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.020187 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.084485 #5866]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:10:20.084560 #5866]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:10:20.084981 #5866]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:10:20.085037 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085186 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085218 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085232 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085237 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085245 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085249 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085301 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085324 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085337 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085343 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085350 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085355 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085371 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085391 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085402 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085406 #5866]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:10:20.085415 #5866]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:10:20.085732 #5866]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:10:20.085762 #5866]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:12:17.348204 #6330]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:12:17.348296 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348401 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348443 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348458 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348464 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348471 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348480 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348507 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348524 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348537 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348543 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348553 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348558 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348570 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348575 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348585 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.348589 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.348598 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414223 #6330]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:12:17.414286 #6330]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:12:17.414796 #6330]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:12:17.414838 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414860 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414866 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414873 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414877 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414884 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414888 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414912 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414929 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414942 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414948 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414956 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414962 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414975 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414980 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.414991 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.414995 #6330]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:17.415005 #6330]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:17.415258 #6330]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:12:17.415283 #6330]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:12:19.696378 #6330]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Ruby", :lang=>""}
I, [2025-12-10T12:12:19.696394 #6330]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T12:12:19.696404 #6330]  INFO -- : Create worker's name is get_tags
I, [2025-12-10T12:12:19.696418 #6330]  INFO -- : Create Conversation
I, [2025-12-10T12:12:19.696444 #6330]  INFO -- : Use template get_tags
I, [2025-12-10T12:12:19.696769 #6330]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:12:19.696797 #6330]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:12:20.280800 #6330]  INFO -- : Successful send a message
I, [2025-12-10T12:12:20.280878 #6330]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:12:20.280899 #6330]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T12:12:20.280933 #6330]  INFO -- : Calling worker: get_embedding with params: {:text=>"ruby,,,,", :length=>1024}
I, [2025-12-10T12:12:20.280939 #6330]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T12:12:20.280944 #6330]  INFO -- : Create worker's name is get_embedding
I, [2025-12-10T12:12:20.280952 #6330]  INFO -- : Create Conversation
I, [2025-12-10T12:12:20.281015 #6330]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T12:12:20.281033 #6330]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T12:12:20.357692 #6330] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T12:12:20.357790 #6330]  INFO -- : Successful send a message
E, [2025-12-10T12:12:20.357815 #6330] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T12:12:20.357846 #6330] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T12:12:20.357885 #6330]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Ruby", :lang=>""}
I, [2025-12-10T12:12:20.357893 #6330]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T12:12:20.357915 #6330]  INFO -- : Use template get_tags
I, [2025-12-10T12:12:20.358286 #6330]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:12:20.358335 #6330]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:12:20.898135 #6330]  INFO -- : Successful send a message
I, [2025-12-10T12:12:20.898201 #6330]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:12:20.898221 #6330]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T12:12:20.898246 #6330]  INFO -- : Calling worker: get_embedding with params: {:text=>"ruby,,,,", :length=>1024}
I, [2025-12-10T12:12:20.898251 #6330]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T12:12:20.898317 #6330]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T12:12:20.898334 #6330]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T12:12:20.974725 #6330] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T12:12:20.974801 #6330]  INFO -- : Successful send a message
E, [2025-12-10T12:12:20.974817 #6330] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T12:12:20.974841 #6330] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T12:12:20.974866 #6330]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Ruby", :lang=>""}
I, [2025-12-10T12:12:20.974872 #6330]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T12:12:20.974890 #6330]  INFO -- : Use template get_tags
I, [2025-12-10T12:12:20.975123 #6330]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:12:20.975152 #6330]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:12:21.512173 #6330]  INFO -- : Successful send a message
I, [2025-12-10T12:12:21.512257 #6330]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:12:21.512295 #6330]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T12:12:21.512330 #6330]  INFO -- : Calling worker: get_embedding with params: {:text=>"ruby,documentation,programming_language,technical_reference,developer_resource", :length=>1024}
I, [2025-12-10T12:12:21.512457 #6330]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T12:12:21.512544 #6330]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T12:12:21.512568 #6330]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T12:12:21.595206 #6330] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T12:12:21.595303 #6330]  INFO -- : Successful send a message
E, [2025-12-10T12:12:21.595323 #6330] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T12:12:21.595354 #6330] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T12:12:21.595386 #6330]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Ruby", :lang=>""}
I, [2025-12-10T12:12:21.595392 #6330]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T12:12:21.595411 #6330]  INFO -- : Use template get_tags
I, [2025-12-10T12:12:21.595659 #6330]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:12:21.595696 #6330]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:12:22.245706 #6330]  INFO -- : Successful send a message
I, [2025-12-10T12:12:22.245806 #6330]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:12:22.245832 #6330]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T12:12:22.245876 #6330]  INFO -- : Calling worker: get_embedding with params: {:text=>"ruby,,,,", :length=>1024}
I, [2025-12-10T12:12:22.245886 #6330]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T12:12:22.245983 #6330]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T12:12:22.246011 #6330]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T12:12:22.323799 #6330] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T12:12:22.323875 #6330]  INFO -- : Successful send a message
E, [2025-12-10T12:12:22.323892 #6330] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T12:12:22.323914 #6330] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T12:12:22.323992 #6330]  INFO -- : Calling worker: summary with params: {:text=>"Ruby\n[]", :tools=>[], :with_history=>false}
I, [2025-12-10T12:12:22.324010 #6330]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T12:12:22.324019 #6330]  INFO -- : Create worker's name is summary
I, [2025-12-10T12:12:22.324029 #6330]  INFO -- : Create Conversation
I, [2025-12-10T12:12:22.324051 #6330]  INFO -- : Use template summarize
I, [2025-12-10T12:12:22.324288 #6330]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:12:22.324314 #6330]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:12:32.314934 #6330]  INFO -- : Successful send a message
I, [2025-12-10T12:12:32.315010 #6330]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:12:32.315029 #6330]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T12:12:43.009939 #6520]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:12:43.010010 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010042 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010048 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010057 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010061 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010067 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010071 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010094 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010098 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010104 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010108 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010114 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010118 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010129 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010140 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010150 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.010154 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.010163 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076364 #6520]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:12:43.076431 #6520]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:12:43.076793 #6520]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:12:43.076823 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076845 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076850 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076856 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076860 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076866 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076870 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076890 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076894 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076900 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076903 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076909 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076912 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076922 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076926 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076935 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.076939 #6520]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:43.076947 #6520]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:43.077166 #6520]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:12:43.077188 #6520]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:12:52.619609 #6600]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:12:52.619684 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619721 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619732 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619740 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619745 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619752 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619756 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619788 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619806 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619822 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619828 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619836 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619841 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619855 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619859 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619873 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.619878 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.619887 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.683559 #6600]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:12:52.683628 #6600]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:12:52.683980 #6600]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:12:52.684013 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684032 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684037 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684044 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684048 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684054 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684057 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684095 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684112 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684125 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684131 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684138 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684143 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684155 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684160 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684170 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684174 #6600]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:12:52.684187 #6600]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:12:52.684426 #6600]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:12:52.684456 #6600]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:13:03.946903 #6690]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:13:03.946986 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947019 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947025 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947034 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947038 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947045 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947049 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947079 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947083 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947090 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947094 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947100 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947104 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947114 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947118 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947128 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:03.947132 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:03.947141 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016061 #6690]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:13:04.016132 #6690]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:13:04.016657 #6690]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:13:04.016701 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016729 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016735 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016742 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016745 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016752 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016755 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016777 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016795 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016807 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016813 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016820 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016825 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016837 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016842 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016851 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.016855 #6690]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:13:04.016865 #6690]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:13:04.017109 #6690]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:13:04.017130 #6690]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:50:07.897374 #15275]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:50:07.897730 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897777 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897784 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897794 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897799 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897806 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897811 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897835 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897840 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897848 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897853 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897860 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897864 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897879 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897888 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897899 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:07.897904 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:07.897914 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.013585 #15275]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:50:08.013650 #15275]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:50:08.014251 #15275]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:50:08.014295 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014316 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014322 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014330 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014335 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014351 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014355 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014389 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014397 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014406 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014411 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014417 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014421 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014434 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014438 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014448 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014452 #15275]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:50:08.014462 #15275]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:50:08.014697 #15275]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:50:08.014720 #15275]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:51:30.395400 #15674]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:51:30.395799 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395848 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395857 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395867 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395872 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395880 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395884 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395918 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395938 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395951 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395957 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395965 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395970 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395983 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.395988 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.395998 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.396003 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.396013 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.521803 #15674]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:51:30.521870 #15674]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:51:30.522574 #15674]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:51:30.522622 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522645 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522651 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522659 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522663 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522670 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522674 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522723 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522781 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522797 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522803 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522810 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522814 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522830 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522834 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522844 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.522848 #15674]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:51:30.522857 #15674]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:51:30.523086 #15674]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:51:30.523111 #15674]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:51:32.759790 #15674]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Rust", :with_history=>true}
I, [2025-12-10T12:51:32.759820 #15674]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T12:51:32.759832 #15674]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T12:51:32.759846 #15674]  INFO -- : Create Conversation
I, [2025-12-10T12:51:32.759875 #15674]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T12:51:32.760199 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:51:32.760229 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:51:45.892392 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:51:45.892471 #15674]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:51:45.892488 #15674]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T12:51:46.494873 #15674]  INFO -- : Calling worker: pre_search with params: {:text=>"Rust\n\n---\n\n### **1. **  \n****  \n- ****  \n  Rust********WebAssembly  \n  ****\n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** | ****<br> <br>  |\n| **** | ****<br> Rust2021 Editionasync/awaitMiri320212024<br> 2018 |\n| **** | ****<br> <br>  - [Rust](https://doc.rust-lang.org/)<br>  - Rust RFCRequest for Comments<br>  - ACM/IEEERust: A Language for Safe Systems Programming<br>  - MozillaMicrosoftAmazonMeta |\n\n---\n\n### **3. **  \n\n#### ****  \n- `Rust programming language features`  \n- `Rust use cases`  \n- `Rust advantages over C++`  \n- `Rust ownership system`  \n- `Rust memory safety`  \n- `Rust systems programming`\n\n#### ****  \n- ****borrow checker, lifetimes, zero-cost abstractions, async/await, FFI, cargo  \n- **** WebAssembly, embedded systems, blockchain, operating systems (e.g., Redox), game engines, CLI tools  \n- **** C++, Go, PythonRust  \n- **** Rust in production, Rust adoption 2024, Rust at Microsoft/Amazon\n\n#### ****  \n```plaintext\n# \nsite:doc.rust-lang.org \"ownership\" \"borrow checker\"  \nsite:rust-lang.org/blog \"Rust use cases\"  \nintitle:\"Rust programming language\" features applications  \nfiletype:pdf \"Rust systems programming\" site:arxiv.org  \n\"Rust vs C++ performance\" site:medium.com OR site:dev.to  \n\"Rust in production\" 2023..2024\n```\n\n#### ****  \n- `beginner tutorial``how to install Rust``Rust for kids`  \n- `Rust language review`  \n- `Rust crash course`\n\n---\n\n### **4. **  \n\n#### ****  \n ** + **  \n-   \n  `Rust  Rust blog  ACM Microsoft AzureCloudflare`  \n-   \n  -   \n  - LinuxFirefoxDocker  \n  - \n\n#### ****  \n ** + **  \n-   \n  `GitHub trending Rust repos (20232024)  Rust Survey (2023/2024)  Stack Overflow trends`  \n-   \n  - RustStack Overflow 20238  \n  - WebAssembly\n\n#### ****  \n ****  \n1. ****Rust****  \n2. ****Rust****LinuxAWS Firecracker  \n3. ****CSDN  \n4. ****TechEmpowerRust vs Go HTTP\n\n---\n\n### ****  \n> ****  \n> 1.  [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/)  What is Rust?Ownership  \n> 2. `site:rust-lang.org/blog \"use cases\" 2023`  \n> 3.  arXiv.org `\"Rust systems programming\"` + `filetype:pdf`  \n> 4.  [Rust Survey 2023](https://blog.rust-lang.org/2023/12/12/rust-survey-2023.html)   \n> 5.  GitHub `language:rust stars:>10k`  Topdeno, rust-analyzer, warp  \n\n********Rust\n\n--- \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:51:46.495044 #15674]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T12:51:46.495071 #15674]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T12:51:46.495088 #15674]  INFO -- : Create Conversation
I, [2025-12-10T12:51:46.495122 #15674]  INFO -- : Use template pre_search
I, [2025-12-10T12:51:46.495552 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:51:46.495602 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:51:49.021793 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:51:49.021918 #15674]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:51:49.021943 #15674]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T12:51:51.355889 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/\",\"link\":\"https://doc.rust-lang.org/book/\",\"snippet\":\"The Rust Programming Language by Steve Klabnik, Carol Nichols, and Chris Krycho, with contributions from the Rust Community\",\"title\":\"The Rust Programming Language\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/hide-experimental-features-in-std-docs/99886\",\"link\":\"https://users.rust-lang.org/t/hide-experimental-features-in-std-docs/99886\",\"snippet\":\"Sep 14, 2023 ... Is there any \\\"official\\\" way to do so? I'm aware of this forum post, some time has passed since then and maybe there's some better way to...\",\"title\":\"Hide experimental features in std docs - The Rust Programming ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../types_and_selfdocumenting_code_in_rust/\",\"link\":\"https://www.reddit.com/r/rust/comments/1d2qns1/types_and_selfdocumenting_code_in_rust/\",\"snippet\":\"May 28, 2024 ... The convention is documented in https://rust-lang.github.io/api-guidelines/naming.html#c-iter-ty Iterator is marked as a \\\"Notable Trait\\\",...\",\"title\":\"Types and self-documenting code in Rust : r/rust\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/how-to-document-optional-features.../64577\",\"link\":\"https://users.rust-lang.org/t/how-to-document-optional-features-in-api-docs/64577\",\"snippet\":\"Sep 9, 2021 ... The Rust Programming Language Forum  How to document optional ... We can use this to conditionally enable nightly features when building...\",\"title\":\"How to document optional features in API docs - help - The Rust ...\"},{\"formattedUrl\":\"https://github.com/rust-lang/reference/issues/788\",\"link\":\"https://github.com/rust-lang/reference/issues/788\",\"snippet\":\"Apr 4, 2020 ... I think reborrowing is an important enough topic to get covered in some official documentation, and if not the book, then the reference should expand upon this...\",\"title\":\"better documentation of reborrowing  Issue #788  rust-lang/reference\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/documentation-of-types...problem/53274\",\"link\":\"https://users.rust-lang.org/t/documentation-of-types-discoverability-problem/53274\",\"snippet\":\"Dec 26, 2020 ... The Rust Programming Language Forum  Documentation of types ... feature prominently in the documentation. 3 Likes. Hyeonu December 28...\",\"title\":\"Documentation of types, discoverability problem - The Rust ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../what_is_the_next_big_thing_coming_to_...\",\"link\":\"https://www.reddit.com/r/rust/comments/ze2foc/what_is_the_next_big_thing_coming_to_rust/\",\"snippet\":\"Dec 6, 2022 ... ... official documentation (eg. why does docs.rust-lang.org show me nightly stuff at all unless I specifically ask for the nightly documentation?!)\",\"title\":\"What is the next big thing coming to Rust : r/rust\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/learning-rust...official...documentation/1579...\",\"link\":\"https://internals.rust-lang.org/t/learning-rust-with-official-books-documentation/15794\",\"snippet\":\"Dec 15, 2021 ... ... Rust Programming Language + Rust by Example I think both are not suit ... This version will have the most important and widely used features of...\",\"title\":\"Learning Rust with Official Books \\u0026 Documentation - documentation ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../why_do_rust_crates_rarely_have_good_d...\",\"link\":\"https://www.reddit.com/r/rust/comments/saxk20/why_do_rust_crates_rarely_have_good_documentation/\",\"snippet\":\"Jan 23, 2022 ... Doesn't Rust have incredible documentation features? I just don ... The Rust Programming Language. A place for all things related to the...\",\"title\":\"Why do Rust crates rarely have good documentation? : r/rust\"},{\"formattedUrl\":\"https://discourse.julialang.org/t/the-challenges-of-documenting.../103198\",\"link\":\"https://discourse.julialang.org/t/the-challenges-of-documenting-generic-functions/103198\",\"snippet\":\"Aug 24, 2023 ... Julia Programming Language  The challenges of documenting generic ... official documentation of color schemes: https://docs.juliaplots...\",\"title\":\"The challenges of documenting generic functions - General Usage ...\"}]", :with_history=>false}
I, [2025-12-10T12:51:51.355931 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:51:51.355942 #15674]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T12:51:51.355958 #15674]  INFO -- : Create Conversation
I, [2025-12-10T12:51:51.355979 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:51:51.356208 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:51:51.356236 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:51:51.548468 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:51:51.548559 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:51:51.548581 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:51:53.799178 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T12:51:53.799240 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:51:53.799275 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:51:53.799548 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:51:53.799574 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:51:54.009866 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:51:54.009991 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:51:54.010022 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:51:56.120774 #15674]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:51:56.120797 #15674]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T12:51:56.120805 #15674]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T12:51:56.120815 #15674]  INFO -- : Create Conversation
I, [2025-12-10T12:51:56.120858 #15674]  INFO -- : Use template generate_search_plan
I, [2025-12-10T12:51:56.121148 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:51:56.121176 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:51:56.900317 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:51:56.900392 #15674]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:51:56.900417 #15674]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T12:51:57.502393 #15674]  INFO -- : Calling worker: smart_search with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:51:57.502728 #15674]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T12:51:57.502757 #15674]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T12:51:57.502771 #15674]  INFO -- : Create Conversation
I, [2025-12-10T12:51:57.502799 #15674]  INFO -- : Use template smart_search
I, [2025-12-10T12:51:57.503043 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:51:57.503077 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:52:00.607731 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:00.607818 #15674]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:52:00.607835 #15674]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T12:52:02.568881 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"snippet\":\"Many programming languages don't require you to think about the stack and the heap very often. But in a systems programming language like Rust, whether a value...\",\"title\":\"What is Ownership? - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"snippet\":\"It enables Rust to make memory safety guarantees without needing a garbage collector, so it's important to understand how ownership works. In this chapter, we'...\",\"title\":\"Understanding Ownership - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"fn calculate_length(s: \\u0026String) -\\u003e usize { // s is a reference to a String s.len() } // Here, s goes out of scope. But because s does not have ownership of what...\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"snippet\":\"Over time, the team discovered that the ownership and type systems are a powerful set of tools to help manage memory safety and concurrency problems! By...\",\"title\":\"Fearless Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-02-message-passing.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-02-message-passing.html\",\"snippet\":\"... ownership throughout your Rust programs. ... This stops us from accidentally using the value again after sending it; the ownership system checks that everything...\",\"title\":\"Using Message Passing to Transfer Data Between Threads - The ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"snippet\":\"Consider this part of the slogan from the Go language documentation again: Do not communicate by sharing memory. ... Rust's type system and ownership rules...\",\"title\":\"Shared-State Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"... system or even writing your own operating system. Working with low-level ... ownership rules don't allow a mutable reference at the same time as any...\",\"title\":\"Unsafe Rust - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"snippet\":\"The Rust standard library uses a 1:1 model of thread implementation, whereby a program uses one operating system thread per one language thread. There are...\",\"title\":\"Using Threads to Run Code Simultaneously - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/ffi.html\",\"link\":\"https://doc.rust-lang.org/nomicon/ffi.html\",\"snippet\":\"Rust is currently unable to call directly into a C++ library, but snappy includes a C interface (documented in snappy-c.h ). A note about libc. Many of these...\",\"title\":\"FFI - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch10-02-traits.html\",\"link\":\"https://doc.rust-lang.org/book/ch10-02-traits.html\",\"snippet\":\"A trait defines the functionality a particular type has and can share with other types. We can use traits to define shared behavior in an abstract way.\",\"title\":\"Traits: Defining Shared Behavior - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T12:52:02.568925 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:02.569166 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:02.569505 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:02.569535 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:02.762147 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:02.762239 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:02.762259 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:04.665461 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T12:52:04.665484 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:04.665512 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:04.665801 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:04.665838 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:04.862416 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:04.862497 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:04.862523 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:07.016340 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../is_rust_worth_the_time_and_investment_...\",\"link\":\"https://www.reddit.com/r/rust/comments/sw0psz/is_rust_worth_the_time_and_investment_to_learn/\",\"snippet\":\"Feb 19, 2022 ... But it can still be useful in production today. Among the companies using Rust: Dropbox, Cloudflare, Facebook, Discord, Amazon, Microsoft,...\",\"title\":\"Is rust worth the time and investment to learn? : r/rust\"},{\"formattedUrl\":\"https://news.ycombinator.com/item?id=39551115\",\"link\":\"https://news.ycombinator.com/item?id=39551115\",\"snippet\":\"Feb 29, 2024 ... After reading that original article, I'm wondering how HAproxy would have stacked up against Nginx. It seems much more suited to their use cases...\",\"title\":\"Cloudflare Makes Pingora Rust Framework Open-Source | Hacker ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/comments/.../dioxus_labs_highlevel_rust/\",\"link\":\"https://www.reddit.com/r/rust/comments/1dkzzn5/dioxus_labs_highlevel_rust/\",\"snippet\":\"Jun 21, 2024 ... Amazon/Google/Cloudflare/Microsoft sponsor ... Their use cases for Rust ... production is annoying and I'd rather do it all in Rust. So from...\",\"title\":\"Dioxus Labs + High-level Rust : r/rust\"},{\"formattedUrl\":\"https://news.ycombinator.com/item?id=39552332\",\"link\":\"https://news.ycombinator.com/item?id=39552332\",\"snippet\":\"It's really hard to argue against something Cloudflare is using in production across many regions. ... It seems much more suited to their use cases. That...\",\"title\":\"I was honestly wondering if this would happen. This is very ...\"},{\"formattedUrl\":\"https://medium.com/.../why-no-one-is-talking-about-rust-in-2025-21d7e05...\",\"link\":\"https://medium.com/solo-devs/why-no-one-is-talking-about-rust-in-2025-21d7e059fa49\",\"snippet\":\"Mar 24, 2025 ... Volvo's cars (Medium), Cloudflare's traffic (GitHub Blog), and Microsoft's Azure (InfoQ) prove it's production-ready. The 2024 Rust Survey (Rust...\",\"title\":\"Why no one is talking about Rust in 2025  | by Sreeved Vp | solo ...\"},{\"formattedUrl\":\"https://github.com/hyperium/hyper/issues/3728\",\"link\":\"https://github.com/hyperium/hyper/issues/3728\",\"snippet\":\"Aug 7, 2024 ... This test aims to be a little more representative of a large scale production use case where many clients send few requests to an http server.\",\"title\":\"Poor performance in http/1.1 with many socket connections  Issue ...\"},{\"formattedUrl\":\"https://www.qovery.com/blog/why-rust-has-a-bright-future-in-the-cloud\",\"link\":\"https://www.qovery.com/blog/why-rust-has-a-bright-future-in-the-cloud\",\"snippet\":\"... Microsoft, Cloudflare, Dropbox, and many others. Let us explore more on ... Rust has also been used to deliver Amazon Elastic Compute Cloud (Amazon EC2)...\",\"title\":\"Why Rust Has a Bright Future in the Cloud\"},{\"formattedUrl\":\"https://codingplainenglish.medium.com/big-tech-isnt-abandoning-rust-they...\",\"link\":\"https://codingplainenglish.medium.com/big-tech-isnt-abandoning-rust-they-re-using-it-where-it-matters-most-1a313a8340bb\",\"snippet\":\"Jul 24, 2025 ... Microsoft put Rust inside the Windows kernel  Google made it official in Android system components  Amazon, Dropbox, and Discord all built...\",\"title\":\"Big Tech Isn't Abandoning Rust  They're Using It Where It Matters ...\"},{\"formattedUrl\":\"https://serokell.io/blog/rust-companies\",\"link\":\"https://serokell.io/blog/rust-companies\",\"snippet\":\"Nov 17, 2020 ... \",\"title\":\"9 Companies That Use Rust in Production\"},{\"formattedUrl\":\"https://developers.cloudflare.com/cloudflare-one/.../cloudflare-tunnel/\",\"link\":\"https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/\",\"snippet\":\"Oct 21, 2025 ... Create a tunnel using the Cloudflare dashboard or API.  Learn more about cloudflared , the server-side daemon that connects your infrastructure...\",\"title\":\"Cloudflare Tunnel  Cloudflare One docs\"}]", :with_history=>false}
I, [2025-12-10T12:52:07.016382 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:07.016413 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:07.016665 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:07.016696 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:07.234108 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:07.234230 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:07.234277 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:09.202423 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://arxiv.org/pdf/2209.09127\",\"link\":\"https://arxiv.org/pdf/2209.09127\",\"snippet\":\"Sep 19, 2022 ... programs written in Rust are not only memory-safe but also fast, leading to performance comparable to C and C++. Multiple existing...\",\"title\":\"Is Rust C++-fast? Benchmarking System Languages on Everyday ...\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2510.20688\",\"link\":\"https://arxiv.org/pdf/2510.20688\",\"snippet\":\"Oct 23, 2025 ... Both C/C++ and unsafe Rust code can be protected from exploitation by applying memory-safety sanitizers [40, 42] to the whole code base, which...\",\"title\":\"SafeFFI: Efficient Sanitization at the Boundary Between Safe and ...\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2206.05503\",\"link\":\"https://arxiv.org/pdf/2206.05503\",\"snippet\":\"Jun 11, 2022 ... The main focus of Rust is (memory) safety, but it later began to target performance as well, adopting the. C++ approach of zero cost abstraction...\",\"title\":\"Rust: The Programming Language for Safety and Performance\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2509.16389\",\"link\":\"https://arxiv.org/pdf/2509.16389\",\"snippet\":\"Sep 19, 2025 ... benchmarks, benchmarking functions compiled and included in LLVM IR are treated as entry points as well. 5. Page 6. guarantees, exposed raw...\",\"title\":\"LiteRSan: Lightweight Memory Safety Via Rust-specific Program ...\"},{\"formattedUrl\":\"https://arxiv.org/pdf/1509.02796\",\"link\":\"https://arxiv.org/pdf/1509.02796\",\"snippet\":\"Sep 9, 2015 ... languages, such as speed and a small memory footprint. Supporting automatic type inference, it's code is often less verbose than C or C++ code.\",\"title\":\"Rust-Bio-a fast and safe bioinformatics library\"},{\"formattedUrl\":\"https://www.arxiv.org/pdf/2510.03879\",\"link\":\"https://www.arxiv.org/pdf/2510.03879\",\"snippet\":\"Oct 4, 2025 ... Memory safety vulnerabilities in C/C++ code constitute a large fraction of security vulnerabilities each year. Microsoft reported 70% of...\",\"title\":\"Adversarial Agent Collaboration for C to Rust Translation\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2411.14174\",\"link\":\"https://arxiv.org/pdf/2411.14174\",\"snippet\":\"Dec 6, 2024 ... All participants are familiar with memory safety errors in C/C++ programs and were given an introduction to Rust1. The task, which is part...\",\"title\":\"Translating C To Rust: Lessons from a User Study\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2412.15042\",\"link\":\"https://arxiv.org/pdf/2412.15042\",\"snippet\":\"Dec 19, 2024 ... Combining the high performance and low-level idioms commonly provided by languages like C and C++ with memory safety by design, the Rust...\",\"title\":\"Compiling C to Safe Rust, Formalized\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2412.14234?\",\"link\":\"https://arxiv.org/pdf/2412.14234?\",\"snippet\":\"Dec 21, 2024 ... Rust, a modern systems programming language, offers a compelling alternative. Its unique ownership model and type system ensure memory safety...\",\"title\":\"Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs ...\"},{\"formattedUrl\":\"https://www.arxiv.org/pdf/2501.14257\",\"link\":\"https://www.arxiv.org/pdf/2501.14257\",\"snippet\":\"Jan 24, 2025 ... ... Rust, to benefit from the memory and thread safety guarantees of ... C and C++ (which are susceptible to bugs and security.\",\"title\":\"C2saferrust: Transforming c projects into safer rust with ...\"}]", :with_history=>false}
I, [2025-12-10T12:52:09.202441 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:09.202469 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:09.202738 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:09.202771 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:09.422600 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:09.422690 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:09.422710 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:11.446997 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../opinions_on_rust_for_hardrealtimesystems...\",\"link\":\"https://www.reddit.com/r/rust/comments/m0irjk/opinions_on_rust_for_hardrealtimesystems/\",\"snippet\":\"Mar 8, 2021 ... Real hard real time systems do not use heap at all. The lion's share ... Introducing RoboPLC - Linux real-time applications in Rust. 101...\",\"title\":\"Opinions on Rust for hard-realtime/systems development? : r/rust\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/concerns-about-embedded-real...rust/91416\",\"link\":\"https://users.rust-lang.org/t/concerns-about-embedded-real-time-linux-using-rust/91416\",\"snippet\":\"Mar 24, 2023 ... ... real time applications due the background processing? ... Rust is not different from C in this regard; and embedded systems are one of the fields...\",\"title\":\"Concerns about embedded real time linux using rust - help - The ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../embedded/.../is_anyone_using_rust_for_embedd...\",\"link\":\"https://www.reddit.com/r/embedded/comments/1amh6jq/is_anyone_using_rust_for_embedded_work/\",\"snippet\":\"Feb 9, 2024 ... Only a fool would develop embedded systems with rust. And here is a few reasons why: ... system, often with real-time computing constraints.\\\" Show...\",\"title\":\"Is anyone using Rust for embedded work ? : r/embedded\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/rust-for-embedded-development.../10861\",\"link\":\"https://users.rust-lang.org/t/rust-for-embedded-development-where-we-are-and-whats-missing/10861\",\"snippet\":\"May 19, 2017 ... Application space: real time systems, control systems, robotics ... I want to write pure Rust applications in a real-time context. And...\",\"title\":\"Rust for embedded development: Where we are and what's missing ...\"},{\"formattedUrl\":\"https://github.com/rust-embedded/awesome-embedded-rust\",\"link\":\"https://github.com/rust-embedded/awesome-embedded-rust\",\"snippet\":\"... embedded systems that uses Rust as the teaching language. Original author: @japaric ... An Embedded Operating System for writing real-time applications in Rust.\",\"title\":\"rust-embedded/awesome-embedded-rust: Curated list of ... - GitHub\"},{\"formattedUrl\":\"https://serokell.io/blog/best-rust-in-use-cases\",\"link\":\"https://serokell.io/blog/best-rust-in-use-cases\",\"snippet\":\"Jun 17, 2024 ... \",\"title\":\"Best Rust business applications in the real world\"},{\"formattedUrl\":\"https://github.com/rust-unofficial/awesome-rust\",\"link\":\"https://github.com/rust-unofficial/awesome-rust\",\"snippet\":\"... embedded devices and desktop applications. Build Status  tauri-apps/tauri ... real-time systems. message-io. lemunozm/message-io - Event-driven message...\",\"title\":\"rust-unofficial/awesome-rust: A curated list of Rust code ... - GitHub\"},{\"formattedUrl\":\"https://www.linkedin.com/.../kshitij-vaze-177a16229_so-ive-had-a-couple-...\",\"link\":\"https://www.linkedin.com/posts/kshitij-vaze-177a16229_so-ive-had-a-couple-dms-asking-me-what-activity-7388766477245440001-D5ih\",\"snippet\":\"Oct 27, 2025 ... Arduino's simple boards might evolve into powerful, AI-enabled devices that can run real-world applications, robotics, and IoT solutions at...\",\"title\":\"How to break into IoT and embedded systems | Kshitij Vaze posted ...\"},{\"formattedUrl\":\"https://medium.com/.../rust-for-real-time-applications-techniques-and-tools-...\",\"link\":\"https://medium.com/@enravishjeni411/rust-for-real-time-applications-techniques-and-tools-you-need-to-know-94e4e6862712\",\"snippet\":\"Sep 24, 2024 ... Tokio is Rust's most popular asynchronous runtime, optimized for high-performance applications. It supports real-time networking and allows you...\",\"title\":\"Rust for Real-Time Applications: Techniques and Tools You Need to ...\"},{\"formattedUrl\":\"https://www.amoriabond.com/.../the-top-4-programming-languages-for-em...\",\"link\":\"https://www.amoriabond.com/insights/articles/the-top-4-programming-languages-for-embedded-systems/\",\"snippet\":\"Jun 17, 2024 ... Resource management - Rust can be used on bare-metal systems and real ... Below are some of the real-world applications of Java in embedded...\",\"title\":\"The Top 4 Programming Languages For Embedded Systems ...\"}]", :with_history=>false}
I, [2025-12-10T12:52:11.447030 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:11.447058 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:11.447361 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:11.447399 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:11.699354 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:11.699438 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:11.699456 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:13.532213 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://dev.to/deepu105/concurrency-in...rust-vs-go-vs.../comments\",\"link\":\"https://dev.to/deepu105/concurrency-in-modern-programming-languages-rust-vs-go-vs-java-vs-nodejs-vs-deno-36gg/comments\",\"snippet\":\"Feb 4, 2022 ... Building a concurrent web server in Rust, Go, JS, TS, .NET, and Java to compare concurrency performance.\",\"title\":\"Discussion of Concurrency in modern programming languages ...\"},{\"formattedUrl\":\"https://dev.to/.../performance-comparison-rust-vs-crystal-with-redis-1a17\",\"link\":\"https://dev.to/jgaskins/performance-comparison-rust-vs-crystal-with-redis-1a17\",\"snippet\":\"Jun 26, 2020 ... Anyway, if you use Ruby or Python for their expressiveness and Rust or Go for their performance, it might be worth writing a part of your app in...\",\"title\":\"Performance Comparison, Rust vs Crystal with Redis - DEV ...\"},{\"formattedUrl\":\"https://dev.to/.../rust-vs-nodejs-vs-go-performance-comparison-for-backen...\",\"link\":\"https://dev.to/hamzakhan/rust-vs-nodejs-vs-go-performance-comparison-for-backend-development-2g69\",\"snippet\":\"Sep 23, 2024 ... ... ::Infallible; async fn handle_request(_: Request\\u003cBody\\u003e) -\\u003e Result\\u003cResponse\\u003cBody\\u003e, Infallible\\u003e { Ok(Response::new(Body::from(\\\"Hello from...\",\"title\":\"**Rust vs Node.js vs Go: Performance Comparison for Backend ...\"},{\"formattedUrl\":\"https://dev.to/.../shell-scripting-vs-go-practical-notes-form-a-reimplementati...\",\"link\":\"https://dev.to/taikedz/shell-scripting-vs-go-practical-notes-form-a-reimplementation-project-1b18\",\"snippet\":\"Jun 9, 2025 ... I reimplemented a shell script in Go and am looking back at the experience. Tagged with go, bash, python, comparison.\",\"title\":\"Shell/Python vs Go - practical thoughts form a reimplementation ...\"},{\"formattedUrl\":\"https://dev.to/.../rust-vs-go-which-should-you-choose-in-2024-50k5\",\"link\":\"https://dev.to/thatcoolguy/rust-vs-go-which-should-you-choose-in-2024-50k5\",\"snippet\":\"Aug 27, 2024 ... In this section, you'll learn how Rust and Go compare in terms of speed and memory usage. ... Rust's async/await paradigm allows you to...\",\"title\":\"Rust vs Go? Which Should You Learn in 2025 - DEV Community\"},{\"formattedUrl\":\"https://dev.to/.../optimized-api-calls-with-typescript-performance-showdow...\",\"link\":\"https://dev.to/hamzakhan/optimized-api-calls-with-typescript-performance-showdown-vs-rust-go-4495\",\"snippet\":\"Oct 3, 2024 ...  Performance Comparison: TypeScript vs Rust vs Go. Now that we've ... Rust: Rust's low-level control and highly efficient async...\",\"title\":\"Optimized API Calls with TypeScript: Performance Showdown vs ...\"},{\"formattedUrl\":\"https://dev.to/.../rust-web-frameworks-compared-actix-vs-axum-vs-rocket-4...\",\"link\":\"https://dev.to/leapcell/rust-web-frameworks-compared-actix-vs-axum-vs-rocket-4bad\",\"snippet\":\"Jul 20, 2025 ... Asynchronous and Concurrent: Leveraging Rust's async/await syntax ... Python, Go, or Rust. Deploy Unlimited Projects for Free: Pay...\",\"title\":\"Rust Web Frameworks Compared: Actix vs Axum vs Rocket - DEV ...\"},{\"formattedUrl\":\"https://dev.to/.../yes-python-is-slow-but-it-doesnt-matter-for-ai-saas-2183\",\"link\":\"https://dev.to/igorbenav/yes-python-is-slow-but-it-doesnt-matter-for-ai-saas-2183\",\"snippet\":\"Sep 10, 2025 ... Very specific performance comparison between Python, Rust, Go, and C++ ... Use async/await properly. Poor API usage: Making 5 separate API...\",\"title\":\"Yes, Python is Slow, but it doesn't matter for AI SaaS - DEV Community\"},{\"formattedUrl\":\"https://dev.to/.../swift-vs-rust-an-overview-of-swift-from-a-rusty-perspectiv...\",\"link\":\"https://dev.to/rhymu/swift-vs-rust-an-overview-of-swift-from-a-rusty-perspective-18c7\",\"snippet\":\"Feb 6, 2021 ... Rust includes direct syntax for asynchronous programming ( async , await ) ... comparison to Rust. Being relatively unencumbered, Rust has a...\",\"title\":\"Swift vs. Rust -- an Overview of Swift from a Rusty Perspective - DEV ...\"},{\"formattedUrl\":\"https://dev.to/.../typescript-vs-go-choosing-your-backend-language-2bc5\",\"link\":\"https://dev.to/encore/typescript-vs-go-choosing-your-backend-language-2bc5\",\"snippet\":\"Nov 8, 2024 ... async function fetchData() { const response = await fetch('https ... Beats Java, Python, and JavaScript in many speed tests. It handles...\",\"title\":\"TypeScript vs Go: Choosing Your Backend Language - DEV ...\"}]", :with_history=>false}
I, [2025-12-10T12:52:13.532258 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:13.532285 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:13.532517 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:13.532544 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:13.795694 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:13.795818 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:13.795848 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:16.081716 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../rfc_rust_support_for_linux_kernel/\",\"link\":\"https://www.reddit.com/r/rust/comments/mqxr1a/rfc_rust_support_for_linux_kernel/\",\"snippet\":\"Apr 14, 2021 ... Alternatively, it may prompt owners of such system to think about supporting a LLVM backend. ... Linux's design was flawed from the beginning and...\",\"title\":\"[RFC] Rust support for Linux Kernel : r/rust\"},{\"formattedUrl\":\"https://rust-lang.github.io/rfcs/3535-constants-in-patterns.html\",\"link\":\"https://rust-lang.github.io/rfcs/3535-constants-in-patterns.html\",\"snippet\":\"(Remember that StructuralPartialEq only reflects shallow structural equality.) Rationale and alternatives. The main design rationale has been explained in the...\",\"title\":\"3535-constants-in-patterns - The Rust RFC Book\"},{\"formattedUrl\":\"https://news.ycombinator.com/item?id=15579806\",\"link\":\"https://news.ycombinator.com/item?id=15579806\",\"snippet\":\"Oct 29, 2017 ... More generally, the 1-32 issue should be solved when RFC 2000 is implemented [0]. In the meantime there's generic-array [1], built on top of...\",\"title\":\"Why Rust fails hard at scientific computing | Hacker News\"},{\"formattedUrl\":\"https://rust-lang.github.io/rfcs/2000-const-generics.html\",\"link\":\"https://rust-lang.github.io/rfcs/2000-const-generics.html\",\"snippet\":\"For most cases, the equality of two consts follows the same reasoning you would expect - two constant values are equal if they are equal to one another. But...\",\"title\":\"2000-const-generics - The Rust RFC Book\"},{\"formattedUrl\":\"https://www.utsystem.edu/.../1999-november-fy2000-2005-cip-and-fy2000...\",\"link\":\"https://www.utsystem.edu/sites/default/files/documents/2017/cip-updates/1999-november-fy2000-2005-cip-and-fy2000-01-capital-budget.pdf\",\"snippet\":\"Nov 11, 1999 ... Projects Scheduled to Receive Design Development Approval in FY 2000 and FY 2001 ... reilforWg steel to rust. The settlement problem and...\",\"title\":\"The University of Texas System Capital Improvement Program\"},{\"formattedUrl\":\"https://rust-lang.github.io/rfcs/2394-async_await.html\",\"link\":\"https://rust-lang.github.io/rfcs/2394-async_await.html\",\"snippet\":\"As with async closures, async blocks can be annotated with move to capture ownership of the variables they close over. The await! compiler built-in. A builtin...\",\"title\":\"2394-async_await - The Rust RFC Book\"},{\"formattedUrl\":\"https://stackoverflow.com/.../is-the-order-of-elements-in-a-json-list-preserve...\",\"link\":\"https://stackoverflow.com/questions/7214293/is-the-order-of-elements-in-a-json-list-preserved\",\"snippet\":\"Aug 27, 2011 ... Yes, the order of elements in JSON arrays is preserved. From RFC 7159 -The JavaScript Object Notation (JSON) Data Interchange Format...\",\"title\":\"javascript - Is the order of elements in a JSON list preserved? - Stack ...\"},{\"formattedUrl\":\"https://rust-lang.github.io/rfcs/\",\"link\":\"https://rust-lang.github.io/rfcs/\",\"snippet\":\"Modifications to active RFCs can be done in follow-up pull requests. We strive to write each RFC in a manner that it will reflect the final design of the...\",\"title\":\"Introduction - The Rust RFC Book\"},{\"formattedUrl\":\"https://stackoverflow.com/.../what-is-the-proper-rest-response-code-for-a-v...\",\"link\":\"https://stackoverflow.com/questions/11746894/what-is-the-proper-rest-response-code-for-a-valid-request-but-empty-data\",\"snippet\":\"Jul 31, 2012 ... 204 for the question in the title. 404 for the question in the description. The Request-URI does NOT stop at 'users'.\",\"title\":\"http - What is the proper REST response code for a valid request but ...\"},{\"formattedUrl\":\"https://rust-lang.github.io/rfcs/3660-crates-io-crate-deletions.html\",\"link\":\"https://rust-lang.github.io/rfcs/3660-crates-io-crate-deletions.html\",\"snippet\":\"Rationale and alternatives. Why is this design the best in the space of possible designs? The proposed design is based on the current informal rules that the...\",\"title\":\"3660-crates-io-crate-deletions - The Rust RFC Book\"}]", :with_history=>false}
I, [2025-12-10T12:52:16.081859 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:16.081912 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:16.082582 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:16.082653 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:16.321956 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:16.322038 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:16.322056 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:18.343488 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://blog.rust-lang.org/2024/02/.../2023-Rust-Annual-Survey-2023-resul...\",\"link\":\"https://blog.rust-lang.org/2024/02/19/2023-Rust-Annual-Survey-2023-results/\",\"snippet\":\"Feb 19, 2024 ... This eighth edition of the survey surfaced new insights and learning opportunities straight from the global Rust language community, which we...\",\"title\":\"2023 Annual Rust Survey Results | Rust Blog\"},{\"formattedUrl\":\"https://survey.stackoverflow.co/2024/technology\",\"link\":\"https://survey.stackoverflow.co/2024/technology\",\"snippet\":\"... community-vetted technology options. ... AWS' share of usage amongst respondents is the same in 2024 as in 2023, while Azure and Google Cloud increased their...\",\"title\":\"Technology | 2024 Stack Overflow Developer Survey\"},{\"formattedUrl\":\"https://blog.rust-lang.org/2025/02/13/2024-State-Of-Rust-Survey-results\",\"link\":\"https://blog.rust-lang.org/2025/02/13/2024-State-Of-Rust-Survey-results\",\"snippet\":\"Feb 13, 2025 ... ... Rust language community, which we will summarize below. In ... Year 2022 2023 2024 How would you rate your Rust expertise? (total...\",\"title\":\"2024 State of Rust Survey Results | Rust Blog\"},{\"formattedUrl\":\"https://survey.stackoverflow.co/2023\",\"link\":\"https://survey.stackoverflow.co/2023\",\"snippet\":\"Jun 13, 2023 ... Rust is the most admired language, more than 80% of developers that use it want to use it again next year. Compare this to the least admired...\",\"title\":\"Stack Overflow Developer Survey 2023\"},{\"formattedUrl\":\"https://blog.jetbrains.com/clion/2024/01/the-cpp-ecosystem-in-2023/\",\"link\":\"https://blog.jetbrains.com/clion/2024/01/the-cpp-ecosystem-in-2023/\",\"snippet\":\"Jan 16, 2024 ... Every year, JetBrains runs the Developer Ecosystem Survey to capture the landscape of the developer community, and this year's results are...\",\"title\":\"The C++ Ecosystem in 2023: Growth of C++20, Wider Adoption of ...\"},{\"formattedUrl\":\"https://www.tiobe.com/tiobe-index/\",\"link\":\"https://www.tiobe.com/tiobe-index/\",\"snippet\":\"As statistics and large-scale data visualization become increasingly ... Winner. 2024, medal Python. 2023, medal C#. 2022, medal C++. 2021, medal Python. 2020...\",\"title\":\"TIOBE Index - TIOBE\"},{\"formattedUrl\":\"https://www.jetbrains.com/lp/devecosystem-2024/\",\"link\":\"https://www.jetbrains.com/lp/devecosystem-2024/\",\"snippet\":\"The undisputed leaders of the JetBrains Language Promise Index are TypeScript, Rust, and Python. Python, which started out with a 32% share in our first survey...\",\"title\":\"Software Developers Statistics 2024 - State of Developer Ecosystem ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../2023_stack_overflow_survey_rust_is_the...\",\"link\":\"https://www.reddit.com/r/rust/comments/149cu1k/2023_stack_overflow_survey_rust_is_the_most/\",\"snippet\":\"Jun 15, 2023 ... Rust is a great language but its not being adopted by most developers because Rust's key features are irrelevant to them.\",\"title\":\"2023 Stack Overflow Survey: Rust is the most admired programming ...\"},{\"formattedUrl\":\"https://medium.com/.../why-no-one-is-talking-about-rust-in-2025-21d7e05...\",\"link\":\"https://medium.com/solo-devs/why-no-one-is-talking-about-rust-in-2025-21d7e059fa49\",\"snippet\":\"Mar 24, 2025 ... Usage stats don't scream collapse  GitHub's 355K Rust crates grew 20% in 2024 (GitHub Blog), and Stack Overflow's 2024 survey shows 12% of pros...\",\"title\":\"Why no one is talking about Rust in 2025  | by Sreeved Vp | solo ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../survey_why_have_you_stopped_using_scala_or...\",\"link\":\"https://www.reddit.com/r/scala/comments/195qk4u/survey_why_have_you_stopped_using_scala_or_are/\",\"snippet\":\"Jan 13, 2024 ... Growing and healthy community, wider adoption by the industry ... I'll likely invest more time/money into Rust in 2024. I'm afraid to...\",\"title\":\"Survey: Why have you stopped using Scala or Are considering ...\"}]", :with_history=>false}
I, [2025-12-10T12:52:18.343519 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:18.343544 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:18.343824 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:18.343853 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:18.564571 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:18.564705 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:18.564733 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:20.561080 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.reddit.com/.../Polkadot/.../i_wanna_become_a_developer_and...\",\"link\":\"https://www.reddit.com/r/Polkadot/comments/s2oyez/i_wanna_become_a_developer_and_i_wanna_work_with/\",\"snippet\":\"Jan 13, 2022 ... Polkadot works with Rust (as do many of the next gen blockchains like Solana, Cosmos, ICP, etc). More specifically, Parity is creating a...\",\"title\":\"I wanna become a developer and I wanna work with in polkadot ...\"},{\"formattedUrl\":\"https://x.com/0xcastle_chain\",\"link\":\"https://x.com/0xcastle_chain\",\"snippet\":\"Rust-Based ecosystems : Solana , CosmWasm ,Polkadot | +50 Rust Audits | + ... Ensure blockchain projects are built on solid security foundations from...\",\"title\":\"0xFrankCastle (@0xcastle_chain) / Posts / X\"},{\"formattedUrl\":\"https://www.reddit.com/.../solidity_vs_rust_in_terms_of_jobs_prospects_yo...\",\"link\":\"https://www.reddit.com/r/ethdev/comments/175bz0l/solidity_vs_rust_in_terms_of_jobs_prospects_your/\",\"snippet\":\"Oct 11, 2023 ... ... project while with Rust you can go with Solana, Polkadot, and Near. ... Yeah but Rust has more applications beyond the blockchain that rust doesn'...\",\"title\":\"Solidity vs Rust in terms of jobs prospects - your opinion? : r/ethdev\"},{\"formattedUrl\":\"https://blog.stackademic.com/solana-blockchain-development-why-rust-b8c...\",\"link\":\"https://blog.stackademic.com/solana-blockchain-development-why-rust-b8cd65a02743\",\"snippet\":\"Feb 22, 2025 ... Here are some other notable blockchain projects using Rust: 1. Polkadot. Polkadot's Substrate framework is written in Rust, enabling...\",\"title\":\"Solana Blockchain Development: Why Rust? | by Ryan Godlonton ...\"},{\"formattedUrl\":\"https://medium.com/.../rust-for-blockchain-in-2025-powering-the-decentral...\",\"link\":\"https://medium.com/solo-devs/rust-for-blockchain-in-2025-powering-the-decentralized-future-09069ce627c1\",\"snippet\":\"May 16, 2025 ... Projects like Solana, Polkadot, and Near rely on Rust for their core infrastructure. This article explores why Rust is dominating blockchain...\",\"title\":\"Rust for Blockchain in 2025: Powering the Decentralized Future | by ...\"},{\"formattedUrl\":\"https://www.itmagination.com/blog/rust-development-blockchain-web3\",\"link\":\"https://www.itmagination.com/blog/rust-development-blockchain-web3\",\"snippet\":\"Few years down the line, and we have a top project with numerous contributors, and a strong community. Solana and Polkadot are fighting Ethereum on their quest...\",\"title\":\"Rust: The Perfect Language For Blockchain Development [UPDATED]\"},{\"formattedUrl\":\"https://medium.com/.../why-rust-is-becoming-the-go-to-language-for-high-...\",\"link\":\"https://medium.com/@bhagyarana80/why-rust-is-becoming-the-go-to-language-for-high-performance-blockchain-apps-83ca7aeaaa34\",\"snippet\":\"Jul 13, 2025 ... From Solana to Polkadot, Rust's blend of speed, safety, and modern design is redefining the future of blockchain development.\",\"title\":\"Why Rust Is Becoming the Go-To Language for High-Performance ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/smart-contracts-nft-blockchain...rust.../64681\",\"link\":\"https://users.rust-lang.org/t/smart-contracts-nft-blockchain-market-places-rust-vs-go/64681\",\"snippet\":\"Sep 11, 2021 ... Solana and Polkadot are the main chains I know comprised entirely of Rust. Heres a look at Dot and their node implementation in Rust: GitHub...\",\"title\":\"Smart contracts, nft, blockchain market places: Rust vs Go - The Rust ...\"},{\"formattedUrl\":\"https://pk.linkedin.com/in/masimhayat\",\"link\":\"https://pk.linkedin.com/in/masimhayat\",\"snippet\":\"Lead Blockchain Engineer | Ethereum | Solana | Polkadot | Web3 | NFT | DeFi ... Substrate | Rust |Crypto l !nk  As a highly experienced and accomplished...\",\"title\":\"Asim Hayat - Lead Blockchain Engineer | Ethereum | Solana ...\"},{\"formattedUrl\":\"https://www.rapidinnovation.io/.../rusts-role-in-blockchain-and-cryptocurre...\",\"link\":\"https://www.rapidinnovation.io/post/rusts-role-in-blockchain-and-cryptocurrency-development\",\"snippet\":\"Many prominent blockchain projects, such as Polkadot and Ethereum 2.0, are being developed using Rust, highlighting the importance of rust programming...\",\"title\":\"Rust in Blockchain and Cryptocurrency Development\"}]", :with_history=>false}
I, [2025-12-10T12:52:20.561120 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:20.561160 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:20.561557 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:20.561597 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:20.863645 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:20.863771 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:20.863801 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:22.763045 #15674]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://medium.com/.../webassembly-is-fast-a-real-world-benchmark-of-we...\",\"link\":\"https://medium.com/@torch2424/webassembly-is-fast-a-real-world-benchmark-of-webassembly-vs-es6-d85a23f8e193\",\"snippet\":\"Dec 18, 2018 ... In most of the performance tests, Rust ... However, the PSPDFKit benchmark does the comparison between WebAssembly and asm.js, and not W.\",\"title\":\"WebAssembly Is Fast: A Real-World Benchmark of WebAssembly vs ...\"},{\"formattedUrl\":\"https://medium.com/.../my-javascript-is-faster-than-your-rust-5f98fe5db1bf\",\"link\":\"https://medium.com/@jbyj/my-javascript-is-faster-than-your-rust-5f98fe5db1bf\",\"snippet\":\"Apr 30, 2022 ... js \\u0026 C++? Well I use Node.js as my benchmark for 'reasonable' performance (Go is used as the 'dream' target, it's hard to compare to...\",\"title\":\"My JavaScript is Faster than Your Rust | by Joshua Daniel | Medium\"},{\"formattedUrl\":\"https://medium.com/.../i-was-understanding-wasm-all-wrong-e4bcab8d077...\",\"link\":\"https://medium.com/@yujiisobe/i-was-understanding-wasm-all-wrong-e4bcab8d077c\",\"snippet\":\"May 5, 2024 ... ... JavaScript version using WASM ... GitHub - yujiosaka/wasm-and-ffi-performance-comparison-in-node: Compare performance between a Rust\",\"title\":\"I was understanding WASM all wrong! | by Yuji Isobe | Medium\"},{\"formattedUrl\":\"https://medium.com/javascript.../i-benchmarked-webassembly-vs-node-js-a...\",\"link\":\"https://medium.com/javascript-in-plain-english/i-benchmarked-webassembly-vs-node-js-a0ebdcfabead\",\"snippet\":\"Oct 6, 2025 ... Rust + wasm-pack: The performance king; AssemblyScript: TypeScript ... // benchmark.js - Compare your implementation import...\",\"title\":\"I Benchmarked WebAssembly vs Node.js for 6 Months  When the ...\"},{\"formattedUrl\":\"https://medium.com/.../javascript-vs-webassembly-performance-for-canvas-...\",\"link\":\"https://medium.com/source-true/javascript-vs-webassembly-performance-for-canvas-particle-system-4c4a526145d8\",\"snippet\":\"Jan 12, 2023 ... Wasm uses statically typed languages such as C/C++ and Rust for target compilation. Wasm doesn't work independently but it's designed to...\",\"title\":\"JavaScript vs WebAssembly performance for Canvas particle system ...\"},{\"formattedUrl\":\"https://medium.com/javascript.../webassembly-and-javascript-in-2025-the-p...\",\"link\":\"https://medium.com/javascript-in-plain-english/webassembly-and-javascript-in-2025-the-perfect-duo-for-high-performance-apps-612a9fcee204\",\"snippet\":\"Sep 6, 2025 ... This combination felt magical like mixing Rust's performance with JS's flexibility. ... Performance Comparison: JS vs Wasm. When I benchmarked...\",\"title\":\"WebAssembly and JavaScript in 2025: The Perfect Duo for High ...\"},{\"formattedUrl\":\"https://julien-decharentenay.medium.com/yew-vs-vuejs-webassembly-whic...\",\"link\":\"https://julien-decharentenay.medium.com/yew-vs-vuejs-webassembly-which-is-better-for-building-a-rust-app-8fa6c45c879f\",\"snippet\":\"Sep 5, 2022 ... Three implementations are presented: (a) plain VueJS  I wanted to compare the execution speed of WebAssembly vs JavaScript, (b) VueJS +...\",\"title\":\"Yew vs VueJS + WebAssembly: Which is Better for Building a Rust ...\"},{\"formattedUrl\":\"https://medium.com/.../understanding-performance-differences-javascript-v...\",\"link\":\"https://medium.com/@tagdiwalaviral/understanding-performance-differences-javascript-vs-webassembly-in-csv-parsing-a-deep-dive-8dcf743e1ab6\",\"snippet\":\"Nov 4, 2024 ... When migrating a CSV parser from JavaScript to WebAssembly (Rust), I encountered some surprising results. I'll be deep diving into the...\",\"title\":\"Understanding performance differences: JavaScript vs ...\"},{\"formattedUrl\":\"https://filia-aleks.medium.com/aws-lambda-battle-2021-performance-comp...\",\"link\":\"https://filia-aleks.medium.com/aws-lambda-battle-2021-performance-comparison-for-all-languages-c1b441005fd1\",\"snippet\":\"Sep 16, 2021 ... Let's compare the performance of all supported runtimes + 2 custom runtimes (Rust and GraalVM). Will compare cold start and warm.\",\"title\":\"AWS Lambda battle 2021: performance comparison for all ...\"},{\"formattedUrl\":\"https://medium.com/.../2d-web-rendering-with-rust-4401cf133f31\",\"link\":\"https://medium.com/lagierandlagier/2d-web-rendering-with-rust-4401cf133f31\",\"snippet\":\"May 21, 2021 ... Given the performance gap between Rust and native and the ergonomics of using Rust ... Screamin' Speed with WebAssembly. A Tale of Javascript...\",\"title\":\"2D Web Rendering with Rust. I'm playing around with a new project ...\"}]", :with_history=>false}
I, [2025-12-10T12:52:22.763079 #15674]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T12:52:22.763107 #15674]  INFO -- : Use template get_topic
I, [2025-12-10T12:52:22.763345 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:22.763379 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T12:52:23.034504 #15674] ERROR -- : Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
I, [2025-12-10T12:52:23.034644 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:23.034672 #15674]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T12:52:23.106541 #15674]  INFO -- : Calling worker: summary with params: {:text=>"Rust", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T12:52:23.106570 #15674]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T12:52:23.106579 #15674]  INFO -- : Create worker's name is summary
I, [2025-12-10T12:52:23.106589 #15674]  INFO -- : Create Conversation
I, [2025-12-10T12:52:23.106610 #15674]  INFO -- : Use template summarize
I, [2025-12-10T12:52:23.106848 #15674]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:52:23.106874 #15674]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T12:52:38.858660 #15674]  INFO -- : Successful send a message
I, [2025-12-10T12:52:38.858758 #15674]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T12:52:38.858776 #15674]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T12:59:56.543801 #18059]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:59:56.544206 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544252 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544258 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544268 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544272 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544279 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544284 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544308 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544325 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544337 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544343 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544354 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544360 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544374 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544379 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544390 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.544395 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.544405 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.672824 #18059]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:59:56.672889 #18059]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:59:56.673557 #18059]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T12:59:56.673603 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673626 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673632 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673640 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673645 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673652 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673657 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673692 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673702 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673709 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673713 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673719 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673723 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673734 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673739 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673748 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.673783 #18059]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T12:59:56.673800 #18059]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T12:59:56.674057 #18059]  INFO -- : Configuration loaded successfully
I, [2025-12-10T12:59:56.674077 #18059]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T12:59:59.454099 #18059]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Python", :with_history=>true}
I, [2025-12-10T12:59:59.454124 #18059]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T12:59:59.454134 #18059]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T12:59:59.454152 #18059]  INFO -- : Create Conversation
I, [2025-12-10T12:59:59.454193 #18059]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T12:59:59.454487 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T12:59:59.454514 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:00:15.397316 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:15.397395 #18059]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:00:15.397411 #18059]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:00:15.999368 #18059]  INFO -- : Calling worker: pre_search with params: {:text=>"**Python**\n\n---\n\n### **1. **\n\n**Deep Research**  \n- ****  \n  Python****  \n  -   \n  - ****  \n- ****  \n  - Python  \n  - PythonR/Julia  \n  -   \n  - \n\n>  ********\n\n---\n\n### **2. **\n\n|  |  |  |\n|------|------|------|\n| ** vs ** | **** | Scikit-learnTensorFlowPyTorch |\n| **** | **** | 2023TransformerMLflow/DVC**2020**MLOps |\n| **** | **** | NeurIPS/ICML/KDDStanford/MITOReillySpringerAndrej KarpathyFast.ai |\n\n>  ****** +  + ** \n\n---\n\n### **3. **\n\n#### ****\n- Python  \n- Machine Learning  \n- Data Science  \n- Frameworks / Libraries  \n- Best Practices  \n\n#### ****\n|  |  |\n|------|------------|\n| **/** | Scikit-learn, TensorFlow, PyTorch, Keras, XGBoost, LightGBM, Pandas, NumPy, Matplotlib, Seaborn, Plotly, Statsmodels, Jupyter, Dask, Ray |\n| **** | Data preprocessing, Feature engineering, Model evaluation, Hyperparameter tuning, Cross-validation, Model deployment, MLOps, CI/CD for ML, Reproducibility, Version control (DVC, MLflow) |\n| **** | End-to-end pipeline, Model monitoring, A/B testing, Explainable AI (XAI), Fairness in ML, Scalable computing |\n| **** | Tutorial, Guide, Handbook, Whitepaper, Case study, Lecture notes |\n\n#### ****\n```bash\n# \nintitle:\"Python machine learning best practices\" site:tensorflow.org\nintitle:\"data science workflow\" site:scikit-learn.org\n\"PyTorch vs TensorFlow\" comparison site:arxiv.org\n\"ML pipeline best practices\" filetype:pdf\n\n# /\n\"Python for Data Science and Machine Learning\" site:stanford.edu\n\"Hands-On Machine Learning\" site:oreilly.com\n\n# 3\n\"machine learning python 2023\" site:medium.com\n\"modern data science toolkit\" after:2021\n```\n\n#### ****\n- beginner  \n- free download/  \n- how to make money / job  \n- tutorial for kids / easy way  \n\n>  ****** +  +  + **\n\n---\n\n### **4. **\n\n#### ****\n- ****  \n  - `scikit-learn.org/stable/user_guide.html`  \n  - `pytorch.org/tutorials`  \n  - `tensorflow.org/guide`  \n- **/**  \n  - arXiv `\"Python machine learning ecosystem\"` + `2021-2024`  \n  - KDD / NeurIPS tooling, reproducibility, deployment  \n- ****  \n  - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlowAurlien Gron  \n  - MIT OpenCourseWare: Introduction to Computational Thinking and Data Science  \n- **MLOps **  \n  - MLflowDVCWeights & Biases   \n\n#### ****\n- GitHub  `stars:>10k`  `scikit-learn/scikit-learn``fastai/fastai`  \n- Stack Overflow  `python` + `machine-learning` + `best-practices`  \n- LinkedIn  Towards Data Science /  \n\n#### ****\n|  |  |  |\n|--------|------|----------|\n| **** | PyTorch LightningHugging Face Transformers  | 2022GitHub |\n| **** |  vs  |  |\n| **** |  |  |\n| **** |  |  MLOps, reproducible research, experiment tracking |\n\n>  ******MLOps**\n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| 1 | **** `scikit-learn.org`, `pytorch.org`, `tensorflow.org`  best practices, guide, tutorial |\n| 2 | **** arXiv.org  `\"python machine learning best practices\" AND (\"2022\" OR \"2023\" OR \"2024\")` |\n| 3 | **** OReilly / Springer  Python Data Science Handbook  Machine Learning with Python |\n| 4 | **** MLOps Python + DVC + MLflow  |\n| 5 | **** Towards Data Science / Medium /<500 |\n| 6 | **** `site:wikipedia.org``site:blogspot.com``site:quora.com`  |\n\n---\n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:00:15.999489 #18059]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:00:15.999504 #18059]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:00:15.999514 #18059]  INFO -- : Create Conversation
I, [2025-12-10T13:00:15.999543 #18059]  INFO -- : Use template pre_search
I, [2025-12-10T13:00:15.999866 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:15.999897 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:00:19.679395 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:19.679518 #18059]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:00:19.679539 #18059]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:00:21.576290 #18059]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://scikit-learn.org/stable/modules/grid_search.html\",\"link\":\"https://scikit-learn.org/stable/modules/grid_search.html\",\"snippet\":\"Talwalkar, Non-stochastic Best Arm Identification and Hyperparameter Optimization, in proc. of Machine Learning Research, 2016. [2]. L. Li, K. Jamieson, G...\",\"title\":\"3.2. Tuning the hyper-parameters of an estimator  scikit-learn 1.7.2 ...\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/modules/cross_validation.html\",\"link\":\"https://scikit-learn.org/stable/modules/cross_validation.html\",\"snippet\":\"To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test,...\",\"title\":\"3.1. Cross-validation: evaluating estimator performance  scikit ...\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/model_persistence.html\",\"link\":\"https://scikit-learn.org/stable/model_persistence.html\",\"snippet\":\"Summary of model persistence methods:,,, Persistence method, Pros, Risks / Cons,,, ONNX, Serve models without a Python environment, Serving and training...\",\"title\":\"10. Model persistence  scikit-learn 1.7.2 documentation\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/modules/ensemble.html\",\"link\":\"https://scikit-learn.org/stable/modules/ensemble.html\",\"snippet\":\"Machine Learning Applications to Land and Structure Valuation. Journal of ... In practice, a stacking predictor predicts as good as the best predictor...\",\"title\":\"1.11. Ensembles: Gradient boosting, random forests, bagging, voting ...\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/common_pitfalls.html\",\"link\":\"https://scikit-learn.org/stable/common_pitfalls.html\",\"snippet\":\"If these data transforms are used when training a model, they also must be used on subsequent datasets, whether it's test data or data in a production system.\",\"title\":\"11. Common pitfalls and recommended practices  scikit-learn 1.7 ...\"},{\"formattedUrl\":\"http://scikit-learn.org/\",\"link\":\"http://scikit-learn.org/\",\"snippet\":\"Machine Learning in Python  Simple and efficient tools for predictive data analysis  Accessible to everybody, and reusable in various contexts  Built on NumPy,...\",\"title\":\"scikit-learn: machine learning in Python  scikit-learn 1.7.2 ...\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/related_projects.html\",\"link\":\"https://scikit-learn.org/stable/related_projects.html\",\"snippet\":\"... best practices for testing and documenting estimators. The scikit ... Tools for diagnostics and assessment of (machine learning) models (in Python).\",\"title\":\"Related Projects  scikit-learn 1.7.2 documentation\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/modules/preprocessing.html\",\"link\":\"https://scikit-learn.org/stable/modules/preprocessing.html\",\"snippet\":\"Regularized target encoding outperforms traditional methods in supervised machine learning ... better in practice. As for the Normalizer , the utility...\",\"title\":\"7.3. Preprocessing data  scikit-learn 1.7.2 documentation\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/modules/neighbors.html\",\"link\":\"https://scikit-learn.org/stable/modules/neighbors.html\",\"snippet\":\"Neighbors-based methods are known as non-generalizing machine learning methods ... best approach from the training data. For a discussion of the strengths...\",\"title\":\"1.6. Nearest Neighbors  scikit-learn 1.7.2 documentation\"},{\"formattedUrl\":\"https://scikit-learn.org/stable/modules/svm.html\",\"link\":\"https://scikit-learn.org/stable/modules/svm.html\",\"snippet\":\"Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\",\"title\":\"1.4. Support Vector Machines  scikit-learn 1.7.2 documentation\"}]", :with_history=>false}
I, [2025-12-10T13:00:21.576363 #18059]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:00:21.576378 #18059]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:00:21.576395 #18059]  INFO -- : Create Conversation
I, [2025-12-10T13:00:21.576419 #18059]  INFO -- : Use template get_topic
I, [2025-12-10T13:00:21.576681 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:21.576712 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:00:21.802130 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:21.802223 #18059]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:00:21.802255 #18059]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:00:24.014312 #18059]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null},{\"id\":2,\"name\":\"Hyperparameter Optimization\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://www.tensorflow.org/\",\"link\":\"https://www.tensorflow.org/\",\"snippet\":\"An end-to-end open source machine learning platform for everyone. Discover TensorFlow's flexible ecosystem of tools, libraries and community resources.\",\"title\":\"TensorFlow\"},{\"formattedUrl\":\"https://blog.tensorflow.org/.../how-waze-uses-tfx-to-scale-production-ready...\",\"link\":\"https://blog.tensorflow.org/2021/09/how-waze-uses-tfx-to-scale-production-ready-ml.html\",\"snippet\":\"Sep 15, 2021 ... On top, we provided a super detailed walkthrough, usage guides and code templates, to our data scientists, so the common DS workflow is: fork,...\",\"title\":\"How Waze Uses TFX to Scale Production-Ready ML  The ...\"},{\"formattedUrl\":\"https://www.tensorflow.org/tfx/guide/mlmd\",\"link\":\"https://www.tensorflow.org/tfx/guide/mlmd\",\"snippet\":\"Sep 6, 2024 ... ML Metadata (MLMD) is a library for recording and retrieving metadata associated with ML developer and data scientist workflows.\",\"title\":\"ML Metadata | TFX | TensorFlow\"},{\"formattedUrl\":\"https://www.tensorflow.org/guide/tensor\",\"link\":\"https://www.tensorflow.org/guide/tensor\",\"snippet\":\"Aug 15, 2024 ... This section of Jake VanderPlas's book Python Data Science Handbook shows more broadcasting tricks (again in NumPy). tf.convert_to_tensor.\",\"title\":\"Introduction to Tensors | TensorFlow Core\"},{\"formattedUrl\":\"https://blog.tensorflow.org/2022/02/exploreCSR-awards-highlights.html\",\"link\":\"https://blog.tensorflow.org/2022/02/exploreCSR-awards-highlights.html\",\"snippet\":\"Feb 23, 2022 ... ... Python programming with open-source ... Data Science Research, to introduce students to data science and machine learning research.\",\"title\":\"Highlights from TensorFlow's 2021 exploreCSR awards  The ...\"},{\"formattedUrl\":\"https://www.tensorflow.org/learn\",\"link\":\"https://www.tensorflow.org/learn\",\"snippet\":\"An end-to-end platform for machine learning  Prepare and load data for successful ML outcomes  Build and fine-tune models with the TensorFlow ecosystem  Deploy...\",\"title\":\"Introduction to TensorFlow\"},{\"formattedUrl\":\"https://blog.tensorflow.org/.../5-steps-to-go-from-notebook-to-deployed.ht...\",\"link\":\"https://blog.tensorflow.org/2022/05/5-steps-to-go-from-notebook-to-deployed.html\",\"snippet\":\"May 25, 2022 ... Vertex AI contains lots of different products that help you across the entire lifecycle of an ML workflow. ... data science. If you need to add...\",\"title\":\"5 steps to go from a notebook to a deployed model  The ...\"},{\"formattedUrl\":\"https://www.tensorflow.org/guide/data\",\"link\":\"https://www.tensorflow.org/guide/data\",\"snippet\":\"Aug 15, 2024 ... ... Python libraries when parsing your input data. You can use the tf ... tf.data includes a few methods which enable this workflow: Datasets sampling.\",\"title\":\"tf.data: Build TensorFlow input pipelines | TensorFlow Core\"},{\"formattedUrl\":\"https://www.tensorflow.org/guide/data_performance_analysis\",\"link\":\"https://www.tensorflow.org/guide/data_performance_analysis\",\"snippet\":\"Nov 16, 2022 ... Analysis Workflow. 1. Is your tf.data pipeline producing data fast ... Note that the datasets name may differ slightly from the python...\",\"title\":\"Analyze tf.data performance with the TF Profiler | TensorFlow Core\"},{\"formattedUrl\":\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\",\"link\":\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\",\"snippet\":\"Skip to main content. TensorFlow  Install  Learn. More. API. More. Overview  Python  C++  Java  More  Ecosystem. More. Community. More.\",\"title\":\"tf.data.Dataset | TensorFlow v2.16.1\"}]", :with_history=>false}
I, [2025-12-10T13:00:24.014344 #18059]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:00:24.014374 #18059]  INFO -- : Use template get_topic
I, [2025-12-10T13:00:24.014671 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:24.014708 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:00:24.236658 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:24.236727 #18059]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:00:24.236742 #18059]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:00:26.335102 #18059]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":1,\"name\":\"Failed to call LLM after 3 attempts: Unexpected error during OpenAI request: the server responded with status 401 for POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\",\"description\":null},{\"id\":2,\"name\":\"Hyperparameter Optimization\",\"description\":null},{\"id\":3,\"name\":\"Machine Learning Workflow\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://discuss.pytorch.org/t/pytorch-coding-conventions/42548\",\"link\":\"https://discuss.pytorch.org/t/pytorch-coding-conventions/42548\",\"snippet\":\"Apr 14, 2019 ... I am new to PyTorch, and I am looking for some PyTorch Coding Conventions or Best Practices. ... There are probably some good tutorials around\",\"title\":\"Pytorch Coding Conventions - PyTorch Forums\"},{\"formattedUrl\":\"https://docs.pytorch.org/tutorials/index.html\",\"link\":\"https://docs.pytorch.org/tutorials/index.html\",\"snippet\":\"A guide on best practices to copy data from CPU to GPU. Getting Started ... Learn how to copy tutorial data into Google Drive so that you can run tutorials on...\",\"title\":\"Welcome to PyTorch Tutorials  PyTorch Tutorials 2.9.0+cu128 ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/.../pytorch_course_focused_on_best_practices_an...\",\"link\":\"https://www.reddit.com/r/learnmachinelearning/comments/17byhv9/pytorch_course_focused_on_best_practices_and/\",\"snippet\":\"Oct 20, 2023 ... Just do the Pytorch tutorials from the official website ? It's pure coding ... if you say that you understand all the ML theory.... [deleted].\",\"title\":\"PyTorch course focused on best practices and coding - not on ML ...\"},{\"formattedUrl\":\"https://github.com/vahidk/EffectivePyTorch\",\"link\":\"https://github.com/vahidk/EffectivePyTorch\",\"snippet\":\"Numerical stability in PyTorch; Faster training with automatic mixed precision. To install PyTorch follow the instructions on the official website: pip...\",\"title\":\"vahidk/EffectivePyTorch: PyTorch tutorials and best practices. - GitHub\"},{\"formattedUrl\":\"https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html\",\"link\":\"https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html\",\"snippet\":\"Sep 21, 2020 ... Performance Tuning Guide is a set of optimizations and best practices which can accelerate training and inference of deep learning models in PyTorch.\",\"title\":\"Performance Tuning Guide  PyTorch Tutorials 2.9.0+cu128 ...\"},{\"formattedUrl\":\"https://forums.fast.ai/t/getting-comfortable-with-pytorch-projects/28371\",\"link\":\"https://forums.fast.ai/t/getting-comfortable-with-pytorch-projects/28371\",\"snippet\":\"Oct 28, 2018 ... (Edit from Jeremy: this notebook is now available as an official pytorch tutorial!) ... Best pytorch practices. (old vs new); How to...\",\"title\":\"Getting Comfortable with Pytorch \\u0026 Projects - Part 1 (2019) - fast.ai ...\"},{\"formattedUrl\":\"https://imperialcollegelondon.github.io/ReCoDE-DeepLearning-Best-Practic...\",\"link\":\"https://imperialcollegelondon.github.io/ReCoDE-DeepLearning-Best-Practices/\",\"snippet\":\"Pytorch Lightning Tutorial: An official guide to starting a new project with Pytorch Lightning, offering step-by-step instructions and best practices. Hydra...\",\"title\":\"ReCoDE-DeepLearning-Best-Practices\"},{\"formattedUrl\":\"https://pytorch.org/tutorials/intermediate/pinmem_nonblock.html\",\"link\":\"https://pytorch.org/tutorials/intermediate/pinmem_nonblock.html\",\"snippet\":\"Jul 31, 2024 ... This tutorial examines two key methods for device-to-device data transfer in PyTorch: pin_memory() and to() with the non_blocking=True option.\",\"title\":\"A guide on good usage of non_blocking and pin_memory() in PyTorch\"},{\"formattedUrl\":\"https://medium.com/.../a-comprehensive-tutorial-to-pytorch-distributeddata...\",\"link\":\"https://medium.com/codex/a-comprehensive-tutorial-to-pytorch-distributeddataparallel-1f4b42bb1b51\",\"snippet\":\"Aug 15, 2021 ... After addressing so many bugs I came across, I've come up with the best practice so far. ... official blog). This blog is organized as...\",\"title\":\"A Comprehensive Tutorial to Pytorch DistributedDataParallel | by ...\"},{\"formattedUrl\":\"https://sebastianraschka.com/teaching/pytorch-1h/\",\"link\":\"https://sebastianraschka.com/teaching/pytorch-1h/\",\"snippet\":\"PyTorch's official website (https://pytorch.org) provides commands to ... best practice when sharing PyTorch code: device = torch.device(\\\"cuda\\\" if...\",\"title\":\"PyTorch in One Hour: From Tensors to Training Neural Networks on ...\"}]", :with_history=>false}
I, [2025-12-10T13:00:26.335152 #18059]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:00:26.335178 #18059]  INFO -- : Use template get_topic
I, [2025-12-10T13:00:26.335404 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:26.335430 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:00:26.571713 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:26.571789 #18059]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:00:26.571806 #18059]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:00:27.848567 #18059]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:00:27.848592 #18059]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:00:27.848602 #18059]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:00:27.848612 #18059]  INFO -- : Create Conversation
I, [2025-12-10T13:00:27.848635 #18059]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:00:27.848906 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:27.848935 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T13:00:31.294289 #18059] ERROR -- : Unexpected error during OpenAI request: the server responded with status 400 for POST http://120.133.75.248:39095/v1/chat/completions
I, [2025-12-10T13:00:31.294388 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:31.294412 #18059]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:00:31.896737 #18059]  INFO -- : Calling worker: smart_search with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:00:31.896846 #18059]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:00:31.896861 #18059]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:00:31.896871 #18059]  INFO -- : Create Conversation
I, [2025-12-10T13:00:31.896896 #18059]  INFO -- : Use template smart_search
I, [2025-12-10T13:00:31.897153 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:31.897181 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T13:00:35.375376 #18059] ERROR -- : Unexpected error during OpenAI request: the server responded with status 400 for POST http://120.133.75.248:39095/v1/chat/completions
I, [2025-12-10T13:00:35.375540 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:35.375587 #18059]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:00:35.376001 #18059]  INFO -- : Calling worker: summary with params: {:text=>"Python", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:00:35.376025 #18059]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:00:35.376034 #18059]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:00:35.376043 #18059]  INFO -- : Create Conversation
I, [2025-12-10T13:00:35.376062 #18059]  INFO -- : Use template summarize
I, [2025-12-10T13:00:35.376290 #18059]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:00:35.376313 #18059]  INFO -- : OpenAIAdapter: Using model qwen3-next
E, [2025-12-10T13:00:38.924969 #18059] ERROR -- : Unexpected error during OpenAI request: the server responded with status 400 for POST http://120.133.75.248:39095/v1/chat/completions
I, [2025-12-10T13:00:38.925088 #18059]  INFO -- : Successful send a message
I, [2025-12-10T13:00:38.925111 #18059]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:04:28.475945 #19591]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:28.476021 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476058 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476064 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476073 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476078 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476085 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476089 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476113 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476118 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476125 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476130 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476136 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476140 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476151 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476156 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476168 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.476172 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.476186 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611186 #19591]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:28.611250 #19591]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:28.611836 #19591]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:28.611880 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.611905 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611911 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.611918 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611923 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.611930 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611935 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.611958 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611963 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.611971 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611975 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.611982 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.611986 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.612002 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.612007 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.612018 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.612023 #19591]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:28.612035 #19591]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:28.612272 #19591]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:28.612301 #19591]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:41.082300 #19689]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:41.082399 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082443 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082449 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082458 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082462 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082468 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082472 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082499 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082504 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082511 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082515 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082521 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082525 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082535 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082539 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082548 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.082552 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.082562 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.148589 #19689]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:41.148654 #19689]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:41.148991 #19689]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:41.149028 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149048 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149053 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149060 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149064 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149070 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149074 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149108 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149124 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149137 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149142 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149150 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149155 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149172 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149176 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149186 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149190 #19689]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:41.149199 #19689]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:41.149442 #19689]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:41.149467 #19689]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:49.483940 #19772]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:49.484013 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484043 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484049 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484057 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484068 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484079 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484083 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484105 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484109 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484115 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484119 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484124 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484128 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484138 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484142 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484151 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.484155 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.484164 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.550630 #19772]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:49.550694 #19772]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:49.551242 #19772]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:49.551281 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551301 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551306 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551312 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551316 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551322 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551326 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551345 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551350 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551359 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551363 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551369 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551373 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551383 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551387 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551396 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551400 #19772]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:49.551410 #19772]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:49.551633 #19772]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:49.551655 #19772]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:58.599317 #19874]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:58.599394 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599427 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599433 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599441 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599445 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599452 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599455 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599477 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599491 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599497 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599501 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599507 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599511 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599521 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599526 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599535 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.599538 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.599550 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677147 #19874]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:58.677215 #19874]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:04:58.677732 #19874]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:04:58.677778 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677799 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677804 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677810 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677814 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677820 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677824 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677844 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677849 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677856 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677859 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677865 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677869 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677879 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677883 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677892 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.677896 #19874]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:04:58.677905 #19874]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:04:58.678131 #19874]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:04:58.678154 #19874]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:05:01.110508 #19874]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Python", :lang=>""}
I, [2025-12-10T13:05:01.110552 #19874]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T13:05:01.110564 #19874]  INFO -- : Create worker's name is get_tags
I, [2025-12-10T13:05:01.110578 #19874]  INFO -- : Create Conversation
I, [2025-12-10T13:05:01.110601 #19874]  INFO -- : Use template get_tags
I, [2025-12-10T13:05:01.110952 #19874]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:05:01.110985 #19874]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:05:01.668911 #19874]  INFO -- : Successful send a message
I, [2025-12-10T13:05:01.668980 #19874]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:05:01.669000 #19874]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T13:05:01.669033 #19874]  INFO -- : Calling worker: get_embedding with params: {:text=>"python,,,scikit-learn,tensorflow", :length=>1024}
I, [2025-12-10T13:05:01.669048 #19874]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T13:05:01.669053 #19874]  INFO -- : Create worker's name is get_embedding
I, [2025-12-10T13:05:01.669060 #19874]  INFO -- : Create Conversation
I, [2025-12-10T13:05:01.669127 #19874]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T13:05:01.669151 #19874]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T13:05:01.744681 #19874] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T13:05:01.744763 #19874]  INFO -- : Successful send a message
E, [2025-12-10T13:05:01.744784 #19874] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T13:05:01.744906 #19874] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T13:05:01.745008 #19874]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Python", :lang=>""}
I, [2025-12-10T13:05:01.745018 #19874]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T13:05:01.745038 #19874]  INFO -- : Use template get_tags
I, [2025-12-10T13:05:01.745498 #19874]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:05:01.745538 #19874]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:05:02.287684 #19874]  INFO -- : Successful send a message
I, [2025-12-10T13:05:02.287763 #19874]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:05:02.287781 #19874]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T13:05:02.287834 #19874]  INFO -- : Calling worker: get_embedding with params: {:text=>"python,,,scikit-learn,tensorflow", :length=>1024}
I, [2025-12-10T13:05:02.287843 #19874]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T13:05:02.287917 #19874]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T13:05:02.287935 #19874]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T13:05:02.374467 #19874] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T13:05:02.374555 #19874]  INFO -- : Successful send a message
E, [2025-12-10T13:05:02.374579 #19874] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T13:05:02.374618 #19874] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T13:05:02.374707 #19874]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Python", :lang=>""}
I, [2025-12-10T13:05:02.374732 #19874]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T13:05:02.374755 #19874]  INFO -- : Use template get_tags
I, [2025-12-10T13:05:02.375082 #19874]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:05:02.375124 #19874]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:05:02.911651 #19874]  INFO -- : Successful send a message
I, [2025-12-10T13:05:02.911721 #19874]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:05:02.911739 #19874]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T13:05:02.911764 #19874]  INFO -- : Calling worker: get_embedding with params: {:text=>"python,machine learning,framework,scikit-learn,tensorflow", :length=>1024}
I, [2025-12-10T13:05:02.911770 #19874]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T13:05:02.911835 #19874]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T13:05:02.911855 #19874]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T13:05:02.996338 #19874] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T13:05:02.996416 #19874]  INFO -- : Successful send a message
E, [2025-12-10T13:05:02.996435 #19874] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T13:05:02.996459 #19874] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T13:05:02.996489 #19874]  INFO -- : Calling worker: get_tags with params: {:topic=>"", :text=>"Python", :lang=>""}
I, [2025-12-10T13:05:02.996495 #19874]  INFO -- : Creating worker instance for: get_tags
I, [2025-12-10T13:05:02.996512 #19874]  INFO -- : Use template get_tags
I, [2025-12-10T13:05:02.996840 #19874]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:05:02.996872 #19874]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:05:03.576274 #19874]  INFO -- : Successful send a message
I, [2025-12-10T13:05:03.576357 #19874]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:05:03.576376 #19874]  INFO -- : Worker get_tags executed successfully
I, [2025-12-10T13:05:03.576430 #19874]  INFO -- : Calling worker: get_embedding with params: {:text=>"python,,,scikit-learn,tensorflow", :length=>1024}
I, [2025-12-10T13:05:03.576437 #19874]  INFO -- : Creating worker instance for: get_embedding
I, [2025-12-10T13:05:03.576509 #19874]  INFO -- : OpenAIAdapter: get embeddings from Ollama
I, [2025-12-10T13:05:03.576532 #19874]  INFO -- : OpenAIAdapter: Using model Qwen/Qwen3-Embedding-0.6B
E, [2025-12-10T13:05:03.652828 #19874] ERROR -- : Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
I, [2025-12-10T13:05:03.652925 #19874]  INFO -- : Successful send a message
E, [2025-12-10T13:05:03.652943 #19874] ERROR -- : Error executing worker get_embedding: Unexpected error during Ollama request: the server responded with status 401 for POST http://120.133.75.248:39095/v1/embeddings
D, [2025-12-10T13:05:03.652967 #19874] DEBUG -- : /home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:95:in `rescue in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/openai_adapter.rb:93:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:128:in `block in embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:61:in `block in retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `times'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/retriable-3.1.2/lib/retriable.rb:56:in `retriable'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/conversation.rb:120:in `embeddings'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:57:in `method_missing'
/home/nix/SmartResearch/agents/workers/get_embedding.rb:5:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/worker.rb:16:in `execute'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_prompt-0.3.0/lib/smart_prompt/engine.rb:78:in `call_worker'
/home/nix/SmartResearch/lib/models/query_processor.rb:43:in `text_to_vector'
/home/nix/SmartResearch/lib/models/query_processor.rb:19:in `block in process_query'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `each'
/home/nix/SmartResearch/lib/models/query_processor.rb:17:in `process_query'
/home/nix/SmartResearch/agents/smart_writer.rb:2:in `find_new_contents'
/home/nix/SmartResearch/agents/smart_kb.rb:319:in `block in <top (required)>'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `instance_eval'
/home/nix/SmartResearch/vendor/bundle/ruby/3.2.0/gems/smart_agent-0.2.2/lib/smart_agent/agent.rb:53:in `please'
/home/nix/SmartResearch/lib/smart_research_cli/application.rb:92:in `call_agent'
/home/nix/SmartResearch/lib/smart_research_cli.rb:37:in `start'
/home/nix/SmartResearch/bin/smart_research_cli:5:in `<top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:58:in `kernel_load'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli/exec.rb:23:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:492:in `exec'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:34:in `dispatch'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/cli.rb:28:in `start'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:37:in `block in <top (required)>'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/lib/bundler/friendly_errors.rb:117:in `with_friendly_errors'
/usr/share/rubygems-integration/all/gems/bundler-2.4.20/exe/bundle:29:in `<top (required)>'
/usr/bin/bundle:25:in `load'
/usr/bin/bundle:25:in `<main>'
I, [2025-12-10T13:05:03.653087 #19874]  INFO -- : Calling worker: summary with params: {:text=>"Python\n[]", :tools=>[], :with_history=>false}
I, [2025-12-10T13:05:03.653093 #19874]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:05:03.653098 #19874]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:05:03.653108 #19874]  INFO -- : Create Conversation
I, [2025-12-10T13:05:03.653132 #19874]  INFO -- : Use template summarize
I, [2025-12-10T13:05:03.653378 #19874]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:05:03.653404 #19874]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:05:16.520825 #19874]  INFO -- : Successful send a message
I, [2025-12-10T13:05:16.520901 #19874]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:05:16.520922 #19874]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:07:11.119536 #20528]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:07:11.119632 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119666 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119673 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119681 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119686 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119692 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119697 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119721 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119726 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119733 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119737 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119743 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119748 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119759 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119763 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119772 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.119777 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.119786 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.253605 #20528]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:07:11.253664 #20528]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:07:11.254344 #20528]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:07:11.254421 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254459 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254465 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254473 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254479 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254486 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254502 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254532 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254550 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254563 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254569 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254576 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254580 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254595 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254600 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254612 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254616 #20528]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:07:11.254627 #20528]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:07:11.254946 #20528]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:07:11.254975 #20528]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:07:14.018746 #20528]  INFO -- : Calling worker: download_page with params: {:url=>"https://scikit-learn.org/stable/modules/grid_search.html", :tools=>[], :with_history=>false}
I, [2025-12-10T13:07:14.018755 #20528]  INFO -- : Creating worker instance for: download_page
I, [2025-12-10T13:07:14.018764 #20528]  INFO -- : Create worker's name is download_page
I, [2025-12-10T13:07:14.018778 #20528]  INFO -- : Create Conversation
I, [2025-12-10T13:07:14.984373 #20528]  INFO -- : Worker download_page executed(stream) successfully
I, [2025-12-10T13:12:14.293089 #21610]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:12:14.293169 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293205 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293211 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293220 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293225 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293232 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293236 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293264 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293271 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293278 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293283 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293289 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293294 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293305 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293310 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293320 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.293324 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.293334 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.364519 #21610]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:12:14.364617 #21610]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:12:14.365129 #21610]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:12:14.365168 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365189 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365198 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365205 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365230 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365244 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365248 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365270 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365275 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365285 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365289 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365294 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365298 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365320 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365334 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365532 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365561 #21610]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:12:14.365585 #21610]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:12:14.365856 #21610]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:12:14.365881 #21610]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:12:32.120955 #21610]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>" Rust ", :with_history=>true}
I, [2025-12-10T13:12:32.120969 #21610]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:12:32.120982 #21610]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:12:32.120995 #21610]  INFO -- : Create Conversation
I, [2025-12-10T13:12:32.121026 #21610]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:12:32.121317 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:32.121343 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:12:45.167875 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:12:45.167945 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:12:45.167961 #21610]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:12:45.770295 #21610]  INFO -- : Calling worker: pre_search with params: {:text=>" Rust \n\n---\n\n### **1. **  \n** + **  \n\n- **** Rust ****  \n- ****Rust   \n- **** C/C++/Go   \n- **/** Rust \n\n>  ********\n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | ****Rust  |\n| **** | ****Rust  6  async/awaitconst genericsproc macros  2021 Edition  |\n| **** | ****rust-lang.orgRust BookRFC  Graydon HoareSteve Klabnik |\n\n>  ****** +  + **\n\n---\n\n### **3. **  \n\n#### ****  \n- `Rust programming language features`  \n- `Rust language characteristics`  \n- `Rust ownership model`  \n- `Rust memory safety`  \n- `Rust zero-cost abstractions`  \n\n#### ****  \n- `borrow checker`, `move semantics`, `trait system`, `pattern matching`, `cargo package manager`, `Rust edition 2021`, `no std`, `fearless concurrency`  \n\n#### ****  \n```plaintext\nintitle:\"Rust\" (\"features\" OR \"characteristics\")  \nsite:rust-lang.org \"The Rust Programming Language\"  \nsite:doc.rust-lang.org \"ownership\"  \nfiletype:pdf \"Rust language design\"  \n\"Rust\" (\"memory safety\" OR \"concurrency\") -forum -reddit -quora  \n```\n\n>  ****  \n> `intitle:\"Rust features\" site:rust-lang.org`  \n> `\"Rust ownership model\" site:doc.rust-lang.org`  \n> `\"Rust zero-cost abstractions\" filetype:pdf`\n\n#### ****  \n- `-forum -reddit -quora -stackoverflow`  \n- `-job -salary -tutorial`  \n- `-beginner -for dummies`\n\n---\n\n### **4. **  \n\n#### ****  \n- ****The Rust Programming LanguageRust Book  \n- **Rust **https://www.rust-lang.org/learn/get-started  \n- **RFC **Rust  RFC 0000, RFC 2000+  \n- **/**Steve Klabnik, Graydon Hoare, Rachel McAnally   \n- **** Rust: Safe, Fast, ConcurrentACM  IEEE   \n\n#### ****  \n- ****Ars TechnicaHacker News Medium  Rust   \n- **** TokioActixWASM-bindgen  Rust   \n- **Rust **https://blog.rust-lang.org/  \n\n#### ****  \n|  |  |  |\n|------|------|----------|\n| **** |  Cargocrates.io  | / `language feature` |\n| **** |  20182020  Rust `fn main() { ... }`  `?` |  2021+  Rust 2021 Edition |\n| **** |  |  `site:doc.rust-lang.org`  |\n| **** | Rust  |  Rust tradeoffs  Rust drawbacks  |\n\n---\n\n###  ****  \n1. **** [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/) 13413 OwnershipBorrowingConcurrency  \n2. **** [https://www.rust-lang.org/learn](https://www.rust-lang.org/learn)   \n3. **** `site:rust-lang.org \"features\"` + `site:doc.rust-lang.org \"zero-cost\"`   \n4. **** Google Scholar  `\"Rust language design\" 2023..2024`   \n\n>  ****Rust  Rust\n\n--- \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:12:45.770488 #21610]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:12:45.770510 #21610]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:12:45.770527 #21610]  INFO -- : Create Conversation
I, [2025-12-10T13:12:45.770562 #21610]  INFO -- : Use template pre_search
I, [2025-12-10T13:12:45.770945 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:45.770983 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:12:47.737738 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:12:47.737836 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:12:47.737851 #21610]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:12:50.451921 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/\",\"link\":\"https://doc.rust-lang.org/book/\",\"snippet\":\"The Rust Programming Language by Steve Klabnik, Carol Nichols, and Chris Krycho, with contributions from the Rust Community\",\"title\":\"The Rust Programming Language\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/hide-experimental-features-in-std-docs/99886\",\"link\":\"https://users.rust-lang.org/t/hide-experimental-features-in-std-docs/99886\",\"snippet\":\"Sep 14, 2023 ... Is there any \\\"official\\\" way to do so? I'm aware of this forum post, some time has passed since then and maybe there's some better way to...\",\"title\":\"Hide experimental features in std docs - The Rust Programming ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../types_and_selfdocumenting_code_in_rust/\",\"link\":\"https://www.reddit.com/r/rust/comments/1d2qns1/types_and_selfdocumenting_code_in_rust/\",\"snippet\":\"May 28, 2024 ... The convention is documented in https://rust-lang.github.io/api-guidelines/naming.html#c-iter-ty Iterator is marked as a \\\"Notable Trait\\\",...\",\"title\":\"Types and self-documenting code in Rust : r/rust\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/how-to-document-optional-features.../64577\",\"link\":\"https://users.rust-lang.org/t/how-to-document-optional-features-in-api-docs/64577\",\"snippet\":\"Sep 9, 2021 ... The Rust Programming Language Forum  How to document optional ... We can use this to conditionally enable nightly features when building...\",\"title\":\"How to document optional features in API docs - help - The Rust ...\"},{\"formattedUrl\":\"https://github.com/rust-lang/reference/issues/788\",\"link\":\"https://github.com/rust-lang/reference/issues/788\",\"snippet\":\"Apr 4, 2020 ... I think reborrowing is an important enough topic to get covered in some official documentation, and if not the book, then the reference should expand upon this...\",\"title\":\"better documentation of reborrowing  Issue #788  rust-lang/reference\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/documentation-of-types...problem/53274\",\"link\":\"https://users.rust-lang.org/t/documentation-of-types-discoverability-problem/53274\",\"snippet\":\"Dec 26, 2020 ... The Rust Programming Language Forum  Documentation of types ... feature prominently in the documentation. 3 Likes. Hyeonu December 28...\",\"title\":\"Documentation of types, discoverability problem - The Rust ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../what_is_the_next_big_thing_coming_to_...\",\"link\":\"https://www.reddit.com/r/rust/comments/ze2foc/what_is_the_next_big_thing_coming_to_rust/\",\"snippet\":\"Dec 6, 2022 ... ... official documentation (eg. why does docs.rust-lang.org show me nightly stuff at all unless I specifically ask for the nightly documentation?!)\",\"title\":\"What is the next big thing coming to Rust : r/rust\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/learning-rust...official...documentation/1579...\",\"link\":\"https://internals.rust-lang.org/t/learning-rust-with-official-books-documentation/15794\",\"snippet\":\"Dec 15, 2021 ... ... Rust Programming Language + Rust by Example I think both are not suit ... This version will have the most important and widely used features of...\",\"title\":\"Learning Rust with Official Books \\u0026 Documentation - documentation ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../why_do_rust_crates_rarely_have_good_d...\",\"link\":\"https://www.reddit.com/r/rust/comments/saxk20/why_do_rust_crates_rarely_have_good_documentation/\",\"snippet\":\"Jan 23, 2022 ... Doesn't Rust have incredible documentation features? I just don ... The Rust Programming Language. A place for all things related to the...\",\"title\":\"Why do Rust crates rarely have good documentation? : r/rust\"},{\"formattedUrl\":\"https://discourse.julialang.org/t/the-challenges-of-documenting.../103198\",\"link\":\"https://discourse.julialang.org/t/the-challenges-of-documenting-generic-functions/103198\",\"snippet\":\"Aug 24, 2023 ... Julia Programming Language  The challenges of documenting generic ... official documentation of color schemes: https://docs.juliaplots...\",\"title\":\"The challenges of documenting generic functions - General Usage ...\"}]", :with_history=>false}
I, [2025-12-10T13:12:50.451959 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:12:50.451967 #21610]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:12:50.451981 #21610]  INFO -- : Create Conversation
I, [2025-12-10T13:12:50.452003 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:12:50.452298 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:50.452331 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:12:50.711983 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:12:50.712059 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:12:50.712081 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:12:52.942888 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/\",\"link\":\"https://doc.rust-lang.org/book/\",\"snippet\":\"The Rust Programming Language by Steve Klabnik, Carol Nichols, and Chris Krycho, with contributions from the Rust Community\",\"title\":\"The Rust Programming Language\"},{\"formattedUrl\":\"https://rust-lang.org/learn/\",\"link\":\"https://rust-lang.org/learn/\",\"snippet\":\"Affectionately nicknamed the book, The Rust Programming Language will give you an overview of the language from first principles. You'll build a few...\",\"title\":\"Learn Rust - Rust Programming Language\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/why-and-why-not-rust/98354\",\"link\":\"https://users.rust-lang.org/t/why-and-why-not-rust/98354\",\"snippet\":\"Aug 13, 2023 ... The Rust Programming Language Forum  Why and Why not Rust? OceanWithoutWater August 13, 2023, 12:47am 1. What can I do with Rust? Who is the...\",\"title\":\"Why and Why not Rust? - The Rust Programming Language Forum\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/for...the-rust-programming-language.../18575\",\"link\":\"https://users.rust-lang.org/t/for-a-beginner-the-rust-programming-language-or-the-programming-rust-book/18575\",\"snippet\":\"Jul 6, 2018 ... Hey, I'm quite new to the rust programming language and want to learn it fully. For that, I've found 2 interesting-looking books on Amazon:...\",\"title\":\"For a beginner: The Rust Programming Language or the ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/using-ai-to-generate-rust-code/128758\",\"link\":\"https://users.rust-lang.org/t/using-ai-to-generate-rust-code/128758\",\"snippet\":\"The Rust Programming Language Forum  Using AI to generate Rust code  curoli April 24, 2025, 2:19pm 1. Hello,. I'm looking for advice and to hear about...\",\"title\":\"Using AI to generate Rust code - The Rust Programming Language ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/feedback-requested-the-rust-book.../93043\",\"link\":\"https://users.rust-lang.org/t/feedback-requested-the-rust-book-abridged/93043\",\"snippet\":\"The Rust Programming Language Forum  Feedback Requested: The Rust Book Abridged  tutorials  jwalton April 24, 2023, 11:42pm 1. Hey all! I'm new to the...\",\"title\":\"Feedback Requested: The Rust Book Abridged - tutorials - The Rust ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/feedback-on-rust-programming...std/133505\",\"link\":\"https://users.rust-lang.org/t/feedback-on-rust-programming-language-std/133505\",\"snippet\":\"The Rust Programming Language Forum  Feedback on Rust Programming Language / std  manuel August 29, 2025, 11:31pm 1. I am sorry when something is...\",\"title\":\"Feedback on Rust Programming Language / std - The Rust ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/what-is-rust-who-owns-rust/68864\",\"link\":\"https://users.rust-lang.org/t/what-is-rust-who-owns-rust/68864\",\"snippet\":\"The Rust Programming Language Forum  What is Rust / Who owns Rust? help  jbe December 15, 2021, 3:58pm 1. After some worrying posts about some parts of...\",\"title\":\"What is Rust / Who owns Rust? - help - The Rust Programming ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch00-00-introduction.html\",\"link\":\"https://doc.rust-lang.org/book/ch00-00-introduction.html\",\"snippet\":\"Welcome to The Rust Programming Language, an introductory book about Rust. The Rust programming language helps you write faster, more reliable software.\",\"title\":\"Introduction - The Rust Programming Language\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/the-best-approach-to-learning-rust/14034\",\"link\":\"https://users.rust-lang.org/t/the-best-approach-to-learning-rust/14034\",\"snippet\":\"Nov 24, 2017 ... The book, in particular, is this one: The Rust Programming Language - The Rust Programming Language. 1 Like. jonny7 November 24, 2017, 2:15pm...\",\"title\":\"The best approach to learning Rust - help - The Rust Programming ...\"}]", :with_history=>false}
I, [2025-12-10T13:12:52.942970 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:12:52.943007 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:12:52.943281 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:52.943309 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:12:53.201524 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:12:53.201588 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:12:53.201605 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:12:54.908468 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:12:54.908490 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:12:54.908517 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:12:54.908748 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:54.908779 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:12:55.170728 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:12:55.170837 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:12:55.170859 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:12:56.976759 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://stackoverflow.com/questions/.../what-does-zero-cost-abstraction-mea...\",\"link\":\"https://stackoverflow.com/questions/69178380/what-does-zero-cost-abstraction-mean\",\"snippet\":\"Sep 14, 2021 ... Zero Cost Abstractions means adding higher-level programming concepts, like generics, collections and so on do not come with a run-time cost...\",\"title\":\"rust - What does 'Zero Cost Abstraction' mean? - Stack Overflow\"},{\"formattedUrl\":\"https://doc.rust-lang.org/beta/embedded-book/.../zero-cost-abstractions.html\",\"link\":\"https://doc.rust-lang.org/beta/embedded-book/static-guarantees/zero-cost-abstractions.html\",\"snippet\":\"Structures defined like this are called Zero Sized Types, as they contain no actual data. Although these types act \\\"real\\\" at compile time - you can copy them,...\",\"title\":\"Zero Cost Abstractions - The Embedded Rust Book\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/how-to-understand-zero-cost...for-rust/9761\",\"link\":\"https://users.rust-lang.org/t/how-to-understand-zero-cost-abstraction-for-rust/9761\",\"snippet\":\"Mar 3, 2017 ... The most notable difference is that Rust can track memory using lifetimes (zero cost at runtime) instead of reference counting or GC. In C++ you...\",\"title\":\"How to understand zero cost abstraction for Rust - tutorials - The ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../what_specifically_are_all_the_zerocost/\",\"link\":\"https://www.reddit.com/r/rust/comments/bo13qq/what_specifically_are_all_the_zerocost/\",\"snippet\":\"May 13, 2019 ... Report. What specifically are all the zero-cost abstractions in Rust? So we all know that Rust is great, and one of the reasons it's so great...\",\"title\":\"What specifically are all the zero-cost abstractions in Rust? : r/rust\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/rust-has-zero-cost-abstraction...a.../100556\",\"link\":\"https://users.rust-lang.org/t/rust-has-zero-cost-abstraction-what-does-this-mean-in-a-practical-sense/100556\",\"snippet\":\"Sep 29, 2023 ... Rust's zero-cost abstraction are meant to mean that you can use higher-level abstractions, and still get the same performance as if you wrote lower-level code...\",\"title\":\"Rust has zero cost abstraction.What does this mean in a practical ...\"},{\"formattedUrl\":\"https://without.boats/blog/zero-cost-abstractions/\",\"link\":\"https://without.boats/blog/zero-cost-abstractions/\",\"snippet\":\"May 16, 2019 ... The idea of a zero cost abstraction is very important to certain programming languages, like Rust and C++, which intend to enable users to write programs with...\",\"title\":\"Zero Cost Abstractions\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../what_languages_other_than_rust_have_z...\",\"link\":\"https://www.reddit.com/r/rust/comments/zkr3xm/what_languages_other_than_rust_have_zero_cost/\",\"snippet\":\"Dec 13, 2022 ... Rust's (and C++'s) zero cost abstractions relies on (at least) these optimizations: Monomorphization: a special version of a generic function or...\",\"title\":\"What languages (other than Rust) have \\\"zero cost abstraction\\\"? : r/rust\"},{\"formattedUrl\":\"https://ranveersequeira.medium.com/learning-rust-understanding-zero-cost-...\",\"link\":\"https://ranveersequeira.medium.com/learning-rust-understanding-zero-cost-abstraction-with-filter-and-map-e967d09fff79\",\"snippet\":\"May 23, 2023 ... Learning Rust: Understanding Zero-Cost Abstraction with Filter and Map Introduction: As a programming language enthusiast, I've recently...\",\"title\":\"Learning Rust: Understanding Zero-Cost Abstraction with Filter and ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../when_zero_cost_abstractions_arent_zero_...\",\"link\":\"https://www.reddit.com/r/rust/comments/p0ul6b/when_zero_cost_abstractions_arent_zero_cost/\",\"snippet\":\"Aug 9, 2021 ... The explanation in the article is slightly off. The Rust code may ... formal Platonic perspective, obviously the newtype is just a...\",\"title\":\"When Zero Cost Abstractions Aren't Zero Cost : r/rust\"},{\"formattedUrl\":\"https://deepu.tech/my-second-impression-of-rust/\",\"link\":\"https://deepu.tech/my-second-impression-of-rust/\",\"snippet\":\"May 7, 2021 ... This static compile-time analysis eliminates many types of memory ... zero-cost abstractions in Rust. But once you step into advanced...\",\"title\":\"My second impression of Rust and why I think it's a great general ...\"}]", :with_history=>false}
I, [2025-12-10T13:12:56.976790 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:12:56.976811 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:12:56.977028 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:56.977058 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:12:57.238121 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:12:57.238192 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:12:57.238210 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:12:59.798090 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://users.rust-lang.org/t/why-crates-for-rust-2015-are-still.../92361\",\"link\":\"https://users.rust-lang.org/t/why-crates-for-rust-2015-are-still-around/92361\",\"snippet\":\"Apr 11, 2023 ... ... edition=2021 main.rs instead of rustc main.rs . ... warning: language edition not specified | = note: editions control which language features...\",\"title\":\"Why crates for Rust 2015 are still around? - The Rust Programming ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/comments/.../should_i_bump_to_2021_editio...\",\"link\":\"https://www.reddit.com/r/rust/comments/qmph74/should_i_bump_to_2021_edition/\",\"snippet\":\"Nov 4, 2021 ... The main effect on users is that your crate will no longer compile with Rust 1.55 or earlier. For this reason, I suggest waiting at least a little while before...\",\"title\":\"Should I bump to 2021 edition? : r/rust\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/no-alloc-attribute-in-2021-edition/13596\",\"link\":\"https://internals.rust-lang.org/t/no-alloc-attribute-in-2021-edition/13596\",\"snippet\":\"Dec 15, 2020 ... ] edition = \\\"2021\\\" # See more keys and their definitions at https ... features would also be moved out of lib/main.rs : [package] name...\",\"title\":\"`#![no_alloc]` attribute in 2021 edition? - language design - Rust ...\"},{\"formattedUrl\":\"https://news.ycombinator.com/item?id=42780192\",\"link\":\"https://news.ycombinator.com/item?id=42780192\",\"snippet\":\"The key part is that editions are configured per-library - libraries A and B might use editions 2015 and 2021, and your application could use edition 2018 and...\",\"title\":\"No. The point of rust editions is that they do break support for older ...\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/what-is-rusts-release-cycle/15113\",\"link\":\"https://internals.rust-lang.org/t/what-is-rusts-release-cycle/15113\",\"snippet\":\"Jul 31, 2021 ... Some key bits of the documentation weren't fully fleshed out until well after the edition release. Many people have remarked on the Rust 2021...\",\"title\":\"What is Rusts release cycle? - language design - Rust Internals\"},{\"formattedUrl\":\"https://codeandbitters.com/rust-2024-upgrade/\",\"link\":\"https://codeandbitters.com/rust-2024-upgrade/\",\"snippet\":\"Feb 6, 2025 ... ... language features give us new abilities and new lints help us find latent bugs. Should we migrate by language change, or by crate? Or both...\",\"title\":\"updating a large codebase to Rust 2024 edition\"},{\"formattedUrl\":\"https://nostarch.com/rust-programming-language-2nd-edition\",\"link\":\"https://nostarch.com/rust-programming-language-2nd-edition\",\"snippet\":\"The Rust Programming Language, 2nd Edition is the official guide to Rust 2021 ... Rust is a language that rewards a deep understanding of its features...\",\"title\":\"The Rust Programming Language, 2nd Edition | No Starch Press\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/appendix-05-editions.html\",\"link\":\"https://doc.rust-lang.org/book/appendix-05-editions.html\",\"snippet\":\"Each edition brings together the features that have landed into a clear package with fully updated documentation and tooling.\",\"title\":\"E - Editions - The Rust Programming Language\"},{\"formattedUrl\":\"https://blog.rust-lang.org/\",\"link\":\"https://blog.rust-lang.org/\",\"snippet\":\"A tale of broken badges and 23,000 features. Oct. 19, Announcing the New Rust Project Directors ... Six Years of Rust. May 11, The Plan for the Rust 2021 Edition.\",\"title\":\"The Rust Programming Language Blog\"},{\"formattedUrl\":\"https://medium.com/.../key-remapping-in-linux-2021-edition-47320999d2...\",\"link\":\"https://medium.com/@canadaduane/key-remapping-in-linux-2021-edition-47320999d2aa\",\"snippet\":\"Nov 18, 2021 ... Wayland's missing features are ... In addition, Hawck allows you to write scripts in a Lua-derived language for full-power customization.\",\"title\":\"Key Remapping in Linux  2021 Edition | by Duane Johnson ...\"}]", :with_history=>false}
I, [2025-12-10T13:12:59.798119 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:12:59.798140 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:12:59.798377 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:12:59.798403 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:00.065131 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:00.065200 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:00.065217 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:00.136285 #21610]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:13:00.136319 #21610]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:13:00.136328 #21610]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:13:00.136337 #21610]  INFO -- : Create Conversation
I, [2025-12-10T13:13:00.136355 #21610]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:13:00.136596 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:00.136620 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:08.373715 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:08.373823 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:08.373842 #21610]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:13:08.976273 #21610]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1: \n  - []  Rust The Rust Programming LanguageOwnershipBorrowingTraitsConcurrency`site:doc.rust-lang.org/book \"ownership\" \"borrowing\" \"traits\" \"concurrency\"`\n  - []  Rust 2021 Edition `site:doc.rust-lang.org/book/appendix-05-editions.html \"Rust 2021 edition\" \"new features\"`\n  - []  Rust Zero-Cost Abstractions`site:blog.rust-lang.org \"zero-cost abstractions\" \"performance\"`\n  - []  Rust RFC Ownership Model`site:github.com/rust-lang/rfcs \"ownership model\" \"design\"`\n\n- 2: \n  - [] Rust GC`\"Rust memory safety\" \"no garbage collector\" \"ownership\" site:doc.rust-lang.org`GC\n  - [] Rust `\"Rust learning curve\" \"difficulty\" \"official documentation\" -reddit -stackoverflow`The Rust Programming Language\n  - [] async/await  Rust `\"Rust async await\" \"zero cost\" \"runtime overhead\" site:doc.rust-lang.org`\n\n- 3: \n  - [] Rust GC`\"Rust borrow checker\" \"dangling pointer prevention\" \"lifetime system\" site:doc.rust-lang.org`lifetimesborrow checker\n  - []  Rust `\"Rust generics\" \"zero-cost\" \"monomorphization\" \"C++ template\" site:doc.rust-lang.org`monomorphizationC++\n  - [] Rust  Trait /`\"Rust trait\" \"interface inheritance\" \"composition vs inheritance\" site:doc.rust-lang.org` Trait \n\n- 4: \n  - [] Rust Pattern Matching`\"Rust pattern matching\" \"compiler optimization\" \"exhaustiveness checking\" site:doc.rust-lang.org`\n  - [] Rust  `no_std` `\"Rust no_std\" \"embedded\" \"core crate\" \"alloc crate\" site:doc.rust-lang.org` `core``alloc` \n  - [] Rust Macros`\"Rust macros\" \"procedural macros\" \"syntax expansion\" \"compile-time code generation\" site:doc.rust-lang.org` `macro_rules!`  `proc-macro` ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:13:08.976506 #21610]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:13:08.976583 #21610]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:13:08.976632 #21610]  INFO -- : Create Conversation
I, [2025-12-10T13:13:08.976668 #21610]  INFO -- : Use template smart_search
I, [2025-12-10T13:13:08.976992 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:08.977062 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:13.907641 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:13.907730 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:13.908473 #21610]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:13:15.883417 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits  17. Fundamentals of ... ownership, because we never had ownership. We call the action of creating...\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/.../ch16-04-extensible-concurrency-sync-and-send....\",\"link\":\"https://doc.rust-lang.org/book/ch16-04-extensible-concurrency-sync-and-send.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits  Allowing Transference of Ownership Between Threads with Send  Allowing Access from Multiple Threads with...\",\"title\":\"Extensible Concurrency with the Send and Sync Traits - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"snippet\":\"What is Ownership? 4.2. References and Borrowing  4.3. The Slice Type  5 ... Extensible Concurrency with the Send and Sync Traits  17. Fundamentals of...\",\"title\":\"What is Ownership? - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits  17. Fundamentals of ... In this chapter, we'll talk about ownership as well as several related features:...\",\"title\":\"Understanding Ownership - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"snippet\":\"By leveraging ownership and type checking, many concurrency errors are ... The Sync and Send traits, which extend Rust's concurrency guarantees to user...\",\"title\":\"Fearless Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits  17. Fundamentals of ... As you saw in Chapter 15, where smart pointers made multiple ownership possible,...\",\"title\":\"Shared-State Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch13-01-closures.html\",\"link\":\"https://doc.rust-lang.org/book/ch13-01-closures.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits  17. Fundamentals of ... borrowing immutably, borrowing mutably, and taking ownership. The closure...\",\"title\":\"Closures: Anonymous Functions that Capture Their Environment ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"... ownership rules don't ... As an example, recall the Send and Sync marker traits we discussed in Extensible Concurrency with the Send and Sync Traits...\",\"title\":\"Unsafe Rust - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch15-00-smart-pointers.html\",\"link\":\"https://doc.rust-lang.org/book/ch15-00-smart-pointers.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits  17. Fundamentals of ... Rust, with its concept of ownership and borrowing, has an additional...\",\"title\":\"Smart Pointers - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"snippet\":\"Extensible Concurrency with the Send and Sync Traits ... The move keyword overrides Rust's conservative default of borrowing; it doesn't let us violate the...\",\"title\":\"Using Threads to Run Code Simultaneously - The Rust ...\"}]", :with_history=>false}
I, [2025-12-10T13:13:15.883598 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:15.883660 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:15.884053 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:15.884100 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:16.138881 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:16.138929 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:16.138951 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:18.458543 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:18.458570 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:18.458607 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:18.458963 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:18.459018 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:18.708056 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:18.708156 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:18.708188 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:20.309656 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://blog.rust-lang.org/2015/04/24/Rust-Once-Run-Everywhere/\",\"link\":\"https://blog.rust-lang.org/2015/04/24/Rust-Once-Run-Everywhere/\",\"snippet\":\"Apr 24, 2015 ... ... performance to C function calls. FFI bindings can also leverage ... In this post we'll explore how to encapsulate unsafe FFI calls to C in safe,...\",\"title\":\"Rust Once, Run Everywhere | Rust Blog\"}]", :with_history=>false}
I, [2025-12-10T13:13:20.309673 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:20.309696 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:20.309933 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:20.309967 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:20.546483 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:20.546551 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:20.546567 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:22.426820 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:22.426935 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:22.426990 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:22.427331 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:22.427372 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:22.682053 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:22.682123 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:22.682141 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:24.347150 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:24.347177 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:24.347221 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:24.347615 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:24.347666 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:24.592340 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:24.592459 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:24.592483 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:26.249955 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://rust-class.org/pages/final-survey.html\",\"link\":\"https://rust-class.org/pages/final-survey.html\",\"snippet\":\"The official documentation provides up-to-date methods and fields but very ... The difficulty of the topics covered, and the lack of direct...\",\"title\":\"Final Survey\"},{\"formattedUrl\":\"https://blog.bytebytego.com/p/how-grabs-migration-from-go-to-rust\",\"link\":\"https://blog.bytebytego.com/p/how-grabs-migration-from-go-to-rust\",\"snippet\":\"Sep 29, 2025 ... Disclaimer: The details in this post have been derived from the official documentation shared online by the Grab Engineering Team. All...\",\"title\":\"How Grab's Migration from Go to Rust Cut Costs by 70%\"},{\"formattedUrl\":\"https://www.hashe.com/coding/rust-vs-cpp-which-to-choose/\",\"link\":\"https://www.hashe.com/coding/rust-vs-cpp-which-to-choose/\",\"snippet\":\"Nov 19, 2024 ... ... difficulty in use. With its compiled code and status as a descendant ... Rust Learning Curve. Rust has a high learning curve due to its...\",\"title\":\"Rust Vs C++: Which One To Choose?\"},{\"formattedUrl\":\"https://webthesis.biblio.polito.it/35376/1/tesi.pdf\",\"link\":\"https://webthesis.biblio.polito.it/35376/1/tesi.pdf\",\"snippet\":\"detail in the official documentation [18]. In this project, round 3 version ... The difficulty of this attack is influenced by the length of the vector...\",\"title\":\"POLITECNICO DI TORINO\"}]", :with_history=>false}
I, [2025-12-10T13:13:26.249983 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:26.250019 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:26.250331 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:26.250392 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:26.506436 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:26.506522 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:26.506545 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:28.488302 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:28.488330 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:28.488374 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:28.488774 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:28.488831 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:28.742807 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:28.742871 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:28.742888 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:30.751294 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:30.751337 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:30.751370 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:30.751693 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:30.751738 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:31.020676 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:31.020781 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:31.020807 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:32.835937 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:32.835962 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:32.836007 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:32.836383 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:32.836434 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:33.102948 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:33.103034 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:33.103054 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:35.128215 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:35.128232 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:35.128258 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:35.128513 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:35.128553 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:35.381816 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:35.381910 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:35.381935 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:37.093928 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:37.093952 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:37.093987 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:37.094317 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:37.094370 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:37.353626 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:37.353692 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:37.353707 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:39.070926 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:39.070977 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:39.071015 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:39.071374 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:39.071425 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:39.330078 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:39.330153 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:39.330171 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:41.091911 #21610]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:13:41.091934 #21610]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:13:41.091965 #21610]  INFO -- : Use template get_topic
I, [2025-12-10T13:13:41.092267 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:41.092315 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:41.356887 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:41.356956 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:41.356986 #21610]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:13:41.358292 #21610]  INFO -- : Calling worker: summary with params: {:text=>" Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:13:41.358317 #21610]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:13:41.358325 #21610]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:13:41.358334 #21610]  INFO -- : Create Conversation
I, [2025-12-10T13:13:41.358352 #21610]  INFO -- : Use template summarize
I, [2025-12-10T13:13:41.358565 #21610]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:13:41.358592 #21610]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:13:53.885401 #21610]  INFO -- : Successful send a message
I, [2025-12-10T13:13:53.885528 #21610]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:13:53.885542 #21610]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:15:19.001031 #22849]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:15:19.001145 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001185 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001191 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001201 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001209 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001217 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001222 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001253 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001258 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001266 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001270 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001278 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001282 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001305 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001309 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001319 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.001323 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.001333 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.066804 #22849]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:15:19.066877 #22849]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:15:19.067424 #22849]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:15:19.067469 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067498 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067503 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067510 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067515 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067522 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067526 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067551 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067558 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067566 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067571 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067577 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067581 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067592 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067724 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067746 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.067752 #22849]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:19.067763 #22849]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:19.068009 #22849]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:15:19.068031 #22849]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:15:27.230799 #22930]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:15:27.230876 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.230909 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.230915 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.230923 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.230927 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.230937 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.230941 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.230967 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.230972 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.230979 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.230982 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.230989 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.230992 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.231004 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.231008 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.231017 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.231022 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.231040 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.295654 #22930]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:15:27.295716 #22930]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:15:27.296194 #22930]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:15:27.296258 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296280 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296285 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296292 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296297 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296302 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296306 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296328 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296333 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296340 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296344 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296349 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296353 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296364 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296368 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296379 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296383 #22930]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:15:27.296393 #22930]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:15:27.296663 #22930]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:15:27.296690 #22930]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:18:37.907713 #23725]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:18:37.907799 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907835 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907841 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907851 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907855 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907863 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907868 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907890 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907895 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907906 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907911 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907918 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907922 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907933 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907938 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907949 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.907953 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.907964 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.977805 #23725]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:18:37.977877 #23725]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:18:37.978292 #23725]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:18:37.978335 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978358 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978363 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978371 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978375 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978381 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978385 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978408 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978412 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978419 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978423 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978430 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978434 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978445 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978449 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978460 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978464 #23725]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:18:37.978474 #23725]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:18:37.978753 #23725]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:18:37.978780 #23725]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:18:40.529317 #23725]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Rust ", :with_history=>true}
I, [2025-12-10T13:18:40.529326 #23725]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:18:40.529334 #23725]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:18:40.529346 #23725]  INFO -- : Create Conversation
I, [2025-12-10T13:18:40.529374 #23725]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:18:40.529727 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:18:40.529762 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:18:52.961724 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:18:52.961813 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:18:52.961849 #23725]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:18:53.564076 #23725]  INFO -- : Calling worker: pre_search with params: {:text=>" **Rust ** \n\n---\n\n### **1. **  \n****\n\n- ****  \n   Rust Ownership Systemborrowinglifetimesmove  \n- ****  \n  -    \n  -   C++/Go   \n  -    \n  -  \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | **** Rust  |\n| **** | ****Rust  1.0  1.70+ 2  |\n| **** | ****RFC  Rust  |\n\n>  ****  \n> 1. The Rust Programming LanguageRust Book  \n> 2. Rust doc.rust-lang.org  \n> 3. Rust RFCs RFC 0046, 0119, 0200  \n> 4. Rust RustConf \n\n---\n\n### **3. **  \n\n#### ****  \n- `Rust ownership system`  \n- `Rust borrow checker`  \n- `Rust move semantics`  \n- `Rust lifetimes`  \n- `Rust memory safety`\n\n#### ****  \n- `ownership vs borrowing`  \n- `mutable reference`  \n- `dangling pointer prevention`  \n- `stack vs heap allocation in Rust`  \n- `Rust ownership rules`\n\n#### ****  \n```plaintext\nsite:doc.rust-lang.org \"ownership system\"  \nsite:rust-lang.org/book \"ownership\"  \nintitle:\"ownership\" \"Rust\" filetype:pdf  \n\"Rust borrow checker\" tutorial  \n\"how does Rust ownership work\" site:stackoverflow.com  \n```\n\n#### ****  \n- `beginner`  \n- `comparison with C++`  \n- `interview question`  \n- `how to fix`\n\n>    \n> `\"Rust ownership system\" site:doc.rust-lang.org`  \n> `\"Rust ownership rules\" \"move\" \"borrow\" site:rust-lang.org/book`\n\n---\n\n### **4. **  \n\n#### ****  \n- **Rust Book4******  \n- **Rust Ownership**  \n- **Rust RFC ** GC  \n- **RustConf / Rust Belt Rust **YouTubeUnderstanding Ownership by Steve Klabnik\n\n#### ****  \n- **Rustlings **  \n- **Reddit r/rust** explain ownership   \n- **Stack Overflow ** Why does Rust have ownership?\n\n#### ****  \n|  |  |  |\n|------|------|----------|\n| **** | NLL | 5Rust |\n| **** | borrowing vs reference vs lifetimes  | doc.rust-lang.org/book/glossary.html |\n| **** |  Rust<1.31 NLL |  `site:doc.rust-lang.org/1.70`  |\n| **** |  | `Rust ownership diagram`  `Rust borrow checker visualization` |\n\n---\n\n###  ****  \n1. **** [https://doc.rust-lang.org/book/ch04-00-ownership.html](https://doc.rust-lang.org/book/ch04-00-ownership.html)  4  \n2. **** `site:doc.rust-lang.org \"borrow checker\"`   \n3. **** [Rust Programming - Ownership Explained (YouTube)](https://www.youtube.com/watch?v=1j321Z7X0Yw)   \n4. **** RFC 0046 r/rust \n\n>  ********\n\n**** Rust  Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:18:53.564178 #23725]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:18:53.564191 #23725]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:18:53.564206 #23725]  INFO -- : Create Conversation
I, [2025-12-10T13:18:53.564231 #23725]  INFO -- : Use template pre_search
I, [2025-12-10T13:18:53.564553 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:18:53.564584 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:18:55.238308 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:18:55.238422 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:18:55.238447 #23725]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:18:57.048817 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"snippet\":\"It enables Rust to make memory safety guarantees without needing a garbage collector, so it's important to understand how ownership works. In this chapter, we'...\",\"title\":\"Understanding Ownership - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"snippet\":\"Ownership is a set of rules that govern how a Rust program manages memory. All programs have to manage the way they use a computer's memory while running.\",\"title\":\"What is Ownership? - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"... ownership, because we never had ownership. We call the action of creating a reference borrowing. As in real life, if a person owns something, you can borrow...\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"snippet\":\"However, thanks to Rust's type system and ownership rules, you can't get locking and unlocking wrong. The API of Mutex\\u003cT\\u003e. As an example of how to use a...\",\"title\":\"Shared-State Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"snippet\":\"Over time, the team discovered that the ownership and type systems are a powerful set of tools to help manage memory safety and concurrency problems! By...\",\"title\":\"Fearless Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-02-message-passing.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-02-message-passing.html\",\"snippet\":\"... ownership throughout your Rust programs. ... This stops us from accidentally using the value again after sending it; the ownership system checks that everything...\",\"title\":\"Using Message Passing to Transfer Data Between Threads - The ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"snippet\":\"(Rust's async system, which we will see in the next chapter, provides ... Rust's ownership rules have saved us again! We got an error from the code in...\",\"title\":\"Using Threads to Run Code Simultaneously - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"... system or even writing your own operating system. Working with low-level ... ownership rules don't allow a mutable reference at the same time as any...\",\"title\":\"Unsafe Rust - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"link\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"snippet\":\"You also don't have to worry about problems resulting from accidentally cleaning up values still in use: the ownership system that makes sure references are...\",\"title\":\"Running Code on Cleanup with the Drop Trait - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-03-slices.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-03-slices.html\",\"snippet\":\"Slices let you reference a contiguous sequence of elements in a collection. A slice is a kind of reference, so it does not have ownership. Here's a small...\",\"title\":\"The Slice Type - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:18:57.048889 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:18:57.048901 #23725]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:18:57.048915 #23725]  INFO -- : Create Conversation
I, [2025-12-10T13:18:57.048941 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:18:57.049195 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:18:57.049221 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:18:57.292685 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:18:57.292752 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:18:57.292774 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:18:59.227725 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"A reference is like a pointer in that it's an address we can follow to access the data stored at that address; that data is owned by some other variable.\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../is_the_rust_borrow_checker_really_that_...\",\"link\":\"https://www.reddit.com/r/rust/comments/15lr1do/is_the_rust_borrow_checker_really_that_challenging/\",\"snippet\":\"Aug 8, 2023 ... ... official documentation with excellent explanations. One may argue that rust lacks the simplicity of for example C. However I'd argue that...\",\"title\":\"Is the Rust Borrow Checker Really That Challenging? : r/rust\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/math-behind-borrow-checker/37079\",\"link\":\"https://users.rust-lang.org/t/math-behind-borrow-checker/37079\",\"snippet\":\"Jan 18, 2020 ... And are there any blog posts (or papers) that discuss this? OptimisticPeach January 18, 2020, 2:15am 2.\",\"title\":\"Math behind borrow checker - help - The Rust Programming ...\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/resources-for...rusts-borrow-checker/19041\",\"link\":\"https://internals.rust-lang.org/t/resources-for-implementing-rusts-borrow-checker/19041\",\"snippet\":\"Jun 21, 2023 ... I'd like to implement Rust's borrow checker, but I haven't found great documentation to get started. The rustc borrow checking code is complicated.\",\"title\":\"Resources for implementing Rust's borrow checker - compiler - Rust ...\"},{\"formattedUrl\":\"https://medium.com/@BobGneu/documentation-tests-in-rust-2ece7165e2f9\",\"link\":\"https://medium.com/@BobGneu/documentation-tests-in-rust-2ece7165e2f9\",\"snippet\":\"Mar 23, 2018 ... The ecosystem has a fantastic handle on the partnership between code, tests, and documentation. The borrow checker gives most green rustaceans a run for their...\",\"title\":\"Documentation + Tests in Rust. When spending time on medium ...\"},{\"formattedUrl\":\"https://github.com/rust-lang/reference/issues/788\",\"link\":\"https://github.com/rust-lang/reference/issues/788\",\"snippet\":\"Apr 4, 2020 ... ... official documentation which was available is an earlier version of the Rustonomicon. ... borrow checker? rust#138194  Rudxain. mentioned this on...\",\"title\":\"better documentation of reborrowing  Issue #788  rust-lang/reference\"},{\"formattedUrl\":\"https://cybernetist.com/2024/04/19/rust-tokio-task-cancellation-patterns/\",\"link\":\"https://cybernetist.com/2024/04/19/rust-tokio-task-cancellation-patterns/\",\"snippet\":\"Apr 19, 2024 ... As with everything in Rust, async programming has to be memory-safe so you need to make sure the borrow checker is happy. Which is a proper...\",\"title\":\"Rust tokio task cancellation patterns - Cybernetist\"},{\"formattedUrl\":\"https://news.ycombinator.com/item?id=40657626\",\"link\":\"https://news.ycombinator.com/item?id=40657626\",\"snippet\":\"Jun 14, 2024 ... It works in a toy example: https://play.rust-lang.org/?version=stable\\u0026mode=debug\\u0026editio... ... They are also documentation / API contracts:.\",\"title\":\"The borrow checker within | Hacker News\"},{\"formattedUrl\":\"https://stackoverflow.com/.../understanding-and-relationship-between-box-r...\",\"link\":\"https://stackoverflow.com/questions/31949579/understanding-and-relationship-between-box-ref-and\",\"snippet\":\"Aug 11, 2015 ... impl Copy (): Please check the official documentation. *mut T ... The borrow checker guarantees that references are always valid...\",\"title\":\"pointers - Understanding and relationship between Box, ref, \\u0026 and ...\"},{\"formattedUrl\":\"https://discuss.pytorch.org/t/is-it-possible-use-a...model...rust.../205091\",\"link\":\"https://discuss.pytorch.org/t/is-it-possible-use-a-executorch-model-with-rust-code/205091\",\"snippet\":\"Jun 22, 2024 ... ... Rust borrow checker using lifetimes. Sometimes I had to check the code to make sure or if the docs were missing. The compilation flags to...\",\"title\":\"Is it possible use a executorch model with rust code? - ExecuTorch ...\"}]", :with_history=>false}
I, [2025-12-10T13:18:59.227755 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:18:59.227783 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:18:59.228055 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:18:59.228092 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:18:59.470224 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:18:59.470297 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:18:59.470315 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:01.877961 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:19:01.877988 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:19:01.878013 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:19:01.878265 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:01.878298 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:02.116583 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:02.116661 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:02.116678 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:02.117778 #23725]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:19:02.117808 #23725]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:19:02.117821 #23725]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:19:02.117830 #23725]  INFO -- : Create Conversation
I, [2025-12-10T13:19:02.117847 #23725]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:19:02.118088 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:02.118112 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:02.700962 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:02.701034 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:02.701048 #23725]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:19:03.303329 #23725]  INFO -- : Calling worker: smart_search with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:19:03.303432 #23725]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:19:03.303445 #23725]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:19:03.303456 #23725]  INFO -- : Create Conversation
I, [2025-12-10T13:19:03.303484 #23725]  INFO -- : Use template smart_search
I, [2025-12-10T13:19:03.303743 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:03.303769 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:04.979850 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:04.979955 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:04.979980 #23725]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:19:07.705485 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"snippet\":\"It enables Rust to make memory safety guarantees without needing a garbage collector, so it's important to understand how ownership works. In this chapter, we'...\",\"title\":\"Understanding Ownership - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"snippet\":\"Ownership is a set of rules that govern how a Rust program manages memory. All programs have to manage the way they use a computer's memory while running.\",\"title\":\"What is Ownership? - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"... ownership, because we never had ownership. We call the action of creating a reference borrowing. As in real life, if a person owns something, you can borrow...\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-03-shared-state.html\",\"snippet\":\"However, thanks to Rust's type system and ownership rules, you can't get locking and unlocking wrong. The API of Mutex\\u003cT\\u003e. As an example of how to use a...\",\"title\":\"Shared-State Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-00-concurrency.html\",\"snippet\":\"Over time, the team discovered that the ownership and type systems are a powerful set of tools to help manage memory safety and concurrency problems! By...\",\"title\":\"Fearless Concurrency - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-02-message-passing.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-02-message-passing.html\",\"snippet\":\"... ownership throughout your Rust programs. ... This stops us from accidentally using the value again after sending it; the ownership system checks that everything...\",\"title\":\"Using Message Passing to Transfer Data Between Threads - The ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"snippet\":\"(Rust's async system, which we will see in the next chapter, provides ... Rust's ownership rules have saved us again! We got an error from the code in...\",\"title\":\"Using Threads to Run Code Simultaneously - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"... system or even writing your own operating system. Working with low-level ... ownership rules don't allow a mutable reference at the same time as any...\",\"title\":\"Unsafe Rust - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"link\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"snippet\":\"You also don't have to worry about problems resulting from accidentally cleaning up values still in use: the ownership system that makes sure references are...\",\"title\":\"Running Code on Cleanup with the Drop Trait - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-03-slices.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-03-slices.html\",\"snippet\":\"Slices let you reference a contiguous sequence of elements in a collection. A slice is a kind of reference, so it does not have ownership. Here's a small...\",\"title\":\"The Slice Type - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:19:07.705558 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:19:07.705590 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:19:07.705868 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:07.705906 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:07.951748 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:07.951817 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:07.951834 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:09.751535 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html\",\"snippet\":\"\",\"title\":\"Untitled\"},{\"formattedUrl\":\"https://doc.rust-lang.org/rust-by-example/scope/borrow.html\",\"link\":\"https://doc.rust-lang.org/rust-by-example/scope/borrow.html\",\"snippet\":\"The compiler statically guarantees (via its borrow checker) that references always point to valid objects. That is, while references to an object exist, the...\",\"title\":\"Borrowing - Rust By Example\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"A reference is like a pointer in that it's an address we can follow to access the data stored at that address; that data is owned by some other variable.\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"link\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"snippet\":\"The Rust compiler has a borrow checker that compares scopes to determine whether all borrows are valid. Listing 10-17 shows the same code as...\",\"title\":\"Validating References with Lifetimes - The Rust Programming ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/borrow-splitting.html\",\"link\":\"https://doc.rust-lang.org/nomicon/borrow-splitting.html\",\"snippet\":\"Splitting Borrows. The mutual exclusion property of mutable references can be very limiting when working with a composite structure. The borrow checker...\",\"title\":\"Splitting Borrows - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html\",\"snippet\":\"... works. In this chapter, we'll talk about ownership as well as several related features: borrowing, slices, and how Rust lays data out in memory.\",\"title\":\"Understanding Ownership - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"It's important to understand that unsafe doesn't turn off the borrow checker or disable any of Rust's other safety checks: if you use a reference in unsafe code...\",\"title\":\"Unsafe Rust - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/rust-by-example/scope/lifetime.html\",\"link\":\"https://doc.rust-lang.org/rust-by-example/scope/lifetime.html\",\"snippet\":\"A lifetime is a construct the compiler (or more specifically, its borrow checker) uses to ensure all borrows are valid.\",\"title\":\"Lifetimes - Rust By Example\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/dropck.html\",\"link\":\"https://doc.rust-lang.org/nomicon/dropck.html\",\"snippet\":\"The Dark Arts of Advanced and Unsafe Rust Programming. ... borrow checker doesn't understand. So why do we care? We care because if the...\",\"title\":\"Drop Check - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch15-05-interior-mutability.html\",\"link\":\"https://doc.rust-lang.org/book/ch15-05-interior-mutability.html\",\"snippet\":\"The advantages of checking the borrowing rules at compile time are that errors will be caught sooner in the development process, and there is no impact on...\",\"title\":\"RefCell\\u003cT\\u003e and the Interior Mutability Pattern - The Rust ...\"}]", :with_history=>false}
I, [2025-12-10T13:19:09.751610 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:19:09.751649 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:19:09.752080 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:09.752143 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:09.998000 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:09.998093 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:09.998119 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:12.001800 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-02-references-and-borrowing.html\",\"snippet\":\"Rust enforces a similar rule for combining mutable and immutable references. ... Ownership is moved out, and nothing is deallocated. The Rules of References.\",\"title\":\"References and Borrowing - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"link\":\"https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html\",\"snippet\":\"Ownership Rules. First, let's take a look at the ownership rules. Keep ... \\\"); | ^^^^ value borrowed here after move | = note: this error originates in...\",\"title\":\"What is Ownership? - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"link\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"snippet\":\"The Rust compiler has a borrow checker that compares scopes to determine whether all borrows are valid. Listing 10-17 shows the same code as...\",\"title\":\"Validating References with Lifetimes - The Rust Programming ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/subtyping.html\",\"link\":\"https://doc.rust-lang.org/nomicon/subtyping.html\",\"snippet\":\"Rust uses lifetimes to track the relationships between borrows and ownership. ... move a value, you are guaranteed to be the only one with access to it...\",\"title\":\"Subtyping and Variance - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/rust-by-example/scope/lifetime.html\",\"link\":\"https://doc.rust-lang.org/rust-by-example/scope/lifetime.html\",\"snippet\":\"A lifetime is a construct the compiler (or more specifically, its borrow checker) uses to ensure all borrows are valid.\",\"title\":\"Lifetimes - Rust By Example\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"link\":\"https://doc.rust-lang.org/book/ch16-01-threads.html\",\"snippet\":\"The move keyword overrides Rust's conservative default of borrowing; it doesn't let us violate the ownership rules. Now that we've covered what threads are...\",\"title\":\"Using Threads to Run Code Simultaneously - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/rust-by-example/scope.html\",\"link\":\"https://doc.rust-lang.org/rust-by-example/scope.html\",\"snippet\":\"Scoping rules. Scopes play an important part in ownership, borrowing, and lifetimes. That is, they indicate to the compiler when borrows are valid,...\",\"title\":\"Scoping rules - Rust By Example\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/types/closure.html\",\"link\":\"https://doc.rust-lang.org/reference/types/closure.html\",\"snippet\":\"The closure borrows or moves the capture path, which may be truncated based on the rules described below. For example:.\",\"title\":\"Closure types - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/rust-by-example/fn/closures/capture.html\",\"link\":\"https://doc.rust-lang.org/rust-by-example/fn/closures/capture.html\",\"snippet\":\"// has been moved. // Removing `move` from closure's signature will cause closure. // to borrow _haystack_ variable immutably, hence _haystack_...\",\"title\":\"Capturing - Rust By Example\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"Dereferencing a Raw Pointer  Are allowed to ignore the borrowing rules by having both immutable and mutable pointers or multiple mutable pointers to the same...\",\"title\":\"Unsafe Rust - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:19:12.001853 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:19:12.001890 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:19:12.002407 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:12.002457 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:12.245413 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:12.245533 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:12.245553 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:14.005004 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://github.com/rust-lang/rfcs/issues/2844\",\"link\":\"https://github.com/rust-lang/rfcs/issues/2844\",\"snippet\":\"Jan 6, 2020 ... rust-lang / rfcs Public. Notifications You must be signed in to ... kaan-atakan. changed the title [-]Integer division operator that...\",\"title\":\"Integer division method or operator that rounds up  Issue #2844 ...\"},{\"formattedUrl\":\"https://github.com/rust-lang/rfcs/pull/3113\",\"link\":\"https://github.com/rust-lang/rfcs/pull/3113\",\"snippet\":\"rust-lang / rfcs Public. Notifications You must be signed in to change ... As the owner of the gba crate, which is a crate for an embedded device, I'm...\",\"title\":\"Add bitfields support by Andy-Python-Programmer  Pull Request ...\"}]", :with_history=>false}
I, [2025-12-10T13:19:14.005037 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:19:14.005151 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:19:14.005517 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:14.005554 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:14.255165 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:14.255248 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:14.255269 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:16.234811 #23725]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://users.rust-lang.org/t/boris-an-ownership-and-borrowing.../105877\",\"link\":\"https://users.rust-lang.org/t/boris-an-ownership-and-borrowing-visualizer/105877\",\"snippet\":\"Jan 26, 2024 ... ... visualizations for rust programs. The ... ownership and borrowing concepts generally, which are only tangentially related to your diagrams.\",\"title\":\"BorIs - An Ownership and Borrowing Visualizer - Rust Users Forum\"},{\"formattedUrl\":\"https://stackoverflow.com/.../is-there-any-mechanism-to-generate-an-owner...\",\"link\":\"https://stackoverflow.com/questions/57487568/is-there-any-mechanism-to-generate-an-ownership-tree-visualization-with-rust-o\",\"snippet\":\"Aug 14, 2019 ... ... ownership tree\\\" visualization with Rust or the Rust tooling? Can I ... How do I build a graph like data structure of linked nodes in Rust?\",\"title\":\"Is there any mechanism to generate an \\\"ownership tree ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/comments/.../ownership_concept_diagram/\",\"link\":\"https://www.reddit.com/r/rust/comments/mgh9n9/ownership_concept_diagram/\",\"snippet\":\"Mar 30, 2021 ... 2.4K votes, 88 comments. (1) In those cases, T can be replaced with Box (2) Use AtomicT when T is a bool or a number Source.\",\"title\":\"Ownership Concept Diagram : r/rust\"},{\"formattedUrl\":\"https://medium.com/.../rust-ownership-and-borrowing-rules-a085b72c9678\",\"link\":\"https://medium.com/@mylifewodoor/rust-ownership-and-borrowing-rules-a085b72c9678\",\"snippet\":\"Apr 30, 2025 ... The first diagram below illustrates how the Rust compiler treats an immutable variable (. It shows how multiple immutable references ( \\u0026s)...\",\"title\":\"Visualizing the Rust Ownership and Borrowing Rules - Ben Racine ...\"},{\"formattedUrl\":\"https://blog.adamant-lang.org/2019/rust-lifetime-visualization-ideas/\",\"link\":\"https://blog.adamant-lang.org/2019/rust-lifetime-visualization-ideas/\",\"snippet\":\"Feb 18, 2019 ... ... visualization. I started with the diagrams in the Graphical depiction of ownership and borrowing in Rust post. However, as I said, they...\",\"title\":\"Rust Lifetime Visualization Ideas  The Adamant Programming ...\"},{\"formattedUrl\":\"https://github.com/cognitive-engineering-lab/aquascope\",\"link\":\"https://github.com/cognitive-engineering-lab/aquascope\",\"snippet\":\"Want to learn more about what the diagram means? Read the new ownership ... Rust, concept inventory, ownership types, program state visualization} }...\",\"title\":\"cognitive-engineering-lab/aquascope: Interactive ... - GitHub\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/borrow-visualizer-for-the-rust.../4187\",\"link\":\"https://internals.rust-lang.org/t/borrow-visualizer-for-the-rust-language-service/4187\",\"snippet\":\"Oct 11, 2016 ... I almost think you need a different visualization for that (like a full annotated/colorised control flow graph?). 1 Like. Nashenas88 October...\",\"title\":\"Borrow visualizer for the Rust Language Service - tools and ...\"},{\"formattedUrl\":\"https://www.janestreet.com/tech-talks/rust-for-everyone/\",\"link\":\"https://www.janestreet.com/tech-talks/rust-for-everyone/\",\"snippet\":\"So if you look around the internet for ownership visualizations, you'll find a half dozen diagrams that all look kind of like this. The unifying feature of...\",\"title\":\"Rust for Everyone! :: Jane Street\"},{\"formattedUrl\":\"https://lib.rs/visualization\",\"link\":\"https://lib.rs/visualization\",\"snippet\":\"Interactive graph visualization widget for rust powered by egui. v0.29.0 750 ... Visualize Ownership and Lifetimes in Rust. v0.0.3 nightly bin+lib...\",\"title\":\"Visualization  list of Rust libraries/crates // Lib.rs\"},{\"formattedUrl\":\"https://cel.cs.brown.edu/aquascope/\",\"link\":\"https://cel.cs.brown.edu/aquascope/\",\"snippet\":\"... visualize the compile-time and run-time behavior of Rust programs. ... If you want to see Aquascope diagrams in action, check out the new chapter on ownership in...\",\"title\":\"Aquascope: Look Beneath the Surface of Rust\"}]", :with_history=>false}
I, [2025-12-10T13:19:16.234840 #23725]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:19:16.234868 #23725]  INFO -- : Use template get_topic
I, [2025-12-10T13:19:16.235095 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:16.235128 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:16.475031 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:16.475107 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:16.475126 #23725]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:19:16.539308 #23725]  INFO -- : Calling worker: summary with params: {:text=>"Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:19:16.539337 #23725]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:19:16.539345 #23725]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:19:16.539354 #23725]  INFO -- : Create Conversation
I, [2025-12-10T13:19:16.539374 #23725]  INFO -- : Use template summarize
I, [2025-12-10T13:19:16.539584 #23725]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:19:16.539609 #23725]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:19:28.453836 #23725]  INFO -- : Successful send a message
I, [2025-12-10T13:19:28.453925 #23725]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:19:28.453944 #23725]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:23:29.857247 #24997]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:23:29.857636 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857679 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857686 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857696 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857701 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857708 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857713 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857741 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857760 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857773 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857779 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857787 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857792 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857805 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857810 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857822 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.857826 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.857836 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.978170 #24997]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:23:29.978236 #24997]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:23:29.978923 #24997]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:23:29.978959 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.978981 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.978987 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.978995 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979000 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979007 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979011 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979032 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979048 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979060 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979066 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979078 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979083 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979097 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979126 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979144 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979154 #24997]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:23:29.979165 #24997]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:23:29.979432 #24997]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:23:29.979456 #24997]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:23:32.550195 #24997]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Rust ", :with_history=>true}
I, [2025-12-10T13:23:32.550256 #24997]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:23:32.550268 #24997]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:23:32.550283 #24997]  INFO -- : Create Conversation
I, [2025-12-10T13:23:32.550346 #24997]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:23:32.550853 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:32.550880 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:23:44.537356 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:23:44.537497 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:23:44.537521 #24997]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:23:45.139888 #24997]  INFO -- : Calling worker: pre_search with params: {:text=>" **Rust ** \n\n---\n\n### **1. **  \n **Technical / Expert Knowledge**  \n\n- ****  \n   Rust OwnershipBorrowingLifetimes  \n- ****  \n  -   \n  -  C++  \n  -   \n  - \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** |  **** |\n| **** |  ****Rust  1.02015 2021 edition 3  |\n| **** |  **** |\n\n> **** >  >  > / > \n\n---\n\n### **3. **  \n\n####  ****  \n- `Rust ownership system`  \n- `Rust ownership mechanism`  \n- `Rust borrow checker`  \n- `Rust memory safety ownership`  \n\n####  ****  \n- `borrowing`  \n- `lifetimes` (`'a`)  \n- `move semantics`  \n- `stack vs heap`  \n- `ownership rules`  \n- `Rust ownership diagram`  \n- `Rust ownership compiler`  \n\n####  ****  \n```plaintext\n\"Rust ownership system\" site:doc.rust-lang.org  \n\"Rust ownership\" filetype:pdf  \nintitle:\"Rust Ownership\" inurl:rust-lang.org  \n\"Rust borrow checker\" explained site:rust-analyzer.github.io  \n```\n\n####  ****  \n- `tutorial`  \n- `beginner`  \n- `comparison`  \n- `vs C++`  \n- `install` / `setup`  \n\n>  ****  \n> `\"Rust ownership system\" site:doc.rust-lang.org \"borrow checker\" \"lifetimes\"`  \n\n---\n\n### **4. **  \n\n####  ****  \n- ****[https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html)  \n  - Rust Book   \n- ****  \n  - Rust Blog  \n  - The Rustonomicon  \n- ****  \n  - Rust Programming Language  \n  - Programming RustO'ReillyJim Blandy  \n\n####  ****  \n- **YouTube ** Rust Ownership Explained by The Rust Programming Language Channel  \n- **Stack Overflow **  \n- **Rust RFCs** RFC 0047  \n\n####  ****  \n|  |  |  |\n|------|------|----------|\n| **** | / |  |\n| **** |  `Rust 2015`  `&mut`  |  2021 edition  |\n| **** |  |  `ownership and lifetimes`  |\n| **** |  | Rust Playground |\n\n---\n\n###  ****  \n\n1. **** [Rust Book - Chapter 4: Understanding Ownership](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html)  \n2. **** `site:doc.rust-lang.org \"borrow checker\" \"move semantics\"`   \n3. **** `Rust ownership diagram filetype:png`  [Rustlings](https://github.com/rust-lang/rustlings)   \n4. **** Stack Overflow `[rust] ownership`  \n\n> ********\n\n--- \n\n Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:23:45.140122 #24997]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:23:45.140146 #24997]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:23:45.140162 #24997]  INFO -- : Create Conversation
I, [2025-12-10T13:23:45.140199 #24997]  INFO -- : Use template pre_search
I, [2025-12-10T13:23:45.140772 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:45.140819 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:23:46.766755 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:23:46.766846 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:23:46.766867 #24997]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:23:48.482417 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/ownership.html\",\"link\":\"https://doc.rust-lang.org/nomicon/ownership.html\",\"snippet\":\"This is exactly what Rust's ownership system was built to solve. Rust knows the scope in which the \\u0026s lives, and as such can prevent it from escaping...\",\"title\":\"Ownership - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/races.html\",\"link\":\"https://doc.rust-lang.org/nomicon/races.html\",\"snippet\":\"A data race has Undefined Behavior, and is therefore impossible to perform in Safe Rust. Data races are prevented mostly through Rust's ownership system alone:...\",\"title\":\"Races - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0382.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0382.html\",\"snippet\":\"Since MyStruct is a type that is not marked Copy , the data gets moved out of x when we set y . This is fundamental to Rust's ownership system: outside of...\",\"title\":\"E0382 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0507.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0507.html\",\"snippet\":\"... , TheDarkKnight).nothing_is_true(); // ok! } For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0507 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"link\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"snippet\":\"With the Drop trait and Rust's ownership system, you don't have to remember to clean up because Rust does it automatically. You also don't have to worry...\",\"title\":\"Running Code on Cleanup with the Drop Trait - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/leaking.html\",\"link\":\"https://doc.rust-lang.org/nomicon/leaking.html\",\"snippet\":\"Rust's ownership system perfectly ensures it! ...except it relies on a destructor being called to be safe. let mut data = Box::new(0); { let guard = thread...\",\"title\":\"Leaking - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0502.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0502.html\",\"snippet\":\"... y = \\u0026a; // ok! println!(\\\"{}\\\", y); } }. For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0502 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0503.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0503.html\",\"snippet\":\"... ends here. println!(\\\"{}\\\", borrow); }. For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0503 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"snippet\":\"... be copied here. borrow(ref_to_val); }. For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0505 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/beta/book/ch00-00-introduction.html\",\"link\":\"https://doc.rust-lang.org/beta/book/ch00-00-introduction.html\",\"snippet\":\"In Chapter 4, you'll learn about Rust's ownership system. Chapter 5 discusses structs and methods. Chapter 6 covers enums, match expressions, and the if let...\",\"title\":\"Introduction - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:23:48.482495 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:23:48.482511 #24997]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:23:48.482527 #24997]  INFO -- : Create Conversation
I, [2025-12-10T13:23:48.482553 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:23:48.482864 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:48.482907 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:23:48.724330 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:23:48.724427 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:23:48.724459 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:23:50.764860 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:23:50.764885 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:23:50.764922 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:23:50.765291 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:50.765345 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:23:50.998905 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:23:50.999027 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:23:50.999057 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:23:53.006889 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:23:53.006915 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:23:53.006955 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:23:53.007367 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:53.007432 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:23:53.238942 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:23:53.239023 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:23:53.239037 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:23:55.048136 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://medium.com/.../ownership-who-really-holds-the-power-of-life-and-...\",\"link\":\"https://medium.com/@chenymj23/ownership-who-really-holds-the-power-of-life-and-death-over-values-c559b0527727\",\"snippet\":\"Oct 7, 2024 ... So today, let's return to rationality and tackle the hardest challenge in learning Rust: ownership and lifetimes. ... Additionally, the official...\",\"title\":\"Rust Ownership and Lifetimes Explained: Clear Examples | Medium\"},{\"formattedUrl\":\"https://www.usenix.org/system/files/soups2021-fulton.pdf\",\"link\":\"https://www.usenix.org/system/files/soups2021-fulton.pdf\",\"snippet\":\"developers to use Rust's ownership and lifetimes. Further, we find that much of the cost of adoption occurs up front, while benefits tend to accrue later...\",\"title\":\"Benefits and Drawbacks of Adopting a Secure Programming ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/.../media_is_this_an_accurate_description_of_rust...\",\"link\":\"https://www.reddit.com/r/rust/comments/vkoedz/media_is_this_an_accurate_description_of_rusts/\",\"snippet\":\"Jun 25, 2022 ... ... documentation doesn't call out that they are ... It is possible that Rust's ownership and lifetimes evolved from C++'s move semantics.\",\"title\":\"[Media] Is this an accurate description of Rust's concurrency model ...\"},{\"formattedUrl\":\"https://stackoverflow.com/questions/.../multiple-mutable-references-in-a-loo...\",\"link\":\"https://stackoverflow.com/questions/69545670/multiple-mutable-references-in-a-loop\",\"snippet\":\"Oct 12, 2021 ... I'm trying to learn Rust's ownership and lifetimes in more detail, and I'm very confused by this piece of code: rust. Copy. let mut lst = vec...\",\"title\":\"rust - Multiple mutable references in a loop - Stack Overflow\"},{\"formattedUrl\":\"https://arxiv.org/abs/2401.01114\",\"link\":\"https://arxiv.org/abs/2401.01114\",\"snippet\":\"Jan 2, 2024 ... With due consideration for Rust's ownership and lifetimes, we first complete the pointer analysis. ... Connected Papers (What is Connected Papers?).\",\"title\":\"Static Deadlock Detection for Rust Programs\"},{\"formattedUrl\":\"https://ilyasergey.net/assets/pdf/papers/rem-oopsla23.pdf\",\"link\":\"https://ilyasergey.net/assets/pdf/papers/rem-oopsla23.pdf\",\"snippet\":\"Aug 27, 2023 ... Rust's ownership and lifetimes disciplines, as well as by non-local ... https://code.visualstudio.com/docs/editor/refactoring. Emerson...\",\"title\":\"Adventure of a Lifetime: Extract Method Refactoring for Rust\"},{\"formattedUrl\":\"https://dl.acm.org/doi/abs/10.1145/3758316.3765486\",\"link\":\"https://dl.acm.org/doi/abs/10.1145/3758316.3765486\",\"snippet\":\"Oct 12, 2025 ... In Rust, ownership and lifetimes make automatic extraction ... https://verse-lab.github.io/papers/Sewen-Thy-Capstone.pdf. Google Scholar.\",\"title\":\"Verifying Extract Method Refactoring in Rust | Companion ...\"},{\"formattedUrl\":\"https://www.sigplan.org/OpenTOC/splash-companion25.html\",\"link\":\"https://www.sigplan.org/OpenTOC/splash-companion25.html\",\"snippet\":\"... papers), interviews (23 practitioners), and a global survey (59 ... In Rust, ownership and lifetimes make automatic extraction attractive yet...\",\"title\":\"SPLASH Companion '25: Companion Proceedings of the 2025 ACM ...\"},{\"formattedUrl\":\"https://dl.acm.org/doi/pdf/10.1145/3758316.3765486\",\"link\":\"https://dl.acm.org/doi/pdf/10.1145/3758316.3765486\",\"snippet\":\"Oct 12, 2025 ... In. Rust, ownership and lifetimes make automatic extraction at- ... https://verse-lab.github.io/papers/  Sewen-Thy-Capstone.pdf. [4] Sewen Thy...\",\"title\":\"Verifying Extract Method Refactoring in Rust\"},{\"formattedUrl\":\"https://www.linkedin.com/.../analytics-india-magazine_the-ai-developer-co...\",\"link\":\"https://www.linkedin.com/posts/analytics-india-magazine_the-ai-developer-community-is-shifting-from-activity-7387783722298720256-55UE\",\"snippet\":\"Oct 25, 2025 ... I learned Rust ownership and lifetimes. I understand Nuxt SSR ... Retrieved Information (Semantic Memory) Relevant documents or data fetched via...\",\"title\":\"AI Developers Shift to Context Engineering: Karpathy, Allred ...\"}]", :with_history=>false}
I, [2025-12-10T13:23:55.048167 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:23:55.048190 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:23:55.048409 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:55.048438 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:23:55.292203 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:23:55.292286 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:23:55.292307 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:23:55.357225 #24997]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:23:55.357251 #24997]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:23:55.357260 #24997]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:23:55.357269 #24997]  INFO -- : Create Conversation
I, [2025-12-10T13:23:55.357285 #24997]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:23:55.357534 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:23:55.357560 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:01.826960 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:01.827055 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:01.827074 #24997]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:24:02.429826 #24997]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1: \n  - []  Rust  `\"Rust ownership system\" site:doc.rust-lang.org`The Rust Programming Language4The Rustonomicon\n  - []  `\"Rust borrow checker\" site:doc.rust-lang.org`\n  - []  `Rust ownership diagram filetype:png site:doc.rust-lang.org`  `Rust ownership and borrowing diagram`/\n\n- 2: \n  - []  `\"Rust ownership and lifetimes\" official documentation`\n  - [] Rust  `\"Rust ownership prevents data races\" site:doc.rust-lang.org/nomicon`The RustonomiconRaces\n  - []  E0502/E0505  `E0502 site:doc.rust-lang.org/error_codes`  `E0505 site:doc.rust-lang.org/error_codes`\n\n- 3: \n  - []  `\"Rust multiple mutable references why not\" site:stackoverflow.com`\n  - [] move semantics `\"Rust ownership move semantics difference\" site:doc.rust-lang.org` `Copy`  `Copy` \n  - [] Drop trait  `\"Rust Drop trait ownership integration\" site:doc.rust-lang.org/book` `drop()` \n\n- 4: \n  - []  `\"Rust ownership compiler implementation\" site:github.com/rust-lang/rust` Rust  `borrowck`\n  - []  `\"Rust ownership formal verification\" site:arxiv.org` `arXiv:2401.01114` \n  - []  Rust 2021 Edition `\"Rust 2021 edition ownership improvements\" site:blog.rust-lang.org`", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:24:02.429964 #24997]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:24:02.429990 #24997]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:24:02.430006 #24997]  INFO -- : Create Conversation
I, [2025-12-10T13:24:02.430038 #24997]  INFO -- : Use template smart_search
I, [2025-12-10T13:24:02.430368 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:02.430418 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:06.317245 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:06.317340 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:06.317355 #24997]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:24:08.393349 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/ownership.html\",\"link\":\"https://doc.rust-lang.org/nomicon/ownership.html\",\"snippet\":\"This is exactly what Rust's ownership system was built to solve. Rust knows the scope in which the \\u0026s lives, and as such can prevent it from escaping...\",\"title\":\"Ownership - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/races.html\",\"link\":\"https://doc.rust-lang.org/nomicon/races.html\",\"snippet\":\"A data race has Undefined Behavior, and is therefore impossible to perform in Safe Rust. Data races are prevented mostly through Rust's ownership system alone:...\",\"title\":\"Races - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0382.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0382.html\",\"snippet\":\"Since MyStruct is a type that is not marked Copy , the data gets moved out of x when we set y . This is fundamental to Rust's ownership system: outside of...\",\"title\":\"E0382 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0507.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0507.html\",\"snippet\":\"... , TheDarkKnight).nothing_is_true(); // ok! } For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0507 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"link\":\"https://doc.rust-lang.org/book/ch15-03-drop.html\",\"snippet\":\"With the Drop trait and Rust's ownership system, you don't have to remember to clean up because Rust does it automatically. You also don't have to worry...\",\"title\":\"Running Code on Cleanup with the Drop Trait - The Rust ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/leaking.html\",\"link\":\"https://doc.rust-lang.org/nomicon/leaking.html\",\"snippet\":\"Rust's ownership system perfectly ensures it! ...except it relies on a destructor being called to be safe. let mut data = Box::new(0); { let guard = thread...\",\"title\":\"Leaking - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0502.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0502.html\",\"snippet\":\"... y = \\u0026a; // ok! println!(\\\"{}\\\", y); } }. For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0502 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0503.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0503.html\",\"snippet\":\"... ends here. println!(\\\"{}\\\", borrow); }. For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0503 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"snippet\":\"... be copied here. borrow(ref_to_val); }. For more information on Rust's ownership system, take a look at the References \\u0026 Borrowing section of the Book.\",\"title\":\"E0505 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/beta/book/ch00-00-introduction.html\",\"link\":\"https://doc.rust-lang.org/beta/book/ch00-00-introduction.html\",\"snippet\":\"In Chapter 4, you'll learn about Rust's ownership system. Chapter 5 discusses structs and methods. Chapter 6 covers enums, match expressions, and the if let...\",\"title\":\"Introduction - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:24:08.393370 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:08.393453 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:08.393757 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:08.393787 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:08.633236 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:08.633336 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:08.633363 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:10.369418 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"link\":\"https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html\",\"snippet\":\"Rust's borrow checker can't understand that we're borrowing different parts of the slice; it only knows that we're borrowing from the same slice twice.\",\"title\":\"Unsafe Rust - The Rust Programming Language\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch17-05-traits-for-async.html\",\"link\":\"https://doc.rust-lang.org/book/ch17-05-traits-for-async.html\",\"snippet\":\"This is exactly what Rust's borrow checker requires: in safe code, it prevents you from moving any item with an active reference to it. Pin builds on that...\",\"title\":\"A Closer Look at the Traits for Async - The Rust Programming ...\"}]", :with_history=>false}
I, [2025-12-10T13:24:10.369465 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:10.369504 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:10.369872 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:10.369922 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:10.606647 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:10.606770 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:10.606797 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:16.671811 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:16.671834 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:16.671866 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:16.672138 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:16.672166 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:16.896582 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:16.896676 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:16.896701 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:18.636470 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://medium.com/.../ownership-who-really-holds-the-power-of-life-and-...\",\"link\":\"https://medium.com/@chenymj23/ownership-who-really-holds-the-power-of-life-and-death-over-values-c559b0527727\",\"snippet\":\"Oct 7, 2024 ... So today, let's return to rationality and tackle the hardest challenge in learning Rust: ownership and lifetimes. ... Additionally, the official...\",\"title\":\"Rust Ownership and Lifetimes Explained: Clear Examples | Medium\"},{\"formattedUrl\":\"https://www.usenix.org/system/files/soups2021-fulton.pdf\",\"link\":\"https://www.usenix.org/system/files/soups2021-fulton.pdf\",\"snippet\":\"developers to use Rust's ownership and lifetimes. Further, we find that much of the cost of adoption occurs up front, while benefits tend to accrue later...\",\"title\":\"Benefits and Drawbacks of Adopting a Secure Programming ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/.../media_is_this_an_accurate_description_of_rust...\",\"link\":\"https://www.reddit.com/r/rust/comments/vkoedz/media_is_this_an_accurate_description_of_rusts/\",\"snippet\":\"Jun 25, 2022 ... ... documentation doesn't call out that they are ... It is possible that Rust's ownership and lifetimes evolved from C++'s move semantics.\",\"title\":\"[Media] Is this an accurate description of Rust's concurrency model ...\"},{\"formattedUrl\":\"https://stackoverflow.com/questions/.../multiple-mutable-references-in-a-loo...\",\"link\":\"https://stackoverflow.com/questions/69545670/multiple-mutable-references-in-a-loop\",\"snippet\":\"Oct 12, 2021 ... I'm trying to learn Rust's ownership and lifetimes in more detail, and I'm very confused by this piece of code: rust. Copy. let mut lst = vec...\",\"title\":\"rust - Multiple mutable references in a loop - Stack Overflow\"},{\"formattedUrl\":\"https://arxiv.org/abs/2401.01114\",\"link\":\"https://arxiv.org/abs/2401.01114\",\"snippet\":\"Jan 2, 2024 ... With due consideration for Rust's ownership and lifetimes, we first complete the pointer analysis. ... Connected Papers (What is Connected Papers?).\",\"title\":\"Static Deadlock Detection for Rust Programs\"},{\"formattedUrl\":\"https://ilyasergey.net/assets/pdf/papers/rem-oopsla23.pdf\",\"link\":\"https://ilyasergey.net/assets/pdf/papers/rem-oopsla23.pdf\",\"snippet\":\"Aug 27, 2023 ... Rust's ownership and lifetimes disciplines, as well as by non-local ... https://code.visualstudio.com/docs/editor/refactoring. Emerson...\",\"title\":\"Adventure of a Lifetime: Extract Method Refactoring for Rust\"},{\"formattedUrl\":\"https://dl.acm.org/doi/abs/10.1145/3758316.3765486\",\"link\":\"https://dl.acm.org/doi/abs/10.1145/3758316.3765486\",\"snippet\":\"Oct 12, 2025 ... In Rust, ownership and lifetimes make automatic extraction ... https://verse-lab.github.io/papers/Sewen-Thy-Capstone.pdf. Google Scholar.\",\"title\":\"Verifying Extract Method Refactoring in Rust | Companion ...\"},{\"formattedUrl\":\"https://www.sigplan.org/OpenTOC/splash-companion25.html\",\"link\":\"https://www.sigplan.org/OpenTOC/splash-companion25.html\",\"snippet\":\"... papers), interviews (23 practitioners), and a global survey (59 ... In Rust, ownership and lifetimes make automatic extraction attractive yet...\",\"title\":\"SPLASH Companion '25: Companion Proceedings of the 2025 ACM ...\"},{\"formattedUrl\":\"https://dl.acm.org/doi/pdf/10.1145/3758316.3765486\",\"link\":\"https://dl.acm.org/doi/pdf/10.1145/3758316.3765486\",\"snippet\":\"Oct 12, 2025 ... In. Rust, ownership and lifetimes make automatic extraction at- ... https://verse-lab.github.io/papers/  Sewen-Thy-Capstone.pdf. [4] Sewen Thy...\",\"title\":\"Verifying Extract Method Refactoring in Rust\"},{\"formattedUrl\":\"https://www.linkedin.com/.../analytics-india-magazine_the-ai-developer-co...\",\"link\":\"https://www.linkedin.com/posts/analytics-india-magazine_the-ai-developer-community-is-shifting-from-activity-7387783722298720256-55UE\",\"snippet\":\"Oct 25, 2025 ... I learned Rust ownership and lifetimes. I understand Nuxt SSR ... Retrieved Information (Semantic Memory) Relevant documents or data fetched via...\",\"title\":\"AI Developers Shift to Context Engineering: Karpathy, Allred ...\"}]", :with_history=>false}
I, [2025-12-10T13:24:18.636511 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:18.636540 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:18.636976 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:18.637015 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:18.889187 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:18.889296 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:18.889321 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:20.742015 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:20.742034 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:20.742067 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:20.742365 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:20.742400 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:20.975332 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:20.975406 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:20.975426 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:22.741951 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0502.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0502.html\",\"snippet\":\"Error code E0502. A variable already borrowed with a certain mutability (either mutable or immutable) was borrowed again with a different mutability.\",\"title\":\"E0502 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0499.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0499.html\",\"snippet\":\"Error code E0499 ... A variable was borrowed as mutable more than once. ... Please note that in Rust, you can either have many immutable references, or one mutable...\",\"title\":\"E0499 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"snippet\":\"A value was moved out while it was still borrowed. Erroneous code example: struct Value {} fn borrow...\",\"title\":\"E0505 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0801.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0801.html\",\"snippet\":\"But it's also possible to use more sophisticated types of self parameter, for instance std::rc::Rc\\u003cSelf\\u003e . The set of allowable Self types is extensible using...\",\"title\":\"E0801 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0025.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0025.html\",\"snippet\":\"Each field of a struct can only be bound once in a pattern. Erroneous code example: struct Foo { a:...\",\"title\":\"E0025 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0666.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0666.html\",\"snippet\":\"Error code E0666. impl Trait types cannot appear nested in the generic arguments of other impl Trait types. Erroneous code example:.\",\"title\":\"E0666 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0074.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0074.html\",\"snippet\":\"This error code is no longer emitted by the compiler. When using the #[simd] attribute on a tuple struct, the components of the tuple struct must all be of a...\",\"title\":\"E0074 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0571.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0571.html\",\"snippet\":\"Error code E0571: A break statement with an argument appeared in a non- loop loop. Example of erroneous code:\",\"title\":\"E0571 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0424.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0424.html\",\"snippet\":\"Error code E0424: The self keyword was used inside of an associated function without a \\\" self receiver\\\" parameter.\",\"title\":\"E0424 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0607.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0607.html\",\"snippet\":\"E0502  E0503  E0504  E0505  E0506  E0507  E0508  E0509  E0510  E0511  E0512  E0514  E0515  E0516  E0517  E0518  E0519  E0520  E0521  E0522...\",\"title\":\"E0607 - Error codes index\"}]", :with_history=>false}
I, [2025-12-10T13:24:22.741977 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:22.742000 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:22.742222 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:22.742247 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:22.987688 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:22.987788 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:22.987812 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:24.935732 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0505.html\",\"snippet\":\"Error code E0505: A value was moved out while it was still borrowed. Erroneous code example: struct Value {} fn borrow(val: \\u0026Value) {} fn eat(val: Value) {} fn...\",\"title\":\"E0505 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0801.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0801.html\",\"snippet\":\"But it's also possible to use more sophisticated types of self parameter, for instance std::rc::Rc\\u003cSelf\\u003e . The set of allowable Self types is extensible using...\",\"title\":\"E0801 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0025.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0025.html\",\"snippet\":\"Each field of a struct can only be bound once in a pattern. Erroneous code example: struct Foo { a:...\",\"title\":\"E0025 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0666.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0666.html\",\"snippet\":\"Error code E0666. impl Trait types cannot appear nested in the generic arguments of other impl Trait types. Erroneous code example:.\",\"title\":\"E0666 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0074.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0074.html\",\"snippet\":\"This error code is no longer emitted by the compiler. When using the #[simd] attribute on a tuple struct, the components of the tuple struct must all be of a...\",\"title\":\"E0074 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0571.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0571.html\",\"snippet\":\"Error code E0571: A break statement with an argument appeared in a non- loop loop. Example of erroneous code:\",\"title\":\"E0571 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0424.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0424.html\",\"snippet\":\"Error code E0424: The self keyword was used inside of an associated function without a \\\" self receiver\\\" parameter.\",\"title\":\"E0424 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0607.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0607.html\",\"snippet\":\"E0505  E0506  E0507  E0508  E0509  E0510  E0511  E0512  E0514  E0515  E0516  E0517  E0518  E0519  E0520  E0521  E0522  E0523  E0524  E0525...\",\"title\":\"E0607 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0804.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0804.html\",\"snippet\":\"Error code E0804: An auto trait cannot be added to the bounds of a dyn Trait type via a pointer cast.\",\"title\":\"E0804 - Error codes index\"},{\"formattedUrl\":\"https://doc.rust-lang.org/error_codes/E0221.html\",\"link\":\"https://doc.rust-lang.org/error_codes/E0221.html\",\"snippet\":\"E0505  E0506  E0507  E0508  E0509  E0510  E0511  E0512  E0514  E0515  E0516  E0517  E0518  E0519  E0520  E0521  E0522  E0523  E0524  E0525...\",\"title\":\"E0221 - Error codes index\"}]", :with_history=>false}
I, [2025-12-10T13:24:24.935804 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:24.935844 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:24.936212 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:24.936257 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:25.187588 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:25.187704 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:25.187730 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:26.918549 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:26.918565 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:26.918589 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:26.918838 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:26.918876 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:27.159082 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:27.159183 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:27.159210 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:28.922569 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:28.922692 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:28.922731 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:28.922947 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:28.922972 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:29.170818 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:29.170881 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:29.170896 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:30.923721 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:30.923746 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:30.923789 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:30.924177 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:30.924230 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:31.167494 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:31.167597 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:31.167623 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:32.788909 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:32.788924 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:32.788947 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:32.789199 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:32.789226 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:33.040846 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:33.040914 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:33.040932 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:34.757528 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:34.757609 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:34.757646 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:34.757919 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:34.757948 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:35.002877 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:35.002946 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:35.002961 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:36.846557 #24997]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:24:36.846575 #24997]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:24:36.846600 #24997]  INFO -- : Use template get_topic
I, [2025-12-10T13:24:36.846829 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:36.846860 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:37.090388 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:37.090454 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:37.090471 #24997]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:24:37.091654 #24997]  INFO -- : Calling worker: summary with params: {:text=>"Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:24:37.091677 #24997]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:24:37.091686 #24997]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:24:37.091696 #24997]  INFO -- : Create Conversation
I, [2025-12-10T13:24:37.091715 #24997]  INFO -- : Use template summarize
I, [2025-12-10T13:24:37.091931 #24997]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:24:37.091954 #24997]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:24:50.422642 #24997]  INFO -- : Successful send a message
I, [2025-12-10T13:24:50.422776 #24997]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:24:50.422820 #24997]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:28:02.380777 #26359]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:28:02.381391 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381459 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381472 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381482 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381487 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381494 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381499 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381525 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381530 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381537 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381542 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381549 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381553 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381565 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381577 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381586 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.381591 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.381600 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.515428 #26359]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:28:02.515491 #26359]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:28:02.516081 #26359]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:28:02.516131 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516155 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516161 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516169 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516173 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516179 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516184 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516208 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516213 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516220 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516224 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516230 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516234 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516246 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516250 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516260 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516265 #26359]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:02.516275 #26359]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:02.516557 #26359]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:28:02.516592 #26359]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:28:05.072166 #26359]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"Go", :with_history=>true}
I, [2025-12-10T13:28:05.072183 #26359]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:28:05.072193 #26359]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:28:05.072208 #26359]  INFO -- : Create Conversation
I, [2025-12-10T13:28:05.072238 #26359]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:28:05.072572 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:05.072604 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:21.343027 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:21.343144 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:21.343176 #26359]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:28:21.945767 #26359]  INFO -- : Calling worker: pre_search with params: {:text=>" **Go** \n\n---\n\n### **1. **  \n ****  \n\n- ****  \n  Go****goroutinechannelselect  \n  ****  \n  GoGo vs JavaGo\n\n---\n\n### **2. **  \n|  |  |\n|------|------|\n| ** vs ** | **** |\n| -  | GoGMP |\n| **** | ****2020 |\n| -  | Gowork-stealing1.14+Go 1.0 |\n| **** | **** |\n| -  | golang.orgGoRob PikeRuss CoxACM/IEEEGoThe Go Programming Language |\n\n---\n\n### **3. **  \n\n#### ****  \n- `Go `  \n- `Go goroutine`  \n- `Go channel`  \n- `Go GMP model`  \n- `Go concurrency design`  \n- `Go memory model`\n\n#### ****  \n- ` vs `  \n- ``  \n- ``  \n- `CSP`Communicating Sequential ProcessesGo  \n- ``  \n- `runtime.GOMAXPROCS`  \n- `select`\n\n#### ****  \n```plaintext\n# \n\"Go concurrency model\" site:golang.org  \n\"goroutine scheduling\" site:blog.golang.org  \n\"Go memory model\" filetype:pdf  \n\"Go GMP model\" intitle:\"design\"  \n\"Go CSP model\" site:arxiv.org  \n\"Go concurrency performance\" after:2020  \n```\n\n#### ****  \n- ``````  \n- ````  \n- `Python``Java`  \n- `web``API`\n\n---\n\n### **4. **  \n\n#### ****  \n- ****  \n  - [https://go.dev/doc/](https://go.dev/doc/)  Concurrency   \n  - [https://blog.golang.org/](https://blog.golang.org/)   concurrency, goroutines, scheduler  \n  - Go Concurrency PatternsRob PikeThe Go Memory Model  \n\n- ****  \n  - The Go Programming LanguageAlan A. A. Donovan & Brian W. Kernighan8  \n  - Go in Action5  \n\n- **/**  \n  - ACM Digital Library Go concurrency model + runtime  \n  - *Gos Concurrency Primitives: A Practical Overview*  \n\n#### ****  \n- ****  \n  - YouTube `\"Russ Cox Go concurrency\"``\"Rob Pike goroutines\"`  \n- **Go**  \n  - GitHub: `golang/go/src/runtime/proc.go`  \n- ****  \n  - MediumDev.toHacker News Go  \n\n#### ****  \n|  |  |  |\n|------|------|----------|\n| **** | goroutine= | concurrency vs parallelism |\n| **** | 2015goroutine | 2020+Go 1.14+ |\n| **** | channelCSP | CSPGMP |\n| **** |  |  |\n\n---\n\n###  ****  \n1. **** [https://go.dev/doc/effective_go#concurrency](https://go.dev/doc/effective_go#concurrency)  \n2. **** [blog.golang.org](https://blog.golang.org/)  goroutine scheduler  memory model  \n3. ****The Go Programming Language8PDF  \n4. **** arXiv  ACM   \n5. **** Rob Pike 2012Concurrency is not ParallelismYouTube  \n\n>  ****Go****\n\n--- \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:28:21.945895 #26359]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:28:21.945911 #26359]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:28:21.945925 #26359]  INFO -- : Create Conversation
I, [2025-12-10T13:28:21.945983 #26359]  INFO -- : Use template pre_search
I, [2025-12-10T13:28:21.946648 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:21.946692 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:24.118553 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:24.118644 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:24.118661 #26359]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:28:25.934226 #26359]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://blog.golang.org/advanced-go-concurrency-patterns\",\"link\":\"https://blog.golang.org/advanced-go-concurrency-patterns\",\"snippet\":\"May 23, 2013 ... At Google I/O a year ago Rob Pike presented Go Concurrency Patterns, an introduction to Go's concurrency model. Last week, at I/O 2013, Go...\",\"title\":\"Advanced Go Concurrency Patterns - The Go Programming Language\"},{\"formattedUrl\":\"https://tip.golang.org/solutions/webdev\",\"link\":\"https://tip.golang.org/solutions/webdev\",\"snippet\":\"Oct 4, 2019 ... In particular, Go's concurrency model makes it absurdly easy to build performant I/O-bound applications. Building a new router for gov.uk...\",\"title\":\"Go for Web Development - The Go Programming Language\"},{\"formattedUrl\":\"https://blog.golang.org/a-conversation-with-the-go-team\",\"link\":\"https://blog.golang.org/a-conversation-with-the-go-team\",\"snippet\":\"Jun 6, 2013 ... The landscape has changed a lot but I think Go's concurrency model has much to offer in the field of interactive graphics. Andrew: There are...\",\"title\":\"A conversation with the Go team - The Go Programming Language\"},{\"formattedUrl\":\"https://tip.golang.org/wiki/Learn\",\"link\":\"https://tip.golang.org/wiki/Learn\",\"snippet\":\"Go Wiki: Learn  LearnConcurrency outlines a course of study of Go's concurrency model and patterns.  LearnErrorHandling links to resources about error handling...\",\"title\":\"Go Wiki: Learn - The Go Programming Language\"},{\"formattedUrl\":\"https://golang.org/issue/21165\",\"link\":\"https://golang.org/issue/21165\",\"snippet\":\"Jul 25, 2017 ... sync.Cond makes emulating pthreads simple. Agreed, but is pthread really a good example for Go's concurrency model to emulate?\",\"title\":\"proposal: sync: remove the Cond type  Issue #21165  golang/go\"}]", :with_history=>false}
I, [2025-12-10T13:28:25.934332 #26359]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:28:25.934342 #26359]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:28:25.934356 #26359]  INFO -- : Create Conversation
I, [2025-12-10T13:28:25.934381 #26359]  INFO -- : Use template get_topic
I, [2025-12-10T13:28:25.934637 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:25.934666 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:26.171435 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:26.171503 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:26.171524 #26359]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:28:27.964436 #26359]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://blog.golang.org/go-11-is-released\",\"link\":\"https://blog.golang.org/go-11-is-released\",\"snippet\":\"May 13, 2013 ... We have made optimizations in the compiler and linker, garbage collector, goroutine scheduler, map implementation, and parts of the standard...\",\"title\":\"Go 1.1 is released - The Go Programming Language\"},{\"formattedUrl\":\"https://blog.golang.org/gccgo-in-gcc-471\",\"link\":\"https://blog.golang.org/gccgo-in-gcc-471\",\"snippet\":\"Jul 11, 2012 ... Many of the core features of the Go runtime are the same in both gccgo and gc, including the goroutine scheduler, channels, the memory allocator...\",\"title\":\"Gccgo in GCC 4.7.1 - The Go Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:28:27.964454 #26359]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:28:27.964550 #26359]  INFO -- : Use template get_topic
I, [2025-12-10T13:28:27.964801 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:27.964835 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:28.196525 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:28.196602 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:28.196625 #26359]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:28:30.012077 #26359]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"http://nil.csail.mit.edu/6.824/2016/notes/gomem.pdf\",\"link\":\"http://nil.csail.mit.edu/6.824/2016/notes/gomem.pdf\",\"snippet\":\"Feb 25, 2016 ... Go Memory Model? Page 64. Go Memory Model. Two purposes:  Make guarantees for programmers.  Allow compilers/hardware to make certain...\",\"title\":\"Go's Memory Model\"},{\"formattedUrl\":\"https://research.swtch.com/gomm.pdf\",\"link\":\"https://research.swtch.com/gomm.pdf\",\"snippet\":\"Jul 12, 2021 ... Go's memory model begins with the following advice, consistent with Go's over- all philosophy: Programs that modify data being simultaneously...\",\"title\":\"Updating the Go Memory Model\"},{\"formattedUrl\":\"https://people.csail.mit.edu/nickolai/papers/chajed-goose-coqpl.pdf\",\"link\":\"https://people.csail.mit.edu/nickolai/papers/chajed-goose-coqpl.pdf\",\"snippet\":\"Jan 25, 2020 ... The Go memory model, May 2014. URL https://golang.org/ref/  mem. [3] R. Krebbers, R. Jung, A. Bizjak, J.-H. Jourdan, D. Dreyer, and L...\",\"title\":\"Verifying concurrent Go code in Coq with Goose\"},{\"formattedUrl\":\"https://dfava.github.io/thesis/dfava_thesis.pdf\",\"link\":\"https://dfava.github.io/thesis/dfava_thesis.pdf\",\"snippet\":\"Go's memory model [40], however, is described, albeit succinctly and precisely, in prose. We provide a formal semantics instead. The main contributions of...\",\"title\":\"Relaxed Memory Models and Data-Race Detection tailored for ...\"},{\"formattedUrl\":\"https://www.sjsu.edu/people/robert.chun/courses/cs159/s3/S.pdf\",\"link\":\"https://www.sjsu.edu/people/robert.chun/courses/cs159/s3/S.pdf\",\"snippet\":\"the mantra of Go's memory model is: Do not communicate by sharing memory; instead, share memory by communicating.[3]. This paper will compare different...\",\"title\":\"A Language Comparison Between Parallel Programming Features ...\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2004.12859\",\"link\":\"https://arxiv.org/pdf/2004.12859\",\"snippet\":\"Nov 18, 2021 ... The Go memory model [15] defines the behaviour of memory access in Go as a happens- before relation by a combination of shared memory and...\",\"title\":\"Static Race Detection and Mutex Safety and Liveness for Go ...\"},{\"formattedUrl\":\"https://uwspace.uwaterloo.ca/bitstreams/b7bb2925-6bd6-49ab.../download\",\"link\":\"https://uwspace.uwaterloo.ca/bitstreams/b7bb2925-6bd6-49ab-a9b3-bc7581139529/download\",\"snippet\":\"This allows communication to a specific actor by sending message to its unique channel. 2.2.2 Memory Model. The key features of Go's memory model, as relating...\",\"title\":\"GoA: Actors with Locally Managed Memory for Go\"},{\"formattedUrl\":\"https://arxiv.org/pdf/2105.11064\",\"link\":\"https://arxiv.org/pdf/2105.11064\",\"snippet\":\"[10] (2014): The Go Memory Model. Available at https://golang.org/ref/mem. [11] Ivan Beschastnikh, Patty Wang, Yuriy Brun \\u0026 Michael D. Ernst (2016):...\",\"title\":\"Automated Dynamic Concurrency Analysis for Go\"},{\"formattedUrl\":\"https://engineering.getweave.com/talk/gba...in.../go_users_group_slides.pdf\",\"link\":\"https://engineering.getweave.com/talk/gba-games-in-go/go_users_group_slides.pdf\",\"snippet\":\" The Go Memory Model does not like to share memory.  Do not communicate by sharing memory; instead, share memory by communicating. (Effective Go).\",\"title\":\"GBA Gaming with Go\"},{\"formattedUrl\":\"https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/blc2.12024\",\"link\":\"https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/blc2.12024\",\"snippet\":\"Jan 23, 2023 ... The Go memory model. [14] is a weak memory model that specifies the ... Fava, D.: Finding and fixing a mismatch between the GO memory model.\",\"title\":\"An executable formal semantics of Go language in K framework\"}]", :with_history=>false}
I, [2025-12-10T13:28:30.012134 #26359]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:28:30.012182 #26359]  INFO -- : Use template get_topic
I, [2025-12-10T13:28:30.012615 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:30.012675 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:30.261960 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:30.262043 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:30.262061 #26359]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:28:31.880073 #26359]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:28:31.880144 #26359]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:28:31.880174 #26359]  INFO -- : Use template get_topic
I, [2025-12-10T13:28:31.880403 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:31.880427 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:32.119020 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:32.119101 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:32.119121 #26359]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:28:34.761478 #26359]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:28:34.761581 #26359]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:28:34.761624 #26359]  INFO -- : Use template get_topic
I, [2025-12-10T13:28:34.761916 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:34.761950 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:35.007826 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:35.007899 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:35.007929 #26359]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:28:35.009015 #26359]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:28:35.009031 #26359]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:28:35.009037 #26359]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:28:35.009046 #26359]  INFO -- : Create Conversation
I, [2025-12-10T13:28:35.009065 #26359]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:28:35.009324 #26359]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:35.009351 #26359]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:35.660224 #26359]  INFO -- : Successful send a message
I, [2025-12-10T13:28:35.660304 #26359]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:35.660320 #26359]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:28:44.528264 #26655]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:28:44.528349 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528384 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528390 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528398 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528402 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528409 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528412 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528449 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528453 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528471 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528475 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528482 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528486 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528497 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528501 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528511 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.528514 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.528524 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.603907 #26655]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:28:44.604213 #26655]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:28:44.604823 #26655]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:28:44.604893 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.604915 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.604921 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.604928 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.604932 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.604938 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.604942 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.605003 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.605022 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.605034 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.605040 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.605047 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.605052 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.605101 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.605118 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.605135 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.605141 #26655]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:28:44.605153 #26655]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:28:44.605618 #26655]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:28:44.605648 #26655]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:28:47.158951 #26655]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-10T13:28:47.158959 #26655]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:28:47.158967 #26655]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:28:47.158978 #26655]  INFO -- : Create Conversation
I, [2025-12-10T13:28:47.159004 #26655]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:28:47.159407 #26655]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:47.159442 #26655]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:28:57.128283 #26655]  INFO -- : Successful send a message
I, [2025-12-10T13:28:57.128367 #26655]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:28:57.128385 #26655]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:28:57.730686 #26655]  INFO -- : Calling worker: pre_search with params: {:text=>"\n\n---\n\n### **1. **  \n**/**  \n\n- \n- ****\n- ****\n\n---\n\n### **2. **  \n- ****    \n- ****    \n- ****    \n- ****  \n\n>  ********\n\n---\n\n### **3. **  \n- ****  \n  \n\n- ****  \n    \n  -   \n  - AI   \n  -   \n  ****\n\n- ****  \n   `site:`, `filetype:`, `intitle:`   \n    \n  ```  \n  \"\" site:stackoverflow.com  \n  ```  \n  \n\n- ****  \n    \n  `- -`\n\n---\n\n### **4. **  \n- ****  \n   ****\n\n- ****  \n  -   \n      \n  - ********\n\n- ****  \n  - ****  \n  - ****  \n  - ****\n\n---\n\n### ****  \n|  |  |  |\n|------|------|----------|\n|  | / |  |\n|  |  |  |\n|  |  |  |\n|  |  | **** |\n|  |  | **** |\n\n>  ****  \n>  2024\n\n---\n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:28:57.730932 #26655]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:28:57.730960 #26655]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:28:57.730976 #26655]  INFO -- : Create Conversation
I, [2025-12-10T13:28:57.731016 #26655]  INFO -- : Use template pre_search
I, [2025-12-10T13:28:57.731507 #26655]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:28:57.731553 #26655]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:29:00.576921 #26655]  INFO -- : Successful send a message
I, [2025-12-10T13:29:00.577029 #26655]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:29:00.577050 #26655]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:29:01.179775 #26655]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1  \n  - []   \n\n- 2  \n  - []   \n\n- 3  \n  - []   \n\n- 4  \n  - []   \n\n---\n\n### ****  \n********  \n\n****  \n>  2025AI  \n\n", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:29:01.179877 #26655]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:29:01.179891 #26655]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:29:01.179902 #26655]  INFO -- : Create Conversation
I, [2025-12-10T13:29:01.179926 #26655]  INFO -- : Use template smart_search
I, [2025-12-10T13:29:01.180172 #26655]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:29:01.180203 #26655]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:29:01.931724 #26655]  INFO -- : Successful send a message
I, [2025-12-10T13:29:01.931830 #26655]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:29:01.931852 #26655]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:29:01.932234 #26655]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:29:01.932260 #26655]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:29:01.932271 #26655]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:29:01.932281 #26655]  INFO -- : Create Conversation
I, [2025-12-10T13:29:01.932303 #26655]  INFO -- : Use template summarize
I, [2025-12-10T13:29:01.932561 #26655]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:29:01.932592 #26655]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:29:09.212160 #26655]  INFO -- : Successful send a message
I, [2025-12-10T13:29:09.212290 #26655]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:29:09.212313 #26655]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:29:52.493575 #27051]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:29:52.493655 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493689 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493696 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493706 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493711 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493718 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493723 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493751 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493756 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493776 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493780 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493787 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493791 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493803 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493807 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493816 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.493820 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.493830 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561019 #27051]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:29:52.561079 #27051]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:29:52.561577 #27051]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:29:52.561616 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561635 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561640 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561647 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561651 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561656 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561660 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561681 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561685 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561691 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561695 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561700 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561704 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561713 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561718 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561726 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561730 #27051]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:29:52.561739 #27051]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:29:52.561994 #27051]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:29:52.562019 #27051]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:29:54.770661 #27051]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>" Rust ", :with_history=>true}
I, [2025-12-10T13:29:54.770670 #27051]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:29:54.770677 #27051]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:29:54.770689 #27051]  INFO -- : Create Conversation
I, [2025-12-10T13:29:54.770716 #27051]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:29:54.771038 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:29:54.771065 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:09.225554 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:09.225670 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:09.225693 #27051]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:30:09.829531 #27051]  INFO -- : Calling worker: pre_search with params: {:text=>" ** Rust ** \n\n---\n\n### **1. **  \n ****  \n\n- ****  \n- Rust ****  \n- \n\n>  ******** Rust \n\n---\n\n### **2. **  \n\n|  |  |\n|------|------|\n| ** vs ** | **** Rust  |\n| **** | ****Rust  2015  2024+  |\n| **** | ****Rust  Rust BookRust RFC |\n\n>  ** + **\n\n---\n\n### **3. **  \n\n#### ****  \n- `Rust `  \n- `Rust lifetime`  \n- `Rust lifetime explanation`  \n\n#### ****  \n- `Rust borrow checker`  \n- `Rust ownership`  \n- `Rust lifetime annotations`  \n- `Rust lifetime elision`  \n\n#### ****  \n```plaintext\n\"Rust lifetime\" site:doc.rust-lang.org  \n\"Rust lifetime\" intitle:\"book\"  \n\"Rust lifetime\" filetype:pdf  \n\"Rust lifetime\" -intitle:video -intitle:youtube  \n```\n\n>   `site:doc.rust-lang.org` Rust Programming LanguageRust Book  \n>   `intitle:\"book\"`   \n>  /YouTube \n\n#### ****  \n- `-interview` `-forum` `-stackoverflow`  \n- `-advanced` `-complex`  \n- `-comparison` `-vs` C++/Go \n\n---\n\n### **4. **  \n\n#### ****  \n- ** Rust Book**https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html  \n  -   \n- **Rust Lifetime Annotations**  \n  -  `<'a>`   \n\n#### ****  \n- **Rust by Example**  \n- **The Rust Programming Language (O'Reilly )**/  \n- **Rust  r/rust**  \n\n#### ****  \n|  |  |  |\n|------|------|----------|\n| **** |  |  |\n| **** |  |  `Rust ownership lifetime`  |\n| **** | lifetime vs lifetimes vs borrowing |  `\"Rust lifetime\"` |\n| **** |  | Rust  |\n\n---\n\n###  ****\n\n1. ****  \n   ```  \n   \"Rust lifetime\" site:doc.rust-lang.org  \n   ```  \n    Rust Book10\n\n2. ****  \n   -  `Rust lifetime elision`   \n   -  `Rust ownership lifetime`   \n\n3. ****  \n   - Stack Overflow   \n   -   \n   -   \n\n4. ****  \n    +  + \n\n--- \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:30:09.829654 #27051]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:30:09.829669 #27051]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:30:09.829680 #27051]  INFO -- : Create Conversation
I, [2025-12-10T13:30:09.829709 #27051]  INFO -- : Use template pre_search
I, [2025-12-10T13:30:09.830161 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:09.830194 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:11.183309 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:11.183401 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:11.183421 #27051]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:30:12.916820 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/rustc/symbol-mangling/v0.html\",\"link\":\"https://doc.rust-lang.org/rustc/symbol-mangling/v0.html\",\"snippet\":\"A lifetime may be displayed like a Rust lifetime using a single quote. Index 0 should be displayed as '_ . Index 0 should not be displayed for lifetimes in...\",\"title\":\"v0 Symbol Format - The rustc book\"}]", :with_history=>false}
I, [2025-12-10T13:30:12.916838 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:12.916847 #27051]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:30:12.916861 #27051]  INFO -- : Create Conversation
I, [2025-12-10T13:30:12.916885 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:12.917160 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:12.917191 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:13.178409 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:13.178491 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:13.178517 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:14.977517 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://medium.com/.../understanding-rust-ownership-borrowing-lifetimes-f...\",\"link\":\"https://medium.com/@bugaevc/understanding-rust-ownership-borrowing-lifetimes-ff9ee9f79a9c\",\"snippet\":\"May 2, 2016 ... Understanding Rust: ownership, borrowing, lifetimes Here's my take on describing these things. Once you grasp it, it all seems intuitively...\",\"title\":\"Understanding Rust: ownership, borrowing, lifetimes | by Sergey ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../why_does_rust_need_humans_to_tell_it_...\",\"link\":\"https://www.reddit.com/r/rust/comments/134jqhv/why_does_rust_need_humans_to_tell_it_how_long_a/\",\"snippet\":\"May 1, 2023 ... Is it related to Rust using an ownership model instead of garbage collection like other languages? ... lifetime relationship between the argument.\",\"title\":\"Why does Rust need humans to tell it how long a variable's lifetime is?\"},{\"formattedUrl\":\"https://www.integralist.co.uk/posts/rust-ownership/\",\"link\":\"https://www.integralist.co.uk/posts/rust-ownership/\",\"snippet\":\"Rust Ownership, Borrowing, and Lifetimes. TOC ... A few months ago I started working for Fastly as a Staff Software Engineer in their Developer Relations...\",\"title\":\"Rust Ownership, Borrowing, and Lifetimes\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../question_about_the_relationship_between...\",\"link\":\"https://www.reddit.com/r/rust/comments/smbfbs/question_about_the_relationship_between_str_and/\",\"snippet\":\"Feb 7, 2022 ... How does ownership of the char work then? If a char is pointing to ... Here both the iterator and items have a lifetime parameter that borrows the...\",\"title\":\"Question about the relationship between str and char : r/rust\"},{\"formattedUrl\":\"https://rainingcomputers.blog/.../the_intuition_behind_rusts_borrowing_rul...\",\"link\":\"https://rainingcomputers.blog/dist/the_intuition_behind_rusts_borrowing_rules_and_ownership.md\",\"snippet\":\"Aug 14, 2023 ... ... relationship between the lifetimes of input borrowers and the lifetime of output returned borrower. ... The key take away here is that Rust allows...\",\"title\":\"The intuition behind Rust's borrowing rules and ownership\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"link\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"snippet\":\"Rust requires us to annotate the relationships using generic lifetime parameters to ensure the actual references used at runtime will definitely be valid.\",\"title\":\"Validating References with Lifetimes - The Rust Programming ...\"},{\"formattedUrl\":\"https://earthly.dev/blog/rust-lifetimes-ownership-burrowing/\",\"link\":\"https://earthly.dev/blog/rust-lifetimes-ownership-burrowing/\",\"snippet\":\"Aug 28, 2023 ... Lifetime subtyping is a concept that allows lifetimes to be compared and ordered based on their relationship to one another. This can be useful...\",\"title\":\"Rust Lifetimes: A Complete Guide to Ownership and Borrowing ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/what-is...relationship...a...lifetime.../88485\",\"link\":\"https://users.rust-lang.org/t/what-is-the-relationship-between-the-value-of-a-struct-and-the-lifetime-in-reference-field/88485\",\"snippet\":\"Jan 31, 2023 ... ... ownership of that vector. To do so ... FYI rust-blog/common-rust-lifetime-misconceptions.md at master  pretzelhammer/rust-blog  GitHub.\",\"title\":\"What is the relationship between the value of a struct and the lifetime ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/subtyping.html\",\"link\":\"https://doc.rust-lang.org/nomicon/subtyping.html\",\"snippet\":\"Rust uses lifetimes to track the relationships between borrows and ownership. ... lifetimes, we need to define the requirement of a lifetime: 'a defines a...\",\"title\":\"Subtyping and Variance - The Rustonomicon\"},{\"formattedUrl\":\"https://web.mit.edu/rust-lang.../rust/.../ch19-02-advanced-lifetimes.html\",\"link\":\"https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/book/second-edition/ch19-02-advanced-lifetimes.html\",\"snippet\":\"Both the Parser we're creating and the context parameter go out of scope at the end of the function, though (because parse_context takes ownership of context ).\",\"title\":\"Advanced Lifetimes - The Rust Programming Language\"}]", :with_history=>false}
I, [2025-12-10T13:30:14.977588 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:14.977622 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:14.977901 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:14.977934 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:15.235843 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:15.235920 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:15.235936 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:17.067366 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/lifetime-elision.html\",\"link\":\"https://doc.rust-lang.org/nomicon/lifetime-elision.html\",\"snippet\":\"In order to make common patterns more ergonomic, Rust allows lifetimes to be elided in function signatures. ... Elision rules are as follows: Each elided lifetime...\",\"title\":\"Lifetime Elision - The Rustonomicon\"},{\"formattedUrl\":\"https://stackoverflow.com/.../what-is-lifetime-elision-in-very-simple-terms\",\"link\":\"https://stackoverflow.com/questions/40325690/what-is-lifetime-elision-in-very-simple-terms\",\"snippet\":\"Oct 30, 2016 ... Lifetime elision is concerned solely with inferring lifetime parameters using three easily memorizable and unambiguous rules.\",\"title\":\"rust - What is lifetime elision in very simple terms? - Stack Overflow\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/lifetime-elision.html\",\"link\":\"https://doc.rust-lang.org/reference/lifetime-elision.html\",\"snippet\":\"Rust has rules that allow lifetimes to be elided in various places where the compiler can infer a sensible default choice.\",\"title\":\"Lifetime elision - The Rust Reference\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/a-better-lifetime-elision-rules/131106\",\"link\":\"https://users.rust-lang.org/t/a-better-lifetime-elision-rules/131106\",\"snippet\":\"Jun 25, 2025 ... A Better Lifetime Elision Rules?  Each variable has its own lifetime.  The lifetime is from the definition of the variable untill is last (...\",\"title\":\"A Better Lifetime Elision Rules? - The Rust Programming Language ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../why_cant_lifetimes_be_elided_from_struct...\",\"link\":\"https://www.reddit.com/r/rust/comments/isgjkj/why_cant_lifetimes_be_elided_from_structs/\",\"snippet\":\"Sep 14, 2020 ... Originally nothing was elided, then it was decided to elide lifetimes in function signatures according to the rules we now take for granted. At...\",\"title\":\"Why can't lifetimes be elided from structs containing references? : r/rust\"},{\"formattedUrl\":\"https://www.ntietz.com/blog/confusing-rust-lifetime-elision/\",\"link\":\"https://www.ntietz.com/blog/confusing-rust-lifetime-elision/\",\"snippet\":\"Jan 2, 2023 ... A confusing lifetime error related to Rust's lifetime elision ... lifetime elision rules, which we'll get to. For now, though, let's...\",\"title\":\"A confusing lifetime error related to Rust's lifetime elision | nicole@web\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/comments/1ee3t1a/lifetime_elision/\",\"link\":\"https://www.reddit.com/r/rust/comments/1ee3t1a/lifetime_elision/\",\"snippet\":\"Jul 28, 2024 ... ... lifetime annotations and the existing elision rules don't apply? Surely, similar cases come up a lot, so given Rust's presumed \\\"implicit...\",\"title\":\"Lifetime Elision : r/rust\"},{\"formattedUrl\":\"https://internals.rust-lang.org/t/why-does-rust-require...lifetimes/22598\",\"link\":\"https://internals.rust-lang.org/t/why-does-rust-require-explicit-lifetimes/22598\",\"snippet\":\"Mar 19, 2025 ... ... Rust already has a lifetime elision rule to handle this. But for ... lifetime parameters equal  written as replacing elided lifetimes with non-...\",\"title\":\"Why does Rust require explicit lifetimes? - language design - Rust ...\"},{\"formattedUrl\":\"https://www.reddit.com/.../rust/.../in_theory_could_the_rust_compiler_auto...\",\"link\":\"https://www.reddit.com/r/rust/comments/sd3r01/in_theory_could_the_rust_compiler_automatically/\",\"snippet\":\"Jan 26, 2022 ... The patterns programmed into Rust's analysis of references are called the lifetime elision rules. These aren't rules for programmers to...\",\"title\":\"In theory, could the Rust compiler automatically infer lifetimes in ...\"},{\"formattedUrl\":\"https://medium.com/.../how-i-think-about-rust-lifetimes-83a726aaa846\",\"link\":\"https://medium.com/@ericdreichert/how-i-think-about-rust-lifetimes-83a726aaa846\",\"snippet\":\"Apr 9, 2016 ... ... lifetime elision rules. It points out that if you add an explicit lifetime parameter to a function, the compiler will add another, distinct...\",\"title\":\"How I think about Rust Lifetimes. I was refactoring code a few weeks ...\"}]", :with_history=>false}
I, [2025-12-10T13:30:17.067408 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:17.067433 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:17.067710 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:17.067739 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:17.336373 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:17.336481 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:17.336506 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:17.404604 #27051]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:30:17.404629 #27051]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:30:17.404637 #27051]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:30:17.404646 #27051]  INFO -- : Create Conversation
I, [2025-12-10T13:30:17.404664 #27051]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:30:17.404917 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:17.404942 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:30.202255 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:30.202372 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:30.202393 #27051]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:30:30.804429 #27051]  INFO -- : Calling worker: smart_search with params: {:text=>"- \n  - [] Rust\n  - [] Rustonomiconlifetime elision\n  - [] ownershiplifetime\n  - [] RustRustonomicon\n  - [] Rust lifetime official definition `doc.rust-lang.org`\n\n- \n  - [] `doc.rust-lang.org` Rust\n  - [] `rust-lang/reference`  `rust-lang/nomicon` \n  - [] Stack OverflowRedditMedium\n\n- \n  - [] \n    - `\"Rust lifetime\" site:doc.rust-lang.org/book`\n    - `\"lifetime elision\" site:doc.rust-lang.org/nomicon`\n    - `\"Rust ownership lifetime relationship\" site:doc.rust-lang.org`\n  - [] \n    - `\"how does Rust lifetime work in simple terms\"`\n    - `\"why do we need lifetime annotations in Rust\"`\n    - `\"Rust lifetime rules for functions\"`\n  - [] Rust\n  - [] \n    -  `site:`  `doc.rust-lang.org` \n    -  `intitle:\"book\"`  `intitle:\"nomicon\"` \n    -  `filetype:html` PDF\n    -  `-` \n\n- \n  - [] \n    1. `\"Rust lifetime\" site:doc.rust-lang.org/book`  Rust Book10\n    2. `\"lifetime elision\" site:doc.rust-lang.org/nomicon`  \n    3. `\"Rust ownership lifetime relationship\" site:doc.rust-lang.org`  `site:doc.rust-lang.org/reference lifetime`\n  - [] RFC\n  - [] \n    -  `doc.rust-lang.org` \n    - \n    - \n  - [] \n    - \n    - \n\n- \n  - []   53 > 1 > 1\n  - [] \n    - \n    - `'a`\n    - \n    - borrow checker\n  - [] \n    - The Rust Programming Language10\n    - The RustonomiconLifetime Elision\n    - Rust ReferenceLifetime Elision\n    -  Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:30:30.804596 #27051]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:30:30.804616 #27051]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:30:30.804630 #27051]  INFO -- : Create Conversation
I, [2025-12-10T13:30:30.804659 #27051]  INFO -- : Use template smart_search
I, [2025-12-10T13:30:30.804959 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:30.805009 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:32.888592 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:32.888659 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:32.888673 #27051]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:30:34.643676 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:30:34.643704 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:34.643852 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:34.644209 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:34.644260 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:34.913204 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:34.913297 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:34.913322 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:36.623188 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/lifetime-elision.html\",\"link\":\"https://doc.rust-lang.org/nomicon/lifetime-elision.html\",\"snippet\":\"Lifetime Elision  For fn definitions, fn types, and the traits Fn , FnMut , and FnOnce , input refers to the types of the formal arguments, while output refers...\",\"title\":\"Lifetime Elision - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/unbounded-lifetimes.html\",\"link\":\"https://doc.rust-lang.org/nomicon/unbounded-lifetimes.html\",\"snippet\":\"The easiest way to avoid unbounded lifetimes is to use lifetime elision at the function boundary. If an output lifetime is elided, then it must be bounded...\",\"title\":\"Unbounded Lifetimes - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/lifetimes.html\",\"link\":\"https://doc.rust-lang.org/nomicon/lifetimes.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Lifetimes - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/lifetime-mismatch.html\",\"link\":\"https://doc.rust-lang.org/nomicon/lifetime-mismatch.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Limits of Lifetimes - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/subtyping.html\",\"link\":\"https://doc.rust-lang.org/nomicon/subtyping.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Subtyping and Variance - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/hrtb.html\",\"link\":\"https://doc.rust-lang.org/nomicon/hrtb.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Higher-Rank Trait Bounds - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/transmutes.html\",\"link\":\"https://doc.rust-lang.org/nomicon/transmutes.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Transmutes - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/phantom-data.html\",\"link\":\"https://doc.rust-lang.org/nomicon/phantom-data.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"PhantomData - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/send-and-sync.html\",\"link\":\"https://doc.rust-lang.org/nomicon/send-and-sync.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Send and Sync - The Rustonomicon\"},{\"formattedUrl\":\"https://doc.rust-lang.org/nomicon/ownership.html\",\"link\":\"https://doc.rust-lang.org/nomicon/ownership.html\",\"snippet\":\"Lifetime Elision  3.6. Unbounded Lifetimes  3.7. Higher-Rank Trait Bounds  3.8. Subtyping and Variance  3.9. Drop Check  3.10. PhantomData  3.11.\",\"title\":\"Ownership - The Rustonomicon\"}]", :with_history=>false}
I, [2025-12-10T13:30:36.623229 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:36.623258 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:36.623555 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:36.623587 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:36.885385 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:36.885495 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:36.885516 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:38.605345 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:30:38.605374 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:38.605398 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:38.605685 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:38.605714 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:38.873109 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:38.873248 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:38.873285 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:40.949360 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/reference/lifetime-elision.html\",\"link\":\"https://doc.rust-lang.org/reference/lifetime-elision.html\",\"snippet\":\"Rust has rules that allow lifetimes to be elided in various places where the compiler can infer a sensible default choice.\",\"title\":\"Lifetime elision - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/items/constant-items.html\",\"link\":\"https://doc.rust-lang.org/reference/items/constant-items.html\",\"snippet\":\"... lifetime; see static lifetime elision. [items.const.static-temporary]. A reference to a constant will have 'static lifetime if the constant value is eligible...\",\"title\":\"Constant items - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/types/impl-trait.html\",\"link\":\"https://doc.rust-lang.org/reference/types/impl-trait.html\",\"snippet\":\"bound, any lifetime parameters present must appear before all type and const generic parameters, and the elided lifetime ( '_ ) may be present if it is...\",\"title\":\"Impl trait type - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/trait-bounds.html\",\"link\":\"https://doc.rust-lang.org/reference/trait-bounds.html\",\"snippet\":\"Lifetime elision  11. Special types and traits  12. Names  12.1. Namespaces ... LifetimeBounds  ( Lifetime + )* Lifetime? Lifetime  LIFETIME_OR_LABEL\",\"title\":\"Trait and lifetime bounds - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/items/associated-items.html\",\"link\":\"https://doc.rust-lang.org/reference/items/associated-items.html\",\"snippet\":\"Lifetimes can be, and usually are, elided with this shorthand. [associated.fn.method.self-pat-mut]. If the self parameter is prefixed with...\",\"title\":\"Associated Items - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/items/generics.html\",\"link\":\"https://doc.rust-lang.org/reference/items/generics.html\",\"snippet\":\"The same parameter name may not be declared more than once in a GenericParams list. Some examples of items with type, const, and lifetime parameters:.\",\"title\":\"Generic parameters - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/memory-allocation-and-lifetime.html\",\"link\":\"https://doc.rust-lang.org/reference/memory-allocation-and-lifetime.html\",\"snippet\":\"Lifetime elision  11. Special types and traits  12. Names  12.1. Namespaces ... The lifetime of an allocation in the heap depends on the lifetime of the...\",\"title\":\"Memory allocation and lifetime - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/destructors.html\",\"link\":\"https://doc.rust-lang.org/reference/destructors.html\",\"snippet\":\"Trait and lifetime bounds  10.7. Type coercions  10.8. Destructors  10.9. Lifetime elision  11. Special types and traits  12. Names  12.1. Namespaces...\",\"title\":\"Destructors - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/subtyping.html\",\"link\":\"https://doc.rust-lang.org/reference/subtyping.html\",\"snippet\":\"Lifetime elision  11. Special types and traits  12. Names  12.1. Namespaces ... Subtyping is restricted to two cases: variance with respect to lifetimes and...\",\"title\":\"Subtyping and Variance - The Rust Reference\"},{\"formattedUrl\":\"https://doc.rust-lang.org/reference/tokens.html\",\"link\":\"https://doc.rust-lang.org/reference/tokens.html\",\"snippet\":\"Literals; Lifetimes; Punctuation; Delimiters. Within this documentation's grammar, simple tokens are given in string table production form, and appear in...\",\"title\":\"Tokens - The Rust Reference\"}]", :with_history=>false}
I, [2025-12-10T13:30:40.949406 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:40.949502 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:40.949916 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:40.949948 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:41.228877 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:41.228992 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:41.229050 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:43.417454 #27051]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/beta/rustc/symbol-mangling/v0.html\",\"link\":\"https://doc.rust-lang.org/beta/rustc/symbol-mangling/v0.html\",\"snippet\":\"A trait-definition is a path to a trait definition. It consists of the ... A lifetime may be displayed like a Rust lifetime using a single quote. Index...\",\"title\":\"v0 Symbol Format - The rustc book\"}]", :with_history=>false}
I, [2025-12-10T13:30:43.417479 #27051]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:30:43.417518 #27051]  INFO -- : Use template get_topic
I, [2025-12-10T13:30:43.418159 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:43.418225 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:43.668113 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:43.668181 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:43.668198 #27051]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:30:43.676422 #27051]  INFO -- : Calling worker: summary with params: {:text=>" Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:30:43.676447 #27051]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:30:43.676456 #27051]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:30:43.676466 #27051]  INFO -- : Create Conversation
I, [2025-12-10T13:30:43.676487 #27051]  INFO -- : Use template summarize
I, [2025-12-10T13:30:43.676712 #27051]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:30:43.676741 #27051]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:30:51.408331 #27051]  INFO -- : Successful send a message
I, [2025-12-10T13:30:51.408414 #27051]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:30:51.408429 #27051]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:32:17.827811 #27915]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:32:17.827884 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.827915 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.827921 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.827931 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.827935 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.827942 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.827946 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.827969 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.827974 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.827981 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.827985 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.827991 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.827995 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.828006 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.828010 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.828019 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.828024 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.828033 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892476 #27915]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:32:17.892540 #27915]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:32:17.892862 #27915]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:32:17.892894 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.892914 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892920 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.892927 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892932 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.892938 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892942 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.892964 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892969 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.892976 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892980 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.892986 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.892990 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.893001 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.893005 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.893014 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.893018 #27915]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:32:17.893028 #27915]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:32:17.893266 #27915]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:32:17.893289 #27915]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:32:20.114937 #27915]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>" Rust ", :with_history=>true}
I, [2025-12-10T13:32:20.114988 #27915]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:32:20.114999 #27915]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:32:20.115012 #27915]  INFO -- : Create Conversation
I, [2025-12-10T13:32:20.115041 #27915]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:32:20.115332 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:20.115356 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:31.059344 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:31.059437 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:31.059454 #27915]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:32:31.662051 #27915]  INFO -- : Calling worker: pre_search with params: {:text=>" ** Rust ** \n\n---\n\n### **1. **  \n ****  \n- Rust ****  \n- ****  \n- \n\n---\n\n### **2. **  \n- ****  \n  -  Rust   \n  -   \n- ****  \n  -  Rust 1.0 **** 1.70+ 2018   \n- ****  \n  - The Rust Programming Language Rust RFCrust-lang.org Rust Stack Overflow   \n  - \n\n---\n\n### **3. **  \n\n####    \n- `Rust `  \n- `Rust lifetime`  \n\n####    \n- `borrow checker`  \n- `ownership`  \n- `reference lifetime`  \n- `static lifetime`  \n- `lifetime annotations`  \n- `elided lifetimes`  \n\n####    \n```plaintext\n\"Rust lifetime\" definition  \n\"Rust lifetime\" site:doc.rust-lang.org  \n\"Rust lifetime\" intitle:\"The Rust Programming Language\"  \n\"Rust lifetime\" filetype:pdf  \n\"Rust lifetime\" vs \"ownership\"  \n```\n\n####    \n- `tutorial`  \n- `beginner`  \n- `crash` / `error`  \n- `compare` / `alternative`  \n\n>  ****  \n> `\"Rust lifetime\" site:doc.rust-lang.org`  \n> `\"Rust lifetime\" intitle:\"The Rust Programming Language\" chapter`\n\n---\n\n### **4. **  \n\n####  ****  \n- ****The Rust Programming Language10 Lifetimes  \n- **Rust **https://doc.rust-lang.org/stable/book/  \n- **Rust RFC #2093**  \n- ****Rust BlogAndre Bogus  Rust   \n\n####  ****  \n- Stack Overflow What is lifetime in Rust?  \n- Rust  Rust /  \n- YouTube  Rust Lifetimes Explained by The Rust Programming Language   \n\n####  ****  \n- ************  \n- ****  \n- **** 2021 Edition   \n- **** `fn longest(x: &str, y: &str) -> &str`\n\n---\n\n###  ****  \n1. ****`\"Rust lifetime\" site:doc.rust-lang.org`  \n2. ****Stack Overflow  + Rust 10  \n3. ****  \n   -   \n   - /  \n   -  vs   \n   -   \n4. ****5Rust\n\n>  ****The Rust Programming Language10\n\n--- \n\n****", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:32:31.662214 #27915]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:32:31.662234 #27915]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:32:31.662250 #27915]  INFO -- : Create Conversation
I, [2025-12-10T13:32:31.662289 #27915]  INFO -- : Use template pre_search
I, [2025-12-10T13:32:31.662801 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:31.662845 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:32.799166 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:32.799252 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:32.799272 #27915]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:32:34.467389 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://doc.rust-lang.org/rustc/symbol-mangling/v0.html\",\"link\":\"https://doc.rust-lang.org/rustc/symbol-mangling/v0.html\",\"snippet\":\"A lifetime may be displayed like a Rust lifetime using a single quote. Index 0 should be displayed as '_ . Index 0 should not be displayed for lifetimes in...\",\"title\":\"v0 Symbol Format - The rustc book\"}]", :with_history=>false}
I, [2025-12-10T13:32:34.467417 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:32:34.467624 #27915]  INFO -- : Create worker's name is get_topic
I, [2025-12-10T13:32:34.467673 #27915]  INFO -- : Create Conversation
I, [2025-12-10T13:32:34.467710 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:32:34.468077 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:34.468128 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:34.719934 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:34.720054 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:34.720089 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:32:36.715290 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://users.rust-lang.org/t/rust-lifetime-b-a/124023\",\"link\":\"https://users.rust-lang.org/t/rust-lifetime-b-a/124023\",\"snippet\":\"Rust lifetime 'b: 'a  help  phil-skillwon January 14, 2025, 11:59am 1. The following Rust code: fn longest\\u003c'a, 'b: 'a\\u003e(s1: \\u0026'a str, s2: \\u0026'b str) -\\u003e \\u0026'a...\",\"title\":\"Rust lifetime 'b: 'a - help - The Rust Programming Language Forum\"},{\"formattedUrl\":\"https://stackoverflow.com/.../question-about-lifetimes-from-the-rust-progra...\",\"link\":\"https://stackoverflow.com/questions/67663123/question-about-lifetimes-from-the-rust-programming-language\",\"snippet\":\"May 23, 2021 ... The Rustonomicon chapter on Lifetimes states ... How do lifetimes in Rust work for a function? 4  Clarification on Rust lifetime syntax.\",\"title\":\"Question about lifetimes from The Rust Programming Language ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/how-to-become-a-rust-ninja/64085\",\"link\":\"https://users.rust-lang.org/t/how-to-become-a-rust-ninja/64085\",\"snippet\":\"Aug 28, 2021 ... The nomicon chapter on variance  Common rust lifetime misconceptions ... The nomicon and jonhoo also have chapters/videos on other topics, which...\",\"title\":\"How to become a Rust ninja? - help - The Rust Programming ...\"},{\"formattedUrl\":\"https://research.ralfj.de/phd/thesis-screen.pdf\",\"link\":\"https://research.ralfj.de/phd/thesis-screen.pdf\",\"snippet\":\"Aug 21, 2020 ... ... Rust lifetime judgments ... Chapter 3: An introduction to Iris hoare-frame. {P} e {w. Q}E. {P  R} e {w. Q  R}E hoare-value. {True} v...\",\"title\":\"Understanding and Evolving the Rust Programming Language\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/complicated-lifetime-annotations/96857\",\"link\":\"https://users.rust-lang.org/t/complicated-lifetime-annotations/96857\",\"snippet\":\"Jul 12, 2023 ... It's described briefly in the Subtyping and Variance and Trait and lifetime bounds chapters of the reference. ... Rust lifetime problem  help. 8...\",\"title\":\"Complicated lifetime annotations - help - The Rust Programming ...\"},{\"formattedUrl\":\"https://d-nb.info/1217656901/34\",\"link\":\"https://d-nb.info/1217656901/34\",\"snippet\":\"Aug 21, 2020 ... ... Rust lifetime judgments ... Chapter 3: An introduction to Iris hoare-frame. {P} e {w. Q}E. {P  R} e {w. Q  R}E hoare-value. {True} v...\",\"title\":\"Understanding and Evolving the Rust Programming Language\"},{\"formattedUrl\":\"https://helda.helsinki.fi/bitstreams/4a5fa3d8-bb16-422a-b218.../download\",\"link\":\"https://helda.helsinki.fi/bitstreams/4a5fa3d8-bb16-422a-b218-ae63fdf88824/download\",\"snippet\":\"Jun 24, 2025 ... CHAPTER 1. INTRODUCTION. RQ1: Which parts of ... them with Rust's lifetime annotations, before giving up, as reflected by Observation 2.\",\"title\":\"Game engine implementation in the Rust programming language\"},{\"formattedUrl\":\"http://www.mcsprogram.org/.../the_rust-programming_language_covers-ru...\",\"link\":\"http://www.mcsprogram.org/browse/u5GE37/246367/the_rust-programming_language_covers-rust-2018.pdf\",\"snippet\":\"The Rust programming language's coverage of Rust 2018 marks a pivotal chapter in its ... compiler, Rust modules, Rust ownership, Rust lifetime, Rust crate...\",\"title\":\"The Rust Programming Language Covers Rust 2018\"},{\"formattedUrl\":\"https://nirakara.org/.../the_rust-programming-language_covers_rust_2018....\",\"link\":\"https://nirakara.org/Download_PDFS/u5GE37/246502/the_rust-programming-language_covers_rust_2018.pdf\",\"snippet\":\"edition, Rust language features, Rust syntax, Rust compiler, Rust modules,. Rust ownership, Rust lifetime, Rust crate ecosystem, Rust development.\",\"title\":\"The Rust Programming Language Covers Rust 2018\"}]", :with_history=>false}
I, [2025-12-10T13:32:36.715509 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:32:36.715608 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:32:36.716088 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:36.716157 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:36.958770 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:36.958830 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:36.958845 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:32:39.044900 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[{\"formattedUrl\":\"https://medium.com/.../understanding-rust-ownership-borrowing-lifetimes-f...\",\"link\":\"https://medium.com/@bugaevc/understanding-rust-ownership-borrowing-lifetimes-ff9ee9f79a9c\",\"snippet\":\"May 2, 2016 ... Understanding Rust: ownership, borrowing, lifetimes Here's my take on describing these things. Once you grasp it, it all seems intuitively...\",\"title\":\"Understanding Rust: ownership, borrowing, lifetimes | by Sergey ...\"},{\"formattedUrl\":\"https://rainingcomputers.blog/.../the_intuition_behind_rusts_borrowing_rul...\",\"link\":\"https://rainingcomputers.blog/dist/the_intuition_behind_rusts_borrowing_rules_and_ownership.md\",\"snippet\":\"Aug 14, 2023 ... ... relationship between the lifetimes of input borrowers and the lifetime of output returned borrower. ... Rust allows you to specify lifetime...\",\"title\":\"The intuition behind Rust's borrowing rules and ownership\"},{\"formattedUrl\":\"https://medium.com/.../rust-ownership-borrowing-lifetimes-oh-my-da1129...\",\"link\":\"https://medium.com/@conrardy/rust-ownership-borrowing-lifetimes-oh-my-da1129014aa5\",\"snippet\":\"Apr 15, 2024 ... Lifetimes are annotations that specify the relationships between references, ensuring that borrowed references do not outlive the data they...\",\"title\":\"Rust: Ownership \\u0026 Borrowing \\u0026 Lifetimes, Oh My! | by Riley ...\"},{\"formattedUrl\":\"https://www.integralist.co.uk/posts/rust-ownership/\",\"link\":\"https://www.integralist.co.uk/posts/rust-ownership/\",\"snippet\":\"Rust Ownership, Borrowing, and Lifetimes. TOC ... A few months ago I started working for Fastly as a Staff Software Engineer in their Developer Relations...\",\"title\":\"Rust Ownership, Borrowing, and Lifetimes\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../new_to_rust_confused_by_lifetimes/\",\"link\":\"https://www.reddit.com/r/rust/comments/1ck2716/new_to_rust_confused_by_lifetimes/\",\"snippet\":\"May 4, 2024 ... The rest of Rust's borrowing concepts seem arbitrary with no connection to real life. ... Lifetimes, borrowing and ownership are at the heart of...\",\"title\":\"New to rust, confused by lifetimes : r/rust\"},{\"formattedUrl\":\"https://earthly.dev/blog/rust-lifetimes-ownership-burrowing/\",\"link\":\"https://earthly.dev/blog/rust-lifetimes-ownership-burrowing/\",\"snippet\":\"Aug 28, 2023 ... In this article, you'll learn all about lifetimes and the concepts of ownership, borrowing, and resource management in Rust.\",\"title\":\"Rust Lifetimes: A Complete Guide to Ownership and Borrowing ...\"},{\"formattedUrl\":\"https://users.rust-lang.org/t/practical-suggestions-for...lifetime.../92634\",\"link\":\"https://users.rust-lang.org/t/practical-suggestions-for-fixing-lifetime-errors/92634\",\"snippet\":\"Apr 17, 2023 ... Ownership, borrowing, and lifetimes is a huge topic. There's way too ... What is the relationship between the lifetime in struct...\",\"title\":\"Practical suggestions for fixing lifetime errors - help - The Rust ...\"},{\"formattedUrl\":\"https://www.reddit.com/r/rust/.../not_another_lifetime_annotations_post/\",\"link\":\"https://www.reddit.com/r/rust/comments/feb31o/not_another_lifetime_annotations_post/\",\"snippet\":\"Mar 6, 2020 ... ... lifetimes/ownership/borrowing all play a role in the solution. But ... In Rust, changing lifetime relationships can break code, much...\",\"title\":\"Not Another Lifetime Annotations Post : r/rust\"},{\"formattedUrl\":\"https://users.rust-lang.org/...lifetimes...ownership-borrowing...rust/115152\",\"link\":\"https://users.rust-lang.org/t/are-lifetimes-in-structs-an-anti-pattern-resources-for-learning-more-about-ownership-borrowing-and-how-not-to-structure-yor-data-in-rust/115152\",\"snippet\":\"Jul 29, 2024 ... ... ownership, borrowing and how (not) to structure yor data in Rust ... Rust's borrowing system before you attempt a lifetime-bearing struct .\",\"title\":\"Are lifetimes in structs an anti-pattern? Resources for learning more ...\"},{\"formattedUrl\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"link\":\"https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html\",\"snippet\":\"... relationship between the references so the borrow checker can perform its analysis. Lifetime Annotation Syntax. Lifetime annotations don't...\",\"title\":\"Validating References with Lifetimes - The Rust Programming ...\"}]", :with_history=>false}
I, [2025-12-10T13:32:39.044933 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:32:39.044968 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:32:39.045309 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:39.045356 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:39.297160 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:39.297231 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:39.297247 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:32:39.333932 #27915]  INFO -- : Calling worker: generate_search_plan with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:32:39.333958 #27915]  INFO -- : Creating worker instance for: generate_search_plan
I, [2025-12-10T13:32:39.333967 #27915]  INFO -- : Create worker's name is generate_search_plan
I, [2025-12-10T13:32:39.333976 #27915]  INFO -- : Create Conversation
I, [2025-12-10T13:32:39.333997 #27915]  INFO -- : Use template generate_search_plan
I, [2025-12-10T13:32:39.334263 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:39.334293 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:46.673071 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:46.673155 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:46.673172 #27915]  INFO -- : Worker generate_search_plan executed(stream) successfully
I, [2025-12-10T13:32:47.275287 #27915]  INFO -- : Calling worker: smart_search with params: {:text=>"- 1: \n  - [] The Rust Programming Language10Lifetimes\"Rust lifetime\" site:doc.rust-lang.org/book/ch10\n  - [] Rust\"lifetime annotations\" site:doc.rust-lang.org/reference\n  - [] Rust\"Rust ownership borrowing lifetime relationship\" site:users.rust-lang.org\n  - [] Stack OverflowRust lifetime explanation for beginners\"Rust lifetime simple explanation\" site:stackoverflow.com\n\n- 2: \n  - [] Medium/Reddit\"Rust lifetime vs scope\" intitle:\"Rust\" -tutorial\n  - [] \"Rust  \" site:rust-lang.org.cn -blog\n  - [] 2021 Edition\"Rust lifetime elision return type 2021 edition\" site:doc.rust-lang.org\n  - []  'static\"Rust 'static lifetime string literal\" site:doc.rust-lang.org\n\n- 3: \n  - [] RFC\"Rust lifetime explicit annotation rationale RFC\"\n  - [] Rust\"Rust borrow checker lifetime inference algorithm\"\n  - [] \"Rust lifetime bound with generic type parameter example\"\n  - [] Rust\"Rust lifetime design motivation glimmer RFC\"\n\n- 4: \n  - [] \"Rust lifetime variance struct example\"\n  - [] Rust Nomicon\"Rust Nomicon lifetime unsafe code\"\n  - [] Rustrustclibrustc_middle/ty/lifetime.rs\"rustc lifetime inference implementation github\"\n  - [] Rustasync/await\"Rust async lifetime pinning\"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:32:47.275390 #27915]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:32:47.275403 #27915]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:32:47.275413 #27915]  INFO -- : Create Conversation
I, [2025-12-10T13:32:47.275435 #27915]  INFO -- : Use template smart_search
I, [2025-12-10T13:32:47.275667 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:47.275693 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:53.117691 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:53.117794 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:53.117830 #27915]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:32:54.647800 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:32:54.647829 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:32:54.647869 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:32:54.648275 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:54.648322 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:54.900617 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:54.900721 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:54.900746 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:32:56.548601 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:32:56.548628 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:32:56.548853 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:32:56.549328 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:56.549386 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:56.779301 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:56.779383 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:56.779401 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:32:58.312664 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:32:58.312766 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:32:58.312796 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:32:58.313048 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:32:58.313075 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:32:58.548479 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:32:58.548615 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:32:58.548673 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:00.318836 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:00.318886 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:00.318936 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:00.319327 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:00.319378 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:00.553383 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:00.553501 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:00.553525 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:02.536810 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:02.536837 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:02.536880 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:02.537282 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:02.537330 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:02.777899 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:02.777969 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:02.777985 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:04.569525 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:04.569569 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:04.569624 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:04.569992 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:04.570039 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:04.802178 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:04.802248 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:04.802263 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:06.548836 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:06.548865 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:06.548913 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:06.549325 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:06.549378 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:06.784942 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:06.785014 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:06.785031 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:08.648438 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:08.648457 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:08.648485 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:08.648725 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:08.648769 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:08.886721 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:08.886833 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:08.886858 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:10.631767 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:10.631818 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:10.631867 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:10.632278 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:10.632333 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:10.869726 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:10.869789 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:10.869805 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:12.687273 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:12.687297 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:12.687338 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:12.687704 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:12.687749 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:12.919387 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:12.919487 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:12.919513 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:14.616806 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:14.616824 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:14.617001 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:14.617339 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:14.617371 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:14.855775 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:14.855843 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:14.855861 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:16.456771 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:16.456817 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:16.456859 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:16.457216 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:16.457263 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:16.688465 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:16.688536 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:16.688552 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:18.342702 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:18.342729 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:18.342846 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:18.343117 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:18.343152 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:18.575535 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:18.575608 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:18.575624 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:20.244989 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:20.245008 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:20.245028 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:20.245259 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:20.245292 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:20.492138 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:20.492254 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:20.492277 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:22.272152 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:22.272171 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:22.272201 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:22.272508 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:22.272546 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:22.517502 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:22.517587 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:22.517610 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:24.093239 #27915]  INFO -- : Calling worker: get_topic with params: {:topics=>"[{\"id\":5,\"name\":\"Rust\",\"description\":null},{\"id\":6,\"name\":\"Rust\",\"description\":null},{\"id\":7,\"name\":\"Rust\",\"description\":null},{\"id\":8,\"name\":\"Rust\",\"description\":null},{\"id\":9,\"name\":\"Rust\",\"description\":null},{\"id\":10,\"name\":\"Go\",\"description\":null},{\"id\":11,\"name\":\"Go\",\"description\":null},{\"id\":12,\"name\":\"Rust\",\"description\":null},{\"id\":13,\"name\":\"Rust\",\"description\":null},{\"id\":14,\"name\":\"Rust\",\"description\":null}]", :search_result=>"[]", :with_history=>false}
I, [2025-12-10T13:33:24.093816 #27915]  INFO -- : Creating worker instance for: get_topic
I, [2025-12-10T13:33:24.093858 #27915]  INFO -- : Use template get_topic
I, [2025-12-10T13:33:24.094112 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:24.094143 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:24.336726 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:24.336805 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:24.336826 #27915]  INFO -- : Worker get_topic executed successfully
I, [2025-12-10T13:33:24.337989 #27915]  INFO -- : Calling worker: summary with params: {:text=>" Rust ", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:33:24.338016 #27915]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:33:24.338025 #27915]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:33:24.338034 #27915]  INFO -- : Create Conversation
I, [2025-12-10T13:33:24.338054 #27915]  INFO -- : Use template summarize
I, [2025-12-10T13:33:24.338283 #27915]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:33:24.338309 #27915]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:33:35.634216 #27915]  INFO -- : Successful send a message
I, [2025-12-10T13:33:35.634291 #27915]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:33:35.634307 #27915]  INFO -- : Worker summary executed(stream) successfully
I, [2025-12-10T13:45:24.895869 #30865]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:45:24.896373 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896432 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896440 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896450 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896470 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896486 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896494 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896596 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896626 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896641 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896646 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896653 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896658 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896678 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896683 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896693 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:24.896698 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:24.896708 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.029262 #30865]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:45:25.029331 #30865]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:45:25.030219 #30865]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:45:25.030269 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030297 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030302 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030309 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030314 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030320 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030324 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030348 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030353 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030360 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030364 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030370 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030374 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030386 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030390 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030405 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030409 #30865]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:45:25.030419 #30865]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:45:25.030656 #30865]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:45:25.030682 #30865]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:46:11.498179 #31102]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:46:11.498256 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498288 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498294 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498311 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498315 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498321 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498325 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498354 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498358 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498365 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498369 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498375 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498378 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498388 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498392 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498401 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.498405 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.498418 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.565355 #31102]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:46:11.565489 #31102]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:46:11.565883 #31102]  INFO -- : Loading configuration from file: ./config/llm_config.yml
I, [2025-12-10T13:46:11.565923 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.565947 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.565953 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.565960 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.565968 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.565974 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.565978 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.566002 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.566011 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.566018 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.566021 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.566027 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.566031 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.566042 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.566046 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.566060 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.566063 #31102]  INFO -- : Start create the SmartPrompt LLMAdapter.
I, [2025-12-10T13:46:11.566073 #31102]  INFO -- : Successful creation an OpenAI client.
I, [2025-12-10T13:46:11.566310 #31102]  INFO -- : Configuration loaded successfully
I, [2025-12-10T13:46:11.566332 #31102]  INFO -- : Started create the SmartPrompt engine.
I, [2025-12-10T13:46:13.990218 #31102]  INFO -- : Calling worker: analyze_search_scope with params: {:text=>"", :with_history=>true}
I, [2025-12-10T13:46:13.990232 #31102]  INFO -- : Creating worker instance for: analyze_search_scope
I, [2025-12-10T13:46:13.990242 #31102]  INFO -- : Create worker's name is analyze_search_scope
I, [2025-12-10T13:46:13.990256 #31102]  INFO -- : Create Conversation
I, [2025-12-10T13:46:13.990287 #31102]  INFO -- : Use template analyze_search_scope
I, [2025-12-10T13:46:13.990604 #31102]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:46:13.990636 #31102]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:46:23.867733 #31102]  INFO -- : Successful send a message
I, [2025-12-10T13:46:23.867809 #31102]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:46:23.867839 #31102]  INFO -- : Worker analyze_search_scope executed(stream) successfully
I, [2025-12-10T13:46:24.470256 #31102]  INFO -- : Calling worker: pre_search with params: {:text=>" **** \n\n---\n\n### **1. **\n\n** / /**\n\n- ****  \n  ****  \n  -   \n  -   \n  - \n\n>  **********/**********\n\n---\n\n### **2. **\n\n|  |  |\n|------|------|\n| **** |   |\n| **** |   |\n| **** |   |\n| **** |   |\n\n>  ************\n\n---\n\n### **3. **\n\n|  |  |\n|------|------|\n| **** |  |\n| **** | AI |\n| **** |   `site:`, `filetype:`, `intitle:` <br> - `\"\" site:github.com`<br> - `\"system test\" filetype:pdf`/ |\n| **** |  |\n\n>  ************\n\n---\n\n### **4. **\n\n|  |  |\n|------|------|\n| **** | ******** |\n| **** | - AI  <br>-   <br>- AI   |\n| **** | - ****<br>- ****<br>- **** |\n\n>  ****  \n> ****  \n>   \n> ****  \n> **\n\n---\n\n###  ****\n\n|  |  |\n|------|------|\n| **** |  |\n| **** |  **** |\n| **** | **** |\n| **** | - <br>- <br>-  |\n| **** |  |\n\n---\n\n>  ****  \n> ****  \n> ****  \n> **/**\n\nAI", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:46:24.470437 #31102]  INFO -- : Creating worker instance for: pre_search
I, [2025-12-10T13:46:24.470463 #31102]  INFO -- : Create worker's name is pre_search
I, [2025-12-10T13:46:24.470481 #31102]  INFO -- : Create Conversation
I, [2025-12-10T13:46:24.470523 #31102]  INFO -- : Use template pre_search
I, [2025-12-10T13:46:24.471036 #31102]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:46:24.471093 #31102]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:46:28.994375 #31102]  INFO -- : Successful send a message
I, [2025-12-10T13:46:28.994446 #31102]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:46:28.994462 #31102]  INFO -- : Worker pre_search executed(stream) successfully
I, [2025-12-10T13:46:29.597713 #31102]  INFO -- : Calling worker: smart_search with params: {:text=>"******** OpenDiggersmart_search \n\n---\n\n###  ****\n\n> ****  \n> ****\n\n---\n\n###  \n\n> ** GitHub  React  Vue    Python **\n\n---\n\n###  \n\n********\n\n|  |  |  |\n|--------------|----------|----------|\n|  | / |  |\n|  |  |  |\n|  |  |  |\n\n---\n\n###  \n\n|  |  |  |\n|----------|----------|------|\n| **** |   |  |\n| **** |   |  |\n| **** |   |  |\n| **** |   |  |\n\n> ********  \n> ********", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:46:29.597807 #31102]  INFO -- : Creating worker instance for: smart_search
I, [2025-12-10T13:46:29.597820 #31102]  INFO -- : Create worker's name is smart_search
I, [2025-12-10T13:46:29.597831 #31102]  INFO -- : Create Conversation
I, [2025-12-10T13:46:29.597854 #31102]  INFO -- : Use template smart_search
I, [2025-12-10T13:46:29.598093 #31102]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:46:29.598121 #31102]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:46:30.183202 #31102]  INFO -- : Successful send a message
I, [2025-12-10T13:46:30.183278 #31102]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:46:30.183291 #31102]  INFO -- : Worker smart_search executed(stream) successfully
I, [2025-12-10T13:46:30.184032 #31102]  INFO -- : Calling worker: summary with params: {:text=>"", :with_history=>true, :tools=>[{:type=>"function", :function=>{:name=>:smart_search, :description=>"", :parameters=>{:type=>"object", :properties=>{:q=>{:type=>:string, :description=>""}}, :required=>[:q]}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metric", "description"=>"Get single metric data from OpenDigger with enhanced error handling", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>"Platform of the repo or user (GitHub, Gitee).", "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>"What is the entity of the metric (Repo, User).", "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>"The owner name of the repo to get a metric data."}, "repo"=>{:type=>"string", :description=>"The repo name of the repo to get a metric data."}, "login"=>{:type=>"string", :description=>"The user login to get a metric data of a user."}, "metricName"=>{:type=>"string", :description=>"The metric name to get the data.", "enum"=>["openrank", "stars", "forks", "participants", "contributors", "issues_new", "issues_closed", "change_requests", "pull_requests", "pull_requests_accepted", "issue_comments", "commits", "activity", "technical_fork", "bus_factor", "releases", "inactive_contributors", "pull_requests_merged", "issue_response_time", "maintainer_count", "code_change_lines", "community_activity", "developer_network"]}}}}}, {:type=>"function", :function=>{"name"=>"get_open_digger_metrics_batch", "description"=>"Batch fetch multiple OpenDigger metrics with intelligent processing", "parameters"=>{"type"=>"object", "required"=>["requests"], "properties"=>{"requests"=>{:type=>"array", :description=>"Batch of up to 20 requests"}}}}}, {:type=>"function", :function=>{"name"=>"compare_repositories", "description"=>"Compare multiple repositories across key metrics with intelligent analysis", "parameters"=>{"type"=>"object", "required"=>["repositories"], "properties"=>{"repositories"=>{:type=>"array", :description=>"2-5 repositories to compare"}, "metrics"=>{:type=>"array", :description=>"Metrics to compare (default: openrank, stars, contributors)"}}}}}, {:type=>"function", :function=>{"name"=>"analyze_trends", "description"=>"Perform comprehensive trend analysis on metrics over time", "parameters"=>{"type"=>"object", "required"=>["platform", "entityType", "metricName"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "entityType"=>{:type=>"string", :description=>nil, "enum"=>["Repo", "User"]}, "owner"=>{:type=>"string", :description=>nil}, "repo"=>{:type=>"string", :description=>nil}, "login"=>{:type=>"string", :description=>nil}, "metricName"=>{:type=>"string", :description=>nil, "enum"=>["openrank", "stars", "forks", "contributors", "participants"]}, "timeRange"=>{:type=>"string", :description=>"Time range for trend analysis", "enum"=>["6m", "1y", "2y", "3y"]}}}}}, {:type=>"function", :function=>{"name"=>"get_ecosystem_insights", "description"=>"Get ecosystem-level insights for languages, topics, or organizations", "parameters"=>{"type"=>"object", "required"=>["platform", "category", "value"], "properties"=>{"platform"=>{:type=>"string", :description=>nil, "enum"=>["GitHub", "Gitee"]}, "category"=>{:type=>"string", :description=>"Type of ecosystem analysis", "enum"=>["language", "topic", "organization"]}, "value"=>{:type=>"string", :description=>"Language name, topic, or organization to analyze"}, "limit"=>{:type=>"number", :description=>"Number of top results to return (default: 10)"}}}}}, {:type=>"function", :function=>{"name"=>"server_health", "description"=>"Get server health status, cache statistics, and performance metrics", "parameters"=>{"type"=>"object", "required"=>[], "properties"=>{"includeCache"=>{:type=>"boolean", :description=>"Include cache statistics in response"}, "includePerfMetrics"=>{:type=>"boolean", :description=>"Include performance metrics"}}}}}]}
I, [2025-12-10T13:46:30.184081 #31102]  INFO -- : Creating worker instance for: summary
I, [2025-12-10T13:46:30.184090 #31102]  INFO -- : Create worker's name is summary
I, [2025-12-10T13:46:30.184100 #31102]  INFO -- : Create Conversation
I, [2025-12-10T13:46:30.184120 #31102]  INFO -- : Use template summarize
I, [2025-12-10T13:46:30.184352 #31102]  INFO -- : OpenAIAdapter: Sending request to OpenAI
I, [2025-12-10T13:46:30.184377 #31102]  INFO -- : OpenAIAdapter: Using model qwen3-next
I, [2025-12-10T13:46:35.480059 #31102]  INFO -- : Successful send a message
I, [2025-12-10T13:46:35.480135 #31102]  INFO -- : OpenAIAdapter: Received response from OpenAI
I, [2025-12-10T13:46:35.480151 #31102]  INFO -- : Worker summary executed(stream) successfully
